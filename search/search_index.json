{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Welcome to the documentation of IASO # Introduction to IASO # IASO is an innovative, open-source, bilingual (EN/FR) data collection platform with advanced geospatial features to plan, monitor and evaluate health, environmental or social programmes in low- and middle-income settings (LMICs). IASO is recognized as a Digital Public Good by the Digital Public Good Alliance and listed as a Digital Square Software Global Good, a testament to its proven impact. IASO comprises: a web dashboard - intended for supervisors to organize data collection and geographical data management a mobile application that also works offline - intended to field users to fill out forms and send data when network is available a matching and scripting interface to analyze, compare and merge several geographic data sources a bi-directional integration with DHIS2 , the widely used Health Management Information System in Low- and middle-income countries In terms of features, IASO can be summarized around three main components which are interconnected and expand the powers of one another: Geospatial data management (Georegistry) Manage multiple master lists of organizational units (e.g. health areas, districts, facilities, or schools) including their GPS coordinates and boundaries Keep track of changes made to the organization units Map multiple geographic data sources Propose changes to org units from IASO mobile application and validate them on the web Structured data collection Create data collection forms using the widely known XLS form format and upload them to IASO Link your form to one or several organization unit type (e.g. National/Regional/District/Health facility) to geo-structure your data collection Keep track of changes with versioning of your data collection forms Validate from the web all data collection form submissions sent from IASO mobile application Monitor data collection completeness per organization unit level and drill-down to identify where issues happen Geo-enabled Microplanning Manage teams of users and teams of teams Assign data collection duties to teams and users using a map interface Create plannings with a scope, a time span, and one or several data collection form(s) The platform has been implemented in Benin, Burkina Faso, Burundi, Cameroon, Central African Republic, the Democratic Republic of Congo, Haiti, Ivory Coast, Mali, Niger, Nigeria and Uganda. It is the official georegistry in Burkina Faso since 2023. IASO has also been implemented at regional level (AFRO region) in support to the Global Polio Eradication Initiative for its geospatial and health facility registries capabilities. Technical stack # IASO is made of a white labeled Android application using Java/Kotlin, reusing large parts of the ODK projects, and a web platform programmed using Python/GeoDjango on top of PostGIS. Frontend is mainly React/Leaflet. The API is implemented via Django rest framework, all data is stored in Postgresql or the media/ directory. One of the aims is the ease of integration with other platforms. We already have csv and geopackage imports and exports and target easy integration with OSM. The companion mobile app for Android allow submitting forms and creating org unit. Forms can also be filled in a web interface via the Enketo companion service. Both IASO and Enketo need to be configured to work together. It is possible to run an Enketo service locally.","title":"Home"},{"location":"index.html#welcome-to-the-documentation-of-iaso","text":"","title":"Welcome to the documentation of IASO"},{"location":"index.html#introduction-to-iaso","text":"IASO is an innovative, open-source, bilingual (EN/FR) data collection platform with advanced geospatial features to plan, monitor and evaluate health, environmental or social programmes in low- and middle-income settings (LMICs). IASO is recognized as a Digital Public Good by the Digital Public Good Alliance and listed as a Digital Square Software Global Good, a testament to its proven impact. IASO comprises: a web dashboard - intended for supervisors to organize data collection and geographical data management a mobile application that also works offline - intended to field users to fill out forms and send data when network is available a matching and scripting interface to analyze, compare and merge several geographic data sources a bi-directional integration with DHIS2 , the widely used Health Management Information System in Low- and middle-income countries In terms of features, IASO can be summarized around three main components which are interconnected and expand the powers of one another: Geospatial data management (Georegistry) Manage multiple master lists of organizational units (e.g. health areas, districts, facilities, or schools) including their GPS coordinates and boundaries Keep track of changes made to the organization units Map multiple geographic data sources Propose changes to org units from IASO mobile application and validate them on the web Structured data collection Create data collection forms using the widely known XLS form format and upload them to IASO Link your form to one or several organization unit type (e.g. National/Regional/District/Health facility) to geo-structure your data collection Keep track of changes with versioning of your data collection forms Validate from the web all data collection form submissions sent from IASO mobile application Monitor data collection completeness per organization unit level and drill-down to identify where issues happen Geo-enabled Microplanning Manage teams of users and teams of teams Assign data collection duties to teams and users using a map interface Create plannings with a scope, a time span, and one or several data collection form(s) The platform has been implemented in Benin, Burkina Faso, Burundi, Cameroon, Central African Republic, the Democratic Republic of Congo, Haiti, Ivory Coast, Mali, Niger, Nigeria and Uganda. It is the official georegistry in Burkina Faso since 2023. IASO has also been implemented at regional level (AFRO region) in support to the Global Polio Eradication Initiative for its geospatial and health facility registries capabilities.","title":"Introduction to IASO"},{"location":"index.html#technical-stack","text":"IASO is made of a white labeled Android application using Java/Kotlin, reusing large parts of the ODK projects, and a web platform programmed using Python/GeoDjango on top of PostGIS. Frontend is mainly React/Leaflet. The API is implemented via Django rest framework, all data is stored in Postgresql or the media/ directory. One of the aims is the ease of integration with other platforms. We already have csv and geopackage imports and exports and target easy integration with OSM. The companion mobile app for Android allow submitting forms and creating org unit. Forms can also be filled in a web interface via the Enketo companion service. Both IASO and Enketo need to be configured to work together. It is possible to run an Enketo service locally.","title":"Technical stack"},{"location":"AWS-Deployment.html","text":"How Iaso is deployed on AWS # on ElasticBeanstalk + RDS Main parts # Creation of the HOST environment where the Iaso code will be deployed as well as the related services The deployment of the code itself and of new version Host infrastructure # This documentation concerned the main Iaso deployment, that are done on AWS. The main pillar is AWS Elastic beanstalk Which is kind of a magic solution from Amazon that tie several of their service together, handle deployment logic, etc... In the past we configured it by hands but now we are moving toward having it all handled via Terrraform so it is in code (we can have an history, avoid misclick, do complex ops etc...). The technical term for this is \"Provisioning\" if you want to look it up. Setup of the Elastic Beainstalk # See https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create-deploy-python-django.html We have custom commands and configuration in .ebextensions/ and in and in .platform/ to extend the nginx config. Running Django 3 on Elastic Beanstalk / Custom AMI # Django 3 requires version 2+ of the gdal library. Sadly, Beanstalk is based on Amazon Linux that contain an outdated version of GDAL. To fix this you have to create a custom AMI to use in your Elastic Beanstalk environments and compile and your own version of gdal and it's dependencies. See the AWS documentation on creating adn using a custom AMI and the Django documentation on compiling the GIS libraries Custom build of the following libraries were done: geos SQLite proj proj-data spatialite gdal You can check scripts/create_ami.sh for reference Read AWS documentation on creating adn using a custom AMI but in summary: In EC2 -> AMIs, identify the AMI of the Elastic Beanstalk EC2 server(Ex: Choose a public AMI in which python3.9 installed with Amazon Linux 2). Select the AMI and launch a new instance based on it. Specify the instance name and choose a key pair. Don't forget to set in the advanced section: #cloud-config repo_releasever: repository version number repo_upgrade: none Connect via SSH to the instance Install the dependencies (see scripts/create_ami.sh) Then go to Actions -> Image -> Create Image When it's ready, go to the Beanstalk Instance Settings and specify the AMI reference of the image we just created. Where is the code ? # Infrastructure and configuration in the Github repository BLSQ/terraform-iaso-eb There is good documentation from Mbayang in the docs/ folder. Visibility is restricted. In the BLSQ/iaso Github repository: * .github For the workflow info * scripts/ * .ebextension For the Elastic beanstalk specific command * .platform Configuration override Related services # S3 bucket: For the static and the user uploaded media (in AWS) Enketo (in another AWS Elastic Beanstalk) Postgresql RDS (in AWS) Queue Service for background Worker (in AWS SQS) Sentry: error handling and notification (as Saas) MailGun (as Saas) Route53: DNS redirection (in AWS) Two type of env in elastic beanstalk: * web * worker We tie them via an \"env\" tag in AWS, so we can deploy them at the same time One Elastic Beanstalk Env can contain multipe \"EC2 Instance\", that is virtual machine server. Their number auto scale according to rule in elastic beanstalk. Usually we have 1 instance for Worker and 2 for Web. S3 bucket # Static: Push static in them so they can be properly cached and CDN (not sure we actually do this) Media: Store uploaded media by the users : Form response (XML), media attached to Form response (photos), gpkg, form definition, etc.. Static are readable by all. Media are only accessible via Signed url that expire after a laps of time (15 minutes I think) and that are generated on the fly by iaso when needed. CI/CD # Deployment of new version is done via Github action. Each change on main are automically deployed on the staging environment Deployment to other env have to be manually triggered Deployement process # How a new version of Iaso is deployed This is a simplified view, some details are omitted for clarity A user trigger the deploy worflow in github actions (or it is trigger automatically for staging) In the github worker: (code in .github/workflows/deploy.yml) Determine version number. Call set_version to set it. It build all the JS/CSS and other ressource for the front-end Add the to the git repo scripts/eb-deploy.py: Connect to the AWS api to fetch all the beanstalk environments for the iaso environment. e.g. : staging -> iaso-staging2 and iaso-staging2-worker For each beanstalk env, trigger eb deploy (from awseb cli): Make a zip file of the content of the git repo (done by eb deploy). Including the compiled asset Call ElasticBeanstalk API to deploy it In the Iaso servers (EC2 instances): Our code/config for this is in the directory .ebextensions Action markqe with \u00a5 are part of Elastic beanstalk logic Deployment is triggered \u00a5 New app version is copied in /var/app/staging \u00a5 The dependencies in requirements.txt are installed \u00a5 Our logic is executed Server translations are compiled The frontend (compiled JS, image, css) is pushed to the S3 bucket. Database migration are done Cache table is created /var/app/staging is moved in /var/app/current \u00a5 If these steps fail, Elastic beanstalk will do a rollback and revert to the previous version. Note since we do manually the maching between worker and web, sometime we have the problem that one is rolled back and not the other and we have a version mismatch. We sometime also have the problem with incompatible database migrations. \u00a5 Send a Slack notification to notify of the success of failure of the github deployment. Related services in more details # S3 bucket: For the static and the user uploaded media (in AWS) Enketo (in another AWS Elastic Beanstalk) Postgresql RDS (in AWS) Queue Service for background Worker (in AWS SQS) Sentry: error handling and notification (as Saas) MailGun (as Saas) Route53: DNS redirection (in AWS) Enketo # Deployed separately, handled via Elastic Beanstalk also, linked to Iaso via environment variable. Mbayang manage this AWS SQS # Queue system used for Worker, see worker section in README S3 bucket # S3 see above Architecture inside the VM # Code is in the /var/app/current Systemctl launch the web server as the web unit. This is done via Gunicorn under the web user, gunicorn launch multiple Django server. There is a NGINX in front of gunicorn. The above is handled automatically via Iaso The logs can be listed inside the VM via journalctl -u web We have 2 crons (for now). They can be seen by using systemctl list-timers","title":"How Iaso is deployed on AWS"},{"location":"AWS-Deployment.html#how-iaso-is-deployed-on-aws","text":"on ElasticBeanstalk + RDS","title":"How Iaso is deployed on AWS"},{"location":"AWS-Deployment.html#main-parts","text":"Creation of the HOST environment where the Iaso code will be deployed as well as the related services The deployment of the code itself and of new version","title":"Main parts"},{"location":"AWS-Deployment.html#host-infrastructure","text":"This documentation concerned the main Iaso deployment, that are done on AWS. The main pillar is AWS Elastic beanstalk Which is kind of a magic solution from Amazon that tie several of their service together, handle deployment logic, etc... In the past we configured it by hands but now we are moving toward having it all handled via Terrraform so it is in code (we can have an history, avoid misclick, do complex ops etc...). The technical term for this is \"Provisioning\" if you want to look it up.","title":"Host infrastructure"},{"location":"AWS-Deployment.html#setup-of-the-elastic-beainstalk","text":"See https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create-deploy-python-django.html We have custom commands and configuration in .ebextensions/ and in and in .platform/ to extend the nginx config.","title":"Setup of the Elastic Beainstalk"},{"location":"AWS-Deployment.html#running-django-3-on-elastic-beanstalk-custom-ami","text":"Django 3 requires version 2+ of the gdal library. Sadly, Beanstalk is based on Amazon Linux that contain an outdated version of GDAL. To fix this you have to create a custom AMI to use in your Elastic Beanstalk environments and compile and your own version of gdal and it's dependencies. See the AWS documentation on creating adn using a custom AMI and the Django documentation on compiling the GIS libraries Custom build of the following libraries were done: geos SQLite proj proj-data spatialite gdal You can check scripts/create_ami.sh for reference Read AWS documentation on creating adn using a custom AMI but in summary: In EC2 -> AMIs, identify the AMI of the Elastic Beanstalk EC2 server(Ex: Choose a public AMI in which python3.9 installed with Amazon Linux 2). Select the AMI and launch a new instance based on it. Specify the instance name and choose a key pair. Don't forget to set in the advanced section: #cloud-config repo_releasever: repository version number repo_upgrade: none Connect via SSH to the instance Install the dependencies (see scripts/create_ami.sh) Then go to Actions -> Image -> Create Image When it's ready, go to the Beanstalk Instance Settings and specify the AMI reference of the image we just created.","title":"Running Django 3 on Elastic Beanstalk / Custom AMI"},{"location":"AWS-Deployment.html#where-is-the-code","text":"Infrastructure and configuration in the Github repository BLSQ/terraform-iaso-eb There is good documentation from Mbayang in the docs/ folder. Visibility is restricted. In the BLSQ/iaso Github repository: * .github For the workflow info * scripts/ * .ebextension For the Elastic beanstalk specific command * .platform Configuration override","title":"Where is the code ?"},{"location":"AWS-Deployment.html#related-services","text":"S3 bucket: For the static and the user uploaded media (in AWS) Enketo (in another AWS Elastic Beanstalk) Postgresql RDS (in AWS) Queue Service for background Worker (in AWS SQS) Sentry: error handling and notification (as Saas) MailGun (as Saas) Route53: DNS redirection (in AWS) Two type of env in elastic beanstalk: * web * worker We tie them via an \"env\" tag in AWS, so we can deploy them at the same time One Elastic Beanstalk Env can contain multipe \"EC2 Instance\", that is virtual machine server. Their number auto scale according to rule in elastic beanstalk. Usually we have 1 instance for Worker and 2 for Web.","title":"Related services"},{"location":"AWS-Deployment.html#s3-bucket","text":"Static: Push static in them so they can be properly cached and CDN (not sure we actually do this) Media: Store uploaded media by the users : Form response (XML), media attached to Form response (photos), gpkg, form definition, etc.. Static are readable by all. Media are only accessible via Signed url that expire after a laps of time (15 minutes I think) and that are generated on the fly by iaso when needed.","title":"S3 bucket"},{"location":"AWS-Deployment.html#cicd","text":"Deployment of new version is done via Github action. Each change on main are automically deployed on the staging environment Deployment to other env have to be manually triggered","title":"CI/CD"},{"location":"AWS-Deployment.html#deployement-process","text":"How a new version of Iaso is deployed This is a simplified view, some details are omitted for clarity A user trigger the deploy worflow in github actions (or it is trigger automatically for staging) In the github worker: (code in .github/workflows/deploy.yml) Determine version number. Call set_version to set it. It build all the JS/CSS and other ressource for the front-end Add the to the git repo scripts/eb-deploy.py: Connect to the AWS api to fetch all the beanstalk environments for the iaso environment. e.g. : staging -> iaso-staging2 and iaso-staging2-worker For each beanstalk env, trigger eb deploy (from awseb cli): Make a zip file of the content of the git repo (done by eb deploy). Including the compiled asset Call ElasticBeanstalk API to deploy it In the Iaso servers (EC2 instances): Our code/config for this is in the directory .ebextensions Action markqe with \u00a5 are part of Elastic beanstalk logic Deployment is triggered \u00a5 New app version is copied in /var/app/staging \u00a5 The dependencies in requirements.txt are installed \u00a5 Our logic is executed Server translations are compiled The frontend (compiled JS, image, css) is pushed to the S3 bucket. Database migration are done Cache table is created /var/app/staging is moved in /var/app/current \u00a5 If these steps fail, Elastic beanstalk will do a rollback and revert to the previous version. Note since we do manually the maching between worker and web, sometime we have the problem that one is rolled back and not the other and we have a version mismatch. We sometime also have the problem with incompatible database migrations. \u00a5 Send a Slack notification to notify of the success of failure of the github deployment.","title":"Deployement process"},{"location":"AWS-Deployment.html#related-services-in-more-details","text":"S3 bucket: For the static and the user uploaded media (in AWS) Enketo (in another AWS Elastic Beanstalk) Postgresql RDS (in AWS) Queue Service for background Worker (in AWS SQS) Sentry: error handling and notification (as Saas) MailGun (as Saas) Route53: DNS redirection (in AWS)","title":"Related services in more details"},{"location":"AWS-Deployment.html#enketo","text":"Deployed separately, handled via Elastic Beanstalk also, linked to Iaso via environment variable. Mbayang manage this","title":"Enketo"},{"location":"AWS-Deployment.html#aws-sqs","text":"Queue system used for Worker, see worker section in README","title":"AWS SQS"},{"location":"AWS-Deployment.html#s3-bucket_1","text":"S3 see above","title":"S3 bucket"},{"location":"AWS-Deployment.html#architecture-inside-the-vm","text":"Code is in the /var/app/current Systemctl launch the web server as the web unit. This is done via Gunicorn under the web user, gunicorn launch multiple Django server. There is a NGINX in front of gunicorn. The above is handled automatically via Iaso The logs can be listed inside the VM via journalctl -u web We have 2 crons (for now). They can be seen by using systemctl list-timers","title":"Architecture inside the VM"},{"location":"pages/dev/how_to/add_new_permission/add_new_permission.html","text":"How to add a new permission in Iaso # 1. Add permission in the model # Go to `/hat/menupermissions/models.py`` Add a private constant with the string value of the permission: `_MY_PERMISSION = \"iaso_my_permission\"`` Add a constant to combine it with _PREFIX : MY_PERMISSION = _PREFIX + _MY_PERMISSION Add the permission to the permissions property of CustomPermissionSupport 's Meta class: (_MY_PERMISSION, _(\"Access some stuff\")) 2. Include the permission in a module # Go to /hat/menupermissions/constants.py Add the permission to a module from MODULE_PERMISSIONS If no existing module fits, create one (see exiting modules for inspiration) If a new module is created, add it to MODULES (in the same file) If it's a new module run migration to add it in modules options for the account 3. Include the permission in the corresponding group # Go to /hat/menupermissions/constants.py Add the permission to a group from PERMISSIONS_PRESENTATION If no existing group fits, create one (see exiting groups for inspiration) If the corresponding group exists add the new permission to that group (see exiting groups for inspiration) 4. If the added permission must be coupled with another permission like read and edit # Go to /hat/menupermissions/constants.py Add the added permission and it's related permission as an item of the READ_EDIT_PERMISSIONS dictionnary The item should have a key which reprensente the string name which will be displayed The item should have a dictionnary reprensenting the coupled permissions, the keys (should be two keys) are read and edit or other keys like no-admin and admin The item should look like item_key\": {\"read\": \"added_permission\", \"edit\": \"coupled_permission\"} Add translations for all the keys( item_key, read and edit ) and the tooltip message of the principal key( item_key ) 5. Make and run migration # docker compose run --rm iaso manage makemigrations && docker compose run --rm iaso manage migrate 6. Add the permission in the front-end # Go to /hat/assets/js/apps/Iaso/utils/permissions.ts . Add and export a constant with the permission key, in a similar way as what was done for the backend in step 1. When using the permission in the front-end: import the constant, don't write the key in a string. 7. Add translations in the front-end # Add a translation for the permission, and its tooltip in permissionMessages.ts . The tooltip key should have the format: <permission name>_tooltip to enable the component to recognize and translate it. Add corresponding translations in en.json and fr.json 8. Add translation for new module (if applicable) # Go to /hat/assets/js/apps/Iaso/domains/modules/messages.ts Add translation for the new module. The translation key should follow the pattern: `iaso.module. ' Example: codename = \"PAYMENTS\" => translation key = iaso.module.payments","title":"How to add a new permission in Iaso"},{"location":"pages/dev/how_to/add_new_permission/add_new_permission.html#how-to-add-a-new-permission-in-iaso","text":"","title":"How to add a new permission in Iaso"},{"location":"pages/dev/how_to/add_new_permission/add_new_permission.html#1-add-permission-in-the-model","text":"Go to `/hat/menupermissions/models.py`` Add a private constant with the string value of the permission: `_MY_PERMISSION = \"iaso_my_permission\"`` Add a constant to combine it with _PREFIX : MY_PERMISSION = _PREFIX + _MY_PERMISSION Add the permission to the permissions property of CustomPermissionSupport 's Meta class: (_MY_PERMISSION, _(\"Access some stuff\"))","title":"1. Add permission in the model"},{"location":"pages/dev/how_to/add_new_permission/add_new_permission.html#2-include-the-permission-in-a-module","text":"Go to /hat/menupermissions/constants.py Add the permission to a module from MODULE_PERMISSIONS If no existing module fits, create one (see exiting modules for inspiration) If a new module is created, add it to MODULES (in the same file) If it's a new module run migration to add it in modules options for the account","title":"2. Include the permission in a module"},{"location":"pages/dev/how_to/add_new_permission/add_new_permission.html#3-include-the-permission-in-the-corresponding-group","text":"Go to /hat/menupermissions/constants.py Add the permission to a group from PERMISSIONS_PRESENTATION If no existing group fits, create one (see exiting groups for inspiration) If the corresponding group exists add the new permission to that group (see exiting groups for inspiration)","title":"3. Include the permission in the corresponding group"},{"location":"pages/dev/how_to/add_new_permission/add_new_permission.html#4-if-the-added-permission-must-be-coupled-with-another-permission-like-read-and-edit","text":"Go to /hat/menupermissions/constants.py Add the added permission and it's related permission as an item of the READ_EDIT_PERMISSIONS dictionnary The item should have a key which reprensente the string name which will be displayed The item should have a dictionnary reprensenting the coupled permissions, the keys (should be two keys) are read and edit or other keys like no-admin and admin The item should look like item_key\": {\"read\": \"added_permission\", \"edit\": \"coupled_permission\"} Add translations for all the keys( item_key, read and edit ) and the tooltip message of the principal key( item_key )","title":"4. If the added permission must be coupled with another permission like read and edit"},{"location":"pages/dev/how_to/add_new_permission/add_new_permission.html#5-make-and-run-migration","text":"docker compose run --rm iaso manage makemigrations && docker compose run --rm iaso manage migrate","title":"5. Make and run migration"},{"location":"pages/dev/how_to/add_new_permission/add_new_permission.html#6-add-the-permission-in-the-front-end","text":"Go to /hat/assets/js/apps/Iaso/utils/permissions.ts . Add and export a constant with the permission key, in a similar way as what was done for the backend in step 1. When using the permission in the front-end: import the constant, don't write the key in a string.","title":"6. Add the permission in the front-end"},{"location":"pages/dev/how_to/add_new_permission/add_new_permission.html#7-add-translations-in-the-front-end","text":"Add a translation for the permission, and its tooltip in permissionMessages.ts . The tooltip key should have the format: <permission name>_tooltip to enable the component to recognize and translate it. Add corresponding translations in en.json and fr.json","title":"7. Add translations in the front-end"},{"location":"pages/dev/how_to/add_new_permission/add_new_permission.html#8-add-translation-for-new-module-if-applicable","text":"Go to /hat/assets/js/apps/Iaso/domains/modules/messages.ts Add translation for the new module. The translation key should follow the pattern: `iaso.module. ' Example: codename = \"PAYMENTS\" => translation key = iaso.module.payments","title":"8. Add translation for new module (if applicable)"},{"location":"pages/dev/how_to/contribute/contribute.html","text":"Contribute # Code formatting # We have adopted Black as our code formatting tool. Line length is 120. The easiest way to use is is to install the pre-commit hook: 1. Install pre-commit: pip install pre-commit 2. Execute pre-commit install to install git hooks in your .git/ directory. Another good way to have it working is to set it up in your code editor. Pycharm, for example, has good support for this. The pre-commit is not mandatory but Continuous Integration will check if the formatting is respected! Tests and linting # For the Python backend, we use the Django builtin test framework. Tests can be executed with docker compose exec iaso ./manage.py test Translations # The few translation for the Django side (login and reset password email etc..) are separated from the test. We only translate the template for now not the python code (string on model or admin). When modifying or adding new strings to translate, use the following command to regenerate the translations: manage.py makemessages --locale=fr --extension txt --extension html This will update hat/locale/fr/LC_MESSAGES/django.po with the new strings to translate. After updating it with the translation you need to following command to have them reflected in the interface: manage.py compilemessages Code reloading # In development the servers will reload when they detect a file change, either in Python or Javascript. If you need reloading for the bluesquare-components code, see the \"Live Bluesquare Components\" section. Troubleshooting # If you need to restart everything docker compose stop && docker compose start If you encounter problems, you can try to rebuild everything from scratch. # kill containers docker compose kill # remove `iaso` container docker compose rm -f iaso # build containers docker compose build # start-up containers docker compose up Jupyter Notebook # To run a Jupyter Notebook, just copy the env variable from runaisasdev.sh, activate the virtualenv and run python manage.py shell_plus --notebook Testing prod js assets in development # During local development, by default, the Javascript and CSS will be loaded from a webpack server with live reloading of the code. To locally test the compiled version as it is in production ( minified and with the same compilation option). You can launch docker compose with the TEST_PROD=true environment variable set. e.g TEST_PROD=true docker compose up This can be useful to reproduce production only bugs. Please also test with this configuration whenever you modify webpack.prod.js to validate your changes. Alternatively this can be done outside of docker by running: npm run webpack-prod to do the build Launching the django server with TEST_PROD e.g. TEST_PROD=true python manage.py runserver .","title":"Contribute"},{"location":"pages/dev/how_to/contribute/contribute.html#contribute","text":"","title":"Contribute"},{"location":"pages/dev/how_to/contribute/contribute.html#code-formatting","text":"We have adopted Black as our code formatting tool. Line length is 120. The easiest way to use is is to install the pre-commit hook: 1. Install pre-commit: pip install pre-commit 2. Execute pre-commit install to install git hooks in your .git/ directory. Another good way to have it working is to set it up in your code editor. Pycharm, for example, has good support for this. The pre-commit is not mandatory but Continuous Integration will check if the formatting is respected!","title":"Code formatting"},{"location":"pages/dev/how_to/contribute/contribute.html#tests-and-linting","text":"For the Python backend, we use the Django builtin test framework. Tests can be executed with docker compose exec iaso ./manage.py test","title":"Tests and linting"},{"location":"pages/dev/how_to/contribute/contribute.html#translations","text":"The few translation for the Django side (login and reset password email etc..) are separated from the test. We only translate the template for now not the python code (string on model or admin). When modifying or adding new strings to translate, use the following command to regenerate the translations: manage.py makemessages --locale=fr --extension txt --extension html This will update hat/locale/fr/LC_MESSAGES/django.po with the new strings to translate. After updating it with the translation you need to following command to have them reflected in the interface: manage.py compilemessages","title":"Translations"},{"location":"pages/dev/how_to/contribute/contribute.html#code-reloading","text":"In development the servers will reload when they detect a file change, either in Python or Javascript. If you need reloading for the bluesquare-components code, see the \"Live Bluesquare Components\" section.","title":"Code reloading"},{"location":"pages/dev/how_to/contribute/contribute.html#troubleshooting","text":"If you need to restart everything docker compose stop && docker compose start If you encounter problems, you can try to rebuild everything from scratch. # kill containers docker compose kill # remove `iaso` container docker compose rm -f iaso # build containers docker compose build # start-up containers docker compose up","title":"Troubleshooting"},{"location":"pages/dev/how_to/contribute/contribute.html#jupyter-notebook","text":"To run a Jupyter Notebook, just copy the env variable from runaisasdev.sh, activate the virtualenv and run python manage.py shell_plus --notebook","title":"Jupyter Notebook"},{"location":"pages/dev/how_to/contribute/contribute.html#testing-prod-js-assets-in-development","text":"During local development, by default, the Javascript and CSS will be loaded from a webpack server with live reloading of the code. To locally test the compiled version as it is in production ( minified and with the same compilation option). You can launch docker compose with the TEST_PROD=true environment variable set. e.g TEST_PROD=true docker compose up This can be useful to reproduce production only bugs. Please also test with this configuration whenever you modify webpack.prod.js to validate your changes. Alternatively this can be done outside of docker by running: npm run webpack-prod to do the build Launching the django server with TEST_PROD e.g. TEST_PROD=true python manage.py runserver .","title":"Testing prod js assets in development"},{"location":"pages/dev/how_to/create_entities_in_web_ui/create_entities_in_web_ui.html","text":"How to create entities in web interface # Use case : develop or test entity related features in the web interface 1. Get some XLS Forms # At least one form will be needed as reference form. More would be optimal as it would allow to test the follow-up feature. 2. Create Forms and form versions # For each XLS form: Open the menu, go to Forms Click the Create button Fill in all mandatory fields and Save Click the Create Version button Use an XLS form to create the version 3. Create one or several EntityType s # From the menu, go to Beneficairies > Beneficiary types Click create Assign one of the created forms as reference form for the benefiacry type Repeat as needed 4. Create submissions for the reference form(s) # Go to Forms > Submissions Using the filters, search for the reference form(s) that were created in the previous step For each form, create a submission Note: To be able to create submissions, Enketo needs to be running. This can be done with the following command: docker compose -f docker-compose.yml -f docker/docker-compose-enketo.yml up 5. Create Entities with the Django admin # Go to `/admin`` Open the Entities menu entry Fill in the mandatory fields Associate one of the newly created submissions to the Entity . It should be a submission for the form defined as reference form for the EntityType of the Entity being created. Save Repeat as needed. 6. Setting up for deduplication # In steps 4 and 5, create at least 2 entities with overlapping data, e.g.: Same or very close names, age etc. The idea is to simulate that 2 Entities were created for the same real world person/object. In a python shell, run: from django.db import connection with connection.cursor() as cursor: cursor.execute('CREATE EXTENSION fuzzystrmatch;') Note: To open a python shell in docker: docker compose exec iaso ./manage.py shell - In a terminal, launch a task worker: docker compose run iaso manage tasks_worker - Go to /api/entityduplicates_analyzes to launch an algorithm analysis (e.g: inverse) - In Iaso web, go to Benefiaries > Duplicates to see if the algorithm matched the duplicates created in previous steps","title":"How to create entities in web interface"},{"location":"pages/dev/how_to/create_entities_in_web_ui/create_entities_in_web_ui.html#how-to-create-entities-in-web-interface","text":"Use case : develop or test entity related features in the web interface","title":"How to create entities in web interface"},{"location":"pages/dev/how_to/create_entities_in_web_ui/create_entities_in_web_ui.html#1-get-some-xls-forms","text":"At least one form will be needed as reference form. More would be optimal as it would allow to test the follow-up feature.","title":"1. Get some XLS Forms"},{"location":"pages/dev/how_to/create_entities_in_web_ui/create_entities_in_web_ui.html#2-create-forms-and-form-versions","text":"For each XLS form: Open the menu, go to Forms Click the Create button Fill in all mandatory fields and Save Click the Create Version button Use an XLS form to create the version","title":"2. Create Forms and form versions"},{"location":"pages/dev/how_to/create_entities_in_web_ui/create_entities_in_web_ui.html#3-create-one-or-several-entitytypes","text":"From the menu, go to Beneficairies > Beneficiary types Click create Assign one of the created forms as reference form for the benefiacry type Repeat as needed","title":"3. Create one or several EntityTypes"},{"location":"pages/dev/how_to/create_entities_in_web_ui/create_entities_in_web_ui.html#4-create-submissions-for-the-reference-forms","text":"Go to Forms > Submissions Using the filters, search for the reference form(s) that were created in the previous step For each form, create a submission Note: To be able to create submissions, Enketo needs to be running. This can be done with the following command: docker compose -f docker-compose.yml -f docker/docker-compose-enketo.yml up","title":"4. Create submissions for the reference form(s)"},{"location":"pages/dev/how_to/create_entities_in_web_ui/create_entities_in_web_ui.html#5-create-entities-with-the-django-admin","text":"Go to `/admin`` Open the Entities menu entry Fill in the mandatory fields Associate one of the newly created submissions to the Entity . It should be a submission for the form defined as reference form for the EntityType of the Entity being created. Save Repeat as needed.","title":"5. Create Entities with the Django admin"},{"location":"pages/dev/how_to/create_entities_in_web_ui/create_entities_in_web_ui.html#6-setting-up-for-deduplication","text":"In steps 4 and 5, create at least 2 entities with overlapping data, e.g.: Same or very close names, age etc. The idea is to simulate that 2 Entities were created for the same real world person/object. In a python shell, run: from django.db import connection with connection.cursor() as cursor: cursor.execute('CREATE EXTENSION fuzzystrmatch;') Note: To open a python shell in docker: docker compose exec iaso ./manage.py shell - In a terminal, launch a task worker: docker compose run iaso manage tasks_worker - Go to /api/entityduplicates_analyzes to launch an algorithm analysis (e.g: inverse) - In Iaso web, go to Benefiaries > Duplicates to see if the algorithm matched the duplicates created in previous steps","title":"6. Setting up for deduplication"},{"location":"pages/dev/how_to/create_registry_in_web_ui/create_registry_in_web_ui.html","text":"How to create registry in web interface # Use case : develop or test registry related features in the web interface 1. Get some Submission # Select a submission you are going to use has reference_instance in an org unit. 2. Get some Org unit # We will use one organization unit and link a reference submission to it. Make sure you choose a org unit having children and that they are all validated. Make also sure that the type of this org unit has sub org unit types, and that those sub types are those used by the children org units. This org unit should have a shape and be visible by the account you are using. Children should also be visible, location (point or shape) is not mandatory. 3. Add reference instance to org unit # Go to `/admin`` Open the Org units menu entry Edit the org unit we choosed at step 2 copy the id of the submission we choosed at step 1 in Reference instance field save 4. Optionnal: create submissions for children # Go to Forms > Submissions Using the filters, search for a form, doesn't need to be a specific one For each children of the main org unit, create a submission Note: To be able to create submissions, Enketo needs to be running. This can be done with the following command: docker compose -f docker-compose.yml -f docker/docker-compose-enketo.yml up 5. Test registry page # Go to Org units > Registry Search for the main org unit we choosed in step 2 Click on View registry You should see the registry page, showing a map of the org unit with the children, the reference instance on the right If you click on list tab, you should see the list of children org units, including those without a location if you completed step 4, you can select the form you used in this step in the dropdown and check that those submissions are present at the bottom of the page You can find an example of registry here on staging. Credentials are in 1Password, look for registry-demo","title":"How to create registry in web interface"},{"location":"pages/dev/how_to/create_registry_in_web_ui/create_registry_in_web_ui.html#how-to-create-registry-in-web-interface","text":"Use case : develop or test registry related features in the web interface","title":"How to create registry in web interface"},{"location":"pages/dev/how_to/create_registry_in_web_ui/create_registry_in_web_ui.html#1-get-some-submission","text":"Select a submission you are going to use has reference_instance in an org unit.","title":"1. Get some Submission"},{"location":"pages/dev/how_to/create_registry_in_web_ui/create_registry_in_web_ui.html#2-get-some-org-unit","text":"We will use one organization unit and link a reference submission to it. Make sure you choose a org unit having children and that they are all validated. Make also sure that the type of this org unit has sub org unit types, and that those sub types are those used by the children org units. This org unit should have a shape and be visible by the account you are using. Children should also be visible, location (point or shape) is not mandatory.","title":"2. Get some Org unit"},{"location":"pages/dev/how_to/create_registry_in_web_ui/create_registry_in_web_ui.html#3-add-reference-instance-to-org-unit","text":"Go to `/admin`` Open the Org units menu entry Edit the org unit we choosed at step 2 copy the id of the submission we choosed at step 1 in Reference instance field save","title":"3. Add reference instance to org unit"},{"location":"pages/dev/how_to/create_registry_in_web_ui/create_registry_in_web_ui.html#4-optionnal-create-submissions-for-children","text":"Go to Forms > Submissions Using the filters, search for a form, doesn't need to be a specific one For each children of the main org unit, create a submission Note: To be able to create submissions, Enketo needs to be running. This can be done with the following command: docker compose -f docker-compose.yml -f docker/docker-compose-enketo.yml up","title":"4. Optionnal: create submissions for children"},{"location":"pages/dev/how_to/create_registry_in_web_ui/create_registry_in_web_ui.html#5-test-registry-page","text":"Go to Org units > Registry Search for the main org unit we choosed in step 2 Click on View registry You should see the registry page, showing a map of the org unit with the children, the reference instance on the right If you click on list tab, you should see the list of children org units, including those without a location if you completed step 4, you can select the form you used in this step in the dropdown and check that those submissions are present at the bottom of the page You can find an example of registry here on staging. Credentials are in 1Password, look for registry-demo","title":"5. Test registry page"},{"location":"pages/dev/how_to/debug_backend/debug_backend.html","text":"Debugging the Backend # Django Debug Toolbar # You can activate the Django Debug Toolbar . To do so, create a hat/local_settings.py files and configure the toolbar. E.g.: from .settings import * # noqa from debug_toolbar.middleware import show_toolbar INSTALLED_APPS += [\"debug_toolbar\"] MIDDLEWARE += [\"debug_toolbar.middleware.DebugToolbarMiddleware\"] def custom_show_toolbar(request): included_urls = [\"/__debug__\", \"/admin\", \"/api\"] included = any(request.path.startswith(url) for url in included_urls) return show_toolbar(request) and included DEBUG_TOOLBAR_CONFIG = { \"DISABLE_PANELS\": [ \"debug_toolbar.panels.redirects.RedirectsPanel\", # ProfilingPanel makes the django admin extremely slow. \"debug_toolbar.panels.profiling.ProfilingPanel\", ], \"SHOW_TEMPLATE_CONTEXT\": True, \"SHOW_TOOLBAR_CALLBACK\": custom_show_toolbar, }","title":"Debugging the Backend"},{"location":"pages/dev/how_to/debug_backend/debug_backend.html#debugging-the-backend","text":"","title":"Debugging the Backend"},{"location":"pages/dev/how_to/debug_backend/debug_backend.html#django-debug-toolbar","text":"You can activate the Django Debug Toolbar . To do so, create a hat/local_settings.py files and configure the toolbar. E.g.: from .settings import * # noqa from debug_toolbar.middleware import show_toolbar INSTALLED_APPS += [\"debug_toolbar\"] MIDDLEWARE += [\"debug_toolbar.middleware.DebugToolbarMiddleware\"] def custom_show_toolbar(request): included_urls = [\"/__debug__\", \"/admin\", \"/api\"] included = any(request.path.startswith(url) for url in included_urls) return show_toolbar(request) and included DEBUG_TOOLBAR_CONFIG = { \"DISABLE_PANELS\": [ \"debug_toolbar.panels.redirects.RedirectsPanel\", # ProfilingPanel makes the django admin extremely slow. \"debug_toolbar.panels.profiling.ProfilingPanel\", ], \"SHOW_TEMPLATE_CONTEXT\": True, \"SHOW_TOOLBAR_CALLBACK\": custom_show_toolbar, }","title":"Django Debug Toolbar"},{"location":"pages/dev/how_to/deploy/deploy.html","text":"0. Make sure everything is there # run the tests check with team mates For IASO deployment make sure you ran eb init with following info eb init Select a default region 5) eu-central-1 : EU (Frankfurt) Select an application to use 4) Iaso Do you wish to continue with CodeCommit? (y/N) (default is n): n 1. Prepare assets # To avoid long/failing deployment, we commit the production assets in the repository git checkout development git pull rm hat/assets/webpack/* npm run webpack-prod git add hat/assets/webpack/ git commit -m 'Committing assets' git push Troubleshooting : npm install : might be needed 2. Deploy to staging # Make sure you have eb installed and run eb init Then you deploy the development branch to staging eb use Iaso-staging eb deploy eb deploy will take of (via container commands see ./.ebextensions/50_container_commands.config) deploying copying the resources and putting them in S3 running the pending migrations Troubleshooting : you might need to dig in the eb activity logs 3. Deploy to production # Technically : we should merge development in master, and deploy master in production but for the momenent use \"just deploy\" to developement to prod eb use Iaso-env eb deploy Check the production Troubleshooting : you might need to dig in the eb activity logs 4. Deploy to playground # For the Playground, deploy as for staging and prod for the web server, but you also need to update the jupyter server (using the pem file you can find on 1password ) Note jupyter is currently using the development branch too. ssh -i ~/.ssh/lightsail.pem ubuntu@18.196.197.98 cd iaso git pull source bin/activate pip install -r requirements.txt killall python nohup ./run.sh & Obviously, a more stable playground setup would be welcome. Troubleshooting : UNPROTECTED PRIVATE KEY FILE! : chmod 600 ~/.ssh/lightsail.pem","title":"Deploy"},{"location":"pages/dev/how_to/deploy/deploy.html#0-make-sure-everything-is-there","text":"run the tests check with team mates For IASO deployment make sure you ran eb init with following info eb init Select a default region 5) eu-central-1 : EU (Frankfurt) Select an application to use 4) Iaso Do you wish to continue with CodeCommit? (y/N) (default is n): n","title":"0. Make sure everything is there"},{"location":"pages/dev/how_to/deploy/deploy.html#1-prepare-assets","text":"To avoid long/failing deployment, we commit the production assets in the repository git checkout development git pull rm hat/assets/webpack/* npm run webpack-prod git add hat/assets/webpack/ git commit -m 'Committing assets' git push Troubleshooting : npm install : might be needed","title":"1. Prepare assets"},{"location":"pages/dev/how_to/deploy/deploy.html#2-deploy-to-staging","text":"Make sure you have eb installed and run eb init Then you deploy the development branch to staging eb use Iaso-staging eb deploy eb deploy will take of (via container commands see ./.ebextensions/50_container_commands.config) deploying copying the resources and putting them in S3 running the pending migrations Troubleshooting : you might need to dig in the eb activity logs","title":"2. Deploy to staging"},{"location":"pages/dev/how_to/deploy/deploy.html#3-deploy-to-production","text":"Technically : we should merge development in master, and deploy master in production but for the momenent use \"just deploy\" to developement to prod eb use Iaso-env eb deploy Check the production Troubleshooting : you might need to dig in the eb activity logs","title":"3. Deploy to production"},{"location":"pages/dev/how_to/deploy/deploy.html#4-deploy-to-playground","text":"For the Playground, deploy as for staging and prod for the web server, but you also need to update the jupyter server (using the pem file you can find on 1password ) Note jupyter is currently using the development branch too. ssh -i ~/.ssh/lightsail.pem ubuntu@18.196.197.98 cd iaso git pull source bin/activate pip install -r requirements.txt killall python nohup ./run.sh & Obviously, a more stable playground setup would be welcome. Troubleshooting : UNPROTECTED PRIVATE KEY FILE! : chmod 600 ~/.ssh/lightsail.pem","title":"4. Deploy to playground"},{"location":"pages/dev/how_to/exclude_featureflag_related_module/exclude_featureflag_related_module.html","text":"How to exclude a featureflag related to a module # 1. Add a new module for which to exclude its related feature flag # Go to /hat/menupermissions/constants.py Add to the dictionnary FEATUREFLAGES_TO_EXCLUDE a new item The key is the name of the module like DATA_COLLECTION_FORMS in capitale letter The value is a list of featureflags(code in capitale letter) to be excluded like [\"FEATUREFLAG_1\",\"FEATUREFLAG_2\"] The whole FEATUREFLAGES_TO_EXCLUDE should be like FEATUREFLAGES_TO_EXCLUDE = { \"MODULE_1\": [\"FEATUREFLAG_1\"], \"MODULE_2\": [\"FEATUREFLAG_2\", \"FEATUREFLAG_3\"],} 2. Add a feature flag to an existing module to be excluded # Go to /hat/menupermissions/constants.py Check the key corresponding to the module Add the featureflag code to the value list of the corresponding module(key)","title":"How to exclude a featureflag related to a module"},{"location":"pages/dev/how_to/exclude_featureflag_related_module/exclude_featureflag_related_module.html#how-to-exclude-a-featureflag-related-to-a-module","text":"","title":"How to exclude a featureflag related to a module"},{"location":"pages/dev/how_to/exclude_featureflag_related_module/exclude_featureflag_related_module.html#1-add-a-new-module-for-which-to-exclude-its-related-feature-flag","text":"Go to /hat/menupermissions/constants.py Add to the dictionnary FEATUREFLAGES_TO_EXCLUDE a new item The key is the name of the module like DATA_COLLECTION_FORMS in capitale letter The value is a list of featureflags(code in capitale letter) to be excluded like [\"FEATUREFLAG_1\",\"FEATUREFLAG_2\"] The whole FEATUREFLAGES_TO_EXCLUDE should be like FEATUREFLAGES_TO_EXCLUDE = { \"MODULE_1\": [\"FEATUREFLAG_1\"], \"MODULE_2\": [\"FEATUREFLAG_2\", \"FEATUREFLAG_3\"],}","title":"1. Add a new module for which to exclude its related feature flag"},{"location":"pages/dev/how_to/exclude_featureflag_related_module/exclude_featureflag_related_module.html#2-add-a-feature-flag-to-an-existing-module-to-be-excluded","text":"Go to /hat/menupermissions/constants.py Check the key corresponding to the module Add the featureflag code to the value list of the corresponding module(key)","title":"2. Add a feature flag to an existing module to be excluded"},{"location":"pages/dev/how_to/manually_test_enketo/manually_test_enketo.html","text":"Manually test Enketo public_create_url # Ensure you have a usable project, form (with form version etc..) and an orgunit in iaso. And Enketo is working. You should be able to make a submission from the web interface. Do it to verify everything Edit the Project in Django admin. And copy the external token It's automatically generated, so you should always have one token='xxxxxxxxx-xxxx-xxxxx-xxxxx-xxxxxxxxx' Still in the admin, take the form_id on the Form (caution: this is an external id, a string, different from the form.id) You should have one if you uploaded a correct FormVersion form_id= 'FORM_ID' On the OrgUnit take the external token: (it's in the dashboard) external_org_unit_id= \"AAAA0000000000\" Make an url with it: f\"/api/enketo/public_create_url/?period={period}&form_id={form_id}&token={token}&external_org_unit_id={external_org_unit_id}\" => '/api/enketo/public_create_url/?period=202301&form_id=FORM_ID&token=xxxxxxxxx-xxxx-xxxxx-xxxxx-xxxxxxxxx&external_org_unit_id=AAAA0000000000' Iaso will return a json with a URL, open it. Fill the form. To test the export, add the to_export=true argument. You will need FormMapping and a DHIS2 configuration to test the full export","title":"Manually test Enketo public_create_url"},{"location":"pages/dev/how_to/manually_test_enketo/manually_test_enketo.html#manually-test-enketo-public_create_url","text":"Ensure you have a usable project, form (with form version etc..) and an orgunit in iaso. And Enketo is working. You should be able to make a submission from the web interface. Do it to verify everything Edit the Project in Django admin. And copy the external token It's automatically generated, so you should always have one token='xxxxxxxxx-xxxx-xxxxx-xxxxx-xxxxxxxxx' Still in the admin, take the form_id on the Form (caution: this is an external id, a string, different from the form.id) You should have one if you uploaded a correct FormVersion form_id= 'FORM_ID' On the OrgUnit take the external token: (it's in the dashboard) external_org_unit_id= \"AAAA0000000000\" Make an url with it: f\"/api/enketo/public_create_url/?period={period}&form_id={form_id}&token={token}&external_org_unit_id={external_org_unit_id}\" => '/api/enketo/public_create_url/?period=202301&form_id=FORM_ID&token=xxxxxxxxx-xxxx-xxxxx-xxxxx-xxxxxxxxx&external_org_unit_id=AAAA0000000000' Iaso will return a json with a URL, open it. Fill the form. To test the export, add the to_export=true argument. You will need FormMapping and a DHIS2 configuration to test the full export","title":"Manually test Enketo public_create_url"},{"location":"pages/dev/how_to/rebuild_front/rebuild_front.html","text":"Rebuilding the Frontend # Docker # Removing Existing Docker Images: # docker rmi -f iaso-webpack:latest Build the new Docker image: # docker compose build --no-cache webpack Local # Removing node_modules: # rm -rf node_modules Clean npm cache: # npm cache clean --force Reinstall npm packages: # npm ci","title":"Rebuilding the Frontend"},{"location":"pages/dev/how_to/rebuild_front/rebuild_front.html#rebuilding-the-frontend","text":"","title":"Rebuilding the Frontend"},{"location":"pages/dev/how_to/rebuild_front/rebuild_front.html#docker","text":"","title":"Docker"},{"location":"pages/dev/how_to/rebuild_front/rebuild_front.html#removing-existing-docker-images","text":"docker rmi -f iaso-webpack:latest","title":"Removing Existing Docker Images:"},{"location":"pages/dev/how_to/rebuild_front/rebuild_front.html#build-the-new-docker-image","text":"docker compose build --no-cache webpack","title":"Build the new Docker image:"},{"location":"pages/dev/how_to/rebuild_front/rebuild_front.html#local","text":"","title":"Local"},{"location":"pages/dev/how_to/rebuild_front/rebuild_front.html#removing-node_modules","text":"rm -rf node_modules","title":"Removing node_modules:"},{"location":"pages/dev/how_to/rebuild_front/rebuild_front.html#clean-npm-cache","text":"npm cache clean --force","title":"Clean npm cache:"},{"location":"pages/dev/how_to/rebuild_front/rebuild_front.html#reinstall-npm-packages","text":"npm ci","title":"Reinstall npm packages:"},{"location":"pages/dev/how_to/run_docs_locally/run_docs_locally.html","text":"How to run this site locally # Clone the repository Start a virtual environment cd to /docs/ Run pip install -r requirements.txt cd to the root folder of iaso Run mkdocs serve","title":"How to run this site locally"},{"location":"pages/dev/how_to/run_docs_locally/run_docs_locally.html#how-to-run-this-site-locally","text":"Clone the repository Start a virtual environment cd to /docs/ Run pip install -r requirements.txt cd to the root folder of iaso Run mkdocs serve","title":"How to run this site locally"},{"location":"pages/dev/how_to/setup_dev_env/setup_dev_env.html","text":"Setup a dev environment # A running local instance for development can be spun up via docker compose which will install and configure all deps in separate container. As such your computer should only need: git docker docker compose If docker compose give you trouble, make sure it can connect to the docker daemon . If you use an Apple Silicon Mac, ensure export DOCKER_DEFAULT_PLATFORM=linux/amd64 is set. A pgdata-iaso folder, containing the database data, will be created in the parent directory of the git repository. 1. Environment variables # The docker-compose.yml file contains sensible defaults for the Django application. Other environment variables can be provided by a .env file . As a starting point, you can copy the sample .env.dist file and edit it to your needs. cp .env.dist .env note: All the commands here need to be run in the project directory in which the repository was cloned 2. Build the containers # This will build and download the containers. docker compose build 3. Start the database # docker compose up db 4. Run migrations # docker compose run --rm iaso manage migrate If you get a message saying that the database iaso does not exist, you can connect to your postgres instance using psql -h localhost -p 5433 -U postgres then type create database iaso; to create the missing database. 5. Start the server # To start all the containers (backend, frontend, db) docker compose up The web server will be reachable at http://localhost:8081 . The docker-compose.yml file describes the setup of the containers. 6. Create a superuser # To login to the app or the Django admin, a superuser needs to be created with: docker compose exec iaso ./manage.py createsuperuser You can now login in the admin at http://localhost:8081/admin . Then additional users with custom groups and permissions can be added through the Django admin or loaded via fixtures. 7. Create and import data # To create the initial account, project and profile, do the following: docker compose exec iaso ./manage.py create_and_import_data You can now login on http://localhost:8081 but still need to import your own data. An alternative to this and the following steps is to import data from DHIS2 . 8. Create a form # Run the following command to create a form: docker compose exec iaso ./manage.py create_form At this point, if you want to edit forms directly on your machine using Enketo, go to the Enketo setup section of this README (down below). Once you are done, you can click on the eye for your newly added form, click on \"+ Create\", tap a letter, then enter, select the org unit, then click \"Create submission\". If Enketo is running and well setup, you can fill the form now. 9. Start adding features # You can now start to develop additional features on Iaso! 10. Import OrgUnit, Forms and Submission from DHIS2 # Alternatively or in addition to steps 7-8, you can import data from the DHIS2 demo server (play.dhis2.org): docker compose run --rm iaso manage seed_test_data --mode=seed --dhis2version=2.35.3 The hierarchy of OrgUnit, group of OrgUnit, Forms, and their Submissions will be imported. OrgUnit types are not handled at the moment Log in to http://127.0.0.1:8081/dashboard with : user : testemail2.35.3 password: testemail2.35.3 11. Enketo # To submit and edit existing form submission from the browser, an Enketo service is needed. To enable the Enketo editor in your local environment, include the additional docker compose configuration file for Enketo. Do so by invoking docker compose with both files. docker compose -f docker-compose.yml -f docker/docker-compose-enketo.yml up No additional configuration is needed. The first time the docker image is launched, it will download dependencies and do a build witch may take a few minutes. Subsequents launches are faster. You can check that the server is correctly launched by going to http://localhost:8005 To seed your DB with typical example forms editable by Enketo, see import data from DHIS2 12. Database dump # To create a copy of your iaso database in a file (dump) you can use: docker compose exec db pg_dump -U postgres iaso -Fc > iaso.dump The dumpfile will be created on your host. The -Fc meant it will use an optimised Postgres format (which take less place). If you want the plain sql command use -Fp 13. Restore database from dump # Ensure the database server is running but not the rest. Close your docker compose, ensure it is down with docker compose down Launch the database server with docker compose up db Choose a name for you database. In this example it will be iaso5 You can list existing databases using docker compose exec db psql -U postgres -l Create the database docker compose exec db psql -U postgres -c \"create database iaso5\" Restore the dump file to put the data in your database cat iaso.dump | docker compose exec -T db pg_restore -U postgres -d iaso5 -Fc --no-owner /dev/stdin Edit your .env file to use to this database in the RDS_DB_NAME settings. Start Iaso. Cut your docker compose (see 0) and relaunch it fully. Warning: Modification in your .env file are not taken into account unless you entirely stop your docker compose 14. Health # On the /health/ url you can find listed the Iaso version number, environment, deployment time, etc... that might help you understand how this server instance is deployed for debugging. e.g. https://iaso.bluesquare.org/health/ 15. Set up a local DHIS2 server # Experimental. For development if you need a local dhis2 server, you can spin up one in your docker compose by using the docker/docker-compose-dhis2.yml configuration file. Replace your invocations of docker compose by docker compose -f docker-compose.yml -f docker/docker-compose-dhis2.yml you need to specify both config files. e.g to launch the cluster: docker compose -f docker-compose.yml -f docker/docker-compose-dhis2.yml up The DHIS2 will be available on your computer on http://localhost:8080 and is reachable from Iaso as http://dhis2:8080. The login and password are admin / district. If you use it as an import source do not set a trailing / Database file are stored in ../pgdata-dhis2 and dhis2 log and uploaded files in docker/DHIS2_home . 16. Sample dhis2 database # You will probably require some sample data in your instance. It is possible to populate your DHIS2 server with sample data from a database dump like it's done for the official play servers. The DHIS2 database take around 3 GB. The steps as are follow: Download the file, stop all the docker, remove the postgres database directory, start only the database docker, load the database dump and then restart everything. wget https://databases.dhis2.org/sierra-leone/2.36.4/dhis2-db-sierra-leone.sql.gz docker compose down sudo rm ../pgdata-dhis2 -r docker compose up db_dhis2 zcat dhis2-db-sierra-leone.sql.gz| docker compose exec -T db_dhis2 psql -U dhis dhis2 -f /dev/stdin docker compose up cd Projects/blsq/iaso docker compose up dhis2 db_dhis2 17. Set up Single Sign On (SSO) with a local DHIS2 # If you want to test the feature with your local dhis2 you can use the following step. This assume you are running everything in Docker containers Launch DHIS2 with iaso within docker compose docker compose -f docker-compose.yml -f docker/docker-compose-dhis2.yml up With the default docker compose setup, iaso is on port 8081 and dhis2 on port 8081 on your machine These step assume you have loaded your DHIS2 with the play test data but it's not mandatory. To see how to do it, look at previous section Configure an Oauth client in DHIS2: open http://localhost:8080/dhis-web-settings/index.html#/oauth2 Add new client: Name : what you want ClientId: What you want (must be the same as your external credential in Iaso) Client Secret : there is one generated, copy it and save it for a latter step Grant Type: check Authorization code Redirect URI : http://localhost:8081/api/dhis2/{same as client id}/login/ Setup external credential in iaso open admin http://localhost:8081/admin/ go to External Credentials | http://localhost:8081/admin/iaso/externalcredentials/ Add external credentials on the top right | http://localhost:8081/admin/iaso/externalcredentials/add/ Account: The account for which you want to enable dhis2 auth Name : Same as DHIS2 Client ID Login : http://dhis2:8080/ Password: the client secret you saved in step 2 Url: http://localhost:8081/ 5 Create a new user in Iaso, grant it some rights In DHIS2 retrieve the id for the user Current way I have found it is to go to http://localhost:8080/api/me and copy the id field But you can also find a user here and it's in the url http://localhost:8080/dhis-web-user/index.html#/users Add the dhis2 id to the Iaso user : Open the target user in the iaso Admin http://localhost:8081/admin/iaso/profile/ and add it to the dhis2 id field, save. Unlog from iaso or in a separate session/container Try the feature by opening : http://localhost:8080/uaa/oauth/authorize?client_id={your_dhis2_client_id}&response_type=code 18. Test forms from Iaso mobile application # 1 - Setup Ngrok # Download and setup Ngrok on https://ngrok.com/. Once Ngrok installed and running you must add your ngrok server url in settings.py by adding the following line : FILE_SERVER_URL = os.environ.get(\"FILE_SERVER_URL\", \"YOUR_NGROK_SERVER_URL\") After this step you have to import settings.py and add FILE_SERVER_URL to forms.py in iaso/models/forms as shown on the following lines : \"file\": settings.FILE_SERVER_URL + self.file.url, \"xls_file\": settings.FILE_SERVER_URL + self.xls_file.url if self.xls_file else None 2 - Setup the mobile app # Once Ngrok installed and running you have to run the app in developer mode (tap 10 times on the Iaso icon at start ) and connect the mobile app to your server by selecting the 3 dots in the top right corner and select \"change server url\". When connected to your server, refresh all data and your app will be ready and connected to your development server. 19. SSO with DHIS2 # You can use DHIS2 as identity provider to login on Iaso. It requires a little configuration on DHIS2 and Iaso in order to achieve that. 1 - Setup OAuth2 clients in DHIS2 # In DHIS2 settings you must setup your Iaso instance as Oauth2 Clients. Client ID and Grant types must be : * Client ID : What you want (Must be the same as your external credential name in Iaso) * Grant Types : Authorization code Redirect URIs is your iaso server followed by : /api/dhis2/{your_dhis2_client_id}/login/ For example : https://myiaso.com/api/dhis2/dhis2_client_id/login/ 2 - Configure the OAuth2 connection in Iaso # In iaso you must setup your dhis2 server credentials. To do so, go to /admin and setup as follow : Name: {your_dhis2_client_id} ( It must be exactly as it is in your DHIS2 client_id and DHIS2 Redirect URIs) Login: Your DHIS2 url (Ex : https://sandbox.dhis2.org/ ) Password: The secret provided by DHIS2 when you created your OAuth2 client. Url: Your Iaso Url (Ex: https://myiaso.com/) Don't forget the / at the end of the urls. 3. Workflow for Single Sign On as a sequence diagram # sequenceDiagram autonumber Note right of Browser: user open url to login Browser->>DHIS2: GET /uaa/oauth/authorize<br>?client_id={your_dhis2_client_id} loop if not logged DHIS2->>Browser: Login screen Browser->>DHIS2: Enter credentials DHIS2->>Browser: Login ok end DHIS2 -->> Browser: 200 Authorize Iaso? Authorize/Deny Browser ->> DHIS2: POST /authorize DHIS2 -->> Browser: 303 redirect Browser ->> IASO: GET /api/dhis2/<dhis2_slug>/login/?code= IASO ->> DHIS2: POST /uaa/oauth/token/ DHIS2 -->> IASO: access token IASO ->> DHIS2 : GET /api/me DHIS2 -->> IASO: credential info Note right of IASO: find matching IASO user Note right of IASO: Log in session IASO -->> Browser: 303 Redirect & set cookies Browser ->> IASO: Use iaso normally as logged user. 20.Live Bluesquare components # It is possible to configure the project to load a version of Bluesquare components from a local git repository instead of the one installed from a package. This enabled to develop feature necessitating modification in the components code. To do so: * place the repository in the parent repository of Iaso ../bluesquare-components/ * install the dependency for bluesquare-component by running npm install in its directory * set the environment variable LIVE_COMPONENTS=true * start your docker compose cd .. git clone git@github.com:BLSQ/bluesquare-components.git cd bluesquare-components npm install cd ../iaso LIVE_COMPONENTS=true docker compose up This way the page will reload automatically if you make a change to the bluesquare-components code. This functionality also works if you launch webpack outside of docker. If you encounter any problem, first check that your repo is on the correct branch and the deps are up-to-date 21. Task worker # In local development, you can run a worker for background tasks by using the command: docker compose run iaso manage tasks_worker Alternatively, you can call the url tasks/run_all which will run all the pending tasks in queue. 22. Customization # You can override default application title, logo and colors using the .env file and specify those variables: THEME_PRIMARY_COLOR=\"<hexa_color>\" THEME_PRIMARY_BACKGROUND_COLOR=\"<hexa_color>\" THEME_SECONDARY_COLOR=\"<hexa_color>\" APP_TITLE=\"<app_title>\" FAVICON_PATH=\"<path_in_static_folder>\" LOGO_PATH=\"<path_in_static_folder>\" SHOW_NAME_WITH_LOGO=\"<'yes' or 'no'>\" Those settings are optional and are using a default value if nothing is provided","title":"Setup a dev environment"},{"location":"pages/dev/how_to/setup_dev_env/setup_dev_env.html#setup-a-dev-environment","text":"A running local instance for development can be spun up via docker compose which will install and configure all deps in separate container. As such your computer should only need: git docker docker compose If docker compose give you trouble, make sure it can connect to the docker daemon . If you use an Apple Silicon Mac, ensure export DOCKER_DEFAULT_PLATFORM=linux/amd64 is set. A pgdata-iaso folder, containing the database data, will be created in the parent directory of the git repository.","title":"Setup a dev environment"},{"location":"pages/dev/how_to/setup_dev_env/setup_dev_env.html#1-environment-variables","text":"The docker-compose.yml file contains sensible defaults for the Django application. Other environment variables can be provided by a .env file . As a starting point, you can copy the sample .env.dist file and edit it to your needs. cp .env.dist .env note: All the commands here need to be run in the project directory in which the repository was cloned","title":"1. Environment variables"},{"location":"pages/dev/how_to/setup_dev_env/setup_dev_env.html#2-build-the-containers","text":"This will build and download the containers. docker compose build","title":"2. Build the containers"},{"location":"pages/dev/how_to/setup_dev_env/setup_dev_env.html#3-start-the-database","text":"docker compose up db","title":"3. Start the database"},{"location":"pages/dev/how_to/setup_dev_env/setup_dev_env.html#4-run-migrations","text":"docker compose run --rm iaso manage migrate If you get a message saying that the database iaso does not exist, you can connect to your postgres instance using psql -h localhost -p 5433 -U postgres then type create database iaso; to create the missing database.","title":"4. Run migrations"},{"location":"pages/dev/how_to/setup_dev_env/setup_dev_env.html#5-start-the-server","text":"To start all the containers (backend, frontend, db) docker compose up The web server will be reachable at http://localhost:8081 . The docker-compose.yml file describes the setup of the containers.","title":"5. Start the server"},{"location":"pages/dev/how_to/setup_dev_env/setup_dev_env.html#6-create-a-superuser","text":"To login to the app or the Django admin, a superuser needs to be created with: docker compose exec iaso ./manage.py createsuperuser You can now login in the admin at http://localhost:8081/admin . Then additional users with custom groups and permissions can be added through the Django admin or loaded via fixtures.","title":"6. Create a superuser"},{"location":"pages/dev/how_to/setup_dev_env/setup_dev_env.html#7-create-and-import-data","text":"To create the initial account, project and profile, do the following: docker compose exec iaso ./manage.py create_and_import_data You can now login on http://localhost:8081 but still need to import your own data. An alternative to this and the following steps is to import data from DHIS2 .","title":"7. Create and import data"},{"location":"pages/dev/how_to/setup_dev_env/setup_dev_env.html#8-create-a-form","text":"Run the following command to create a form: docker compose exec iaso ./manage.py create_form At this point, if you want to edit forms directly on your machine using Enketo, go to the Enketo setup section of this README (down below). Once you are done, you can click on the eye for your newly added form, click on \"+ Create\", tap a letter, then enter, select the org unit, then click \"Create submission\". If Enketo is running and well setup, you can fill the form now.","title":"8. Create a form"},{"location":"pages/dev/how_to/setup_dev_env/setup_dev_env.html#9-start-adding-features","text":"You can now start to develop additional features on Iaso!","title":"9. Start adding features"},{"location":"pages/dev/how_to/setup_dev_env/setup_dev_env.html#10-import-orgunit-forms-and-submission-from-dhis2","text":"Alternatively or in addition to steps 7-8, you can import data from the DHIS2 demo server (play.dhis2.org): docker compose run --rm iaso manage seed_test_data --mode=seed --dhis2version=2.35.3 The hierarchy of OrgUnit, group of OrgUnit, Forms, and their Submissions will be imported. OrgUnit types are not handled at the moment Log in to http://127.0.0.1:8081/dashboard with : user : testemail2.35.3 password: testemail2.35.3","title":"10. Import OrgUnit, Forms and Submission from DHIS2"},{"location":"pages/dev/how_to/setup_dev_env/setup_dev_env.html#11-enketo","text":"To submit and edit existing form submission from the browser, an Enketo service is needed. To enable the Enketo editor in your local environment, include the additional docker compose configuration file for Enketo. Do so by invoking docker compose with both files. docker compose -f docker-compose.yml -f docker/docker-compose-enketo.yml up No additional configuration is needed. The first time the docker image is launched, it will download dependencies and do a build witch may take a few minutes. Subsequents launches are faster. You can check that the server is correctly launched by going to http://localhost:8005 To seed your DB with typical example forms editable by Enketo, see import data from DHIS2","title":"11. Enketo"},{"location":"pages/dev/how_to/setup_dev_env/setup_dev_env.html#12-database-dump","text":"To create a copy of your iaso database in a file (dump) you can use: docker compose exec db pg_dump -U postgres iaso -Fc > iaso.dump The dumpfile will be created on your host. The -Fc meant it will use an optimised Postgres format (which take less place). If you want the plain sql command use -Fp","title":"12. Database dump"},{"location":"pages/dev/how_to/setup_dev_env/setup_dev_env.html#13-restore-database-from-dump","text":"Ensure the database server is running but not the rest. Close your docker compose, ensure it is down with docker compose down Launch the database server with docker compose up db Choose a name for you database. In this example it will be iaso5 You can list existing databases using docker compose exec db psql -U postgres -l Create the database docker compose exec db psql -U postgres -c \"create database iaso5\" Restore the dump file to put the data in your database cat iaso.dump | docker compose exec -T db pg_restore -U postgres -d iaso5 -Fc --no-owner /dev/stdin Edit your .env file to use to this database in the RDS_DB_NAME settings. Start Iaso. Cut your docker compose (see 0) and relaunch it fully. Warning: Modification in your .env file are not taken into account unless you entirely stop your docker compose","title":"13. Restore database from dump"},{"location":"pages/dev/how_to/setup_dev_env/setup_dev_env.html#14-health","text":"On the /health/ url you can find listed the Iaso version number, environment, deployment time, etc... that might help you understand how this server instance is deployed for debugging. e.g. https://iaso.bluesquare.org/health/","title":"14. Health"},{"location":"pages/dev/how_to/setup_dev_env/setup_dev_env.html#15-set-up-a-local-dhis2-server","text":"Experimental. For development if you need a local dhis2 server, you can spin up one in your docker compose by using the docker/docker-compose-dhis2.yml configuration file. Replace your invocations of docker compose by docker compose -f docker-compose.yml -f docker/docker-compose-dhis2.yml you need to specify both config files. e.g to launch the cluster: docker compose -f docker-compose.yml -f docker/docker-compose-dhis2.yml up The DHIS2 will be available on your computer on http://localhost:8080 and is reachable from Iaso as http://dhis2:8080. The login and password are admin / district. If you use it as an import source do not set a trailing / Database file are stored in ../pgdata-dhis2 and dhis2 log and uploaded files in docker/DHIS2_home .","title":"15. Set up a local DHIS2 server"},{"location":"pages/dev/how_to/setup_dev_env/setup_dev_env.html#16-sample-dhis2-database","text":"You will probably require some sample data in your instance. It is possible to populate your DHIS2 server with sample data from a database dump like it's done for the official play servers. The DHIS2 database take around 3 GB. The steps as are follow: Download the file, stop all the docker, remove the postgres database directory, start only the database docker, load the database dump and then restart everything. wget https://databases.dhis2.org/sierra-leone/2.36.4/dhis2-db-sierra-leone.sql.gz docker compose down sudo rm ../pgdata-dhis2 -r docker compose up db_dhis2 zcat dhis2-db-sierra-leone.sql.gz| docker compose exec -T db_dhis2 psql -U dhis dhis2 -f /dev/stdin docker compose up cd Projects/blsq/iaso docker compose up dhis2 db_dhis2","title":"16. Sample dhis2 database"},{"location":"pages/dev/how_to/setup_dev_env/setup_dev_env.html#17-set-up-single-sign-on-sso-with-a-local-dhis2","text":"If you want to test the feature with your local dhis2 you can use the following step. This assume you are running everything in Docker containers Launch DHIS2 with iaso within docker compose docker compose -f docker-compose.yml -f docker/docker-compose-dhis2.yml up With the default docker compose setup, iaso is on port 8081 and dhis2 on port 8081 on your machine These step assume you have loaded your DHIS2 with the play test data but it's not mandatory. To see how to do it, look at previous section Configure an Oauth client in DHIS2: open http://localhost:8080/dhis-web-settings/index.html#/oauth2 Add new client: Name : what you want ClientId: What you want (must be the same as your external credential in Iaso) Client Secret : there is one generated, copy it and save it for a latter step Grant Type: check Authorization code Redirect URI : http://localhost:8081/api/dhis2/{same as client id}/login/ Setup external credential in iaso open admin http://localhost:8081/admin/ go to External Credentials | http://localhost:8081/admin/iaso/externalcredentials/ Add external credentials on the top right | http://localhost:8081/admin/iaso/externalcredentials/add/ Account: The account for which you want to enable dhis2 auth Name : Same as DHIS2 Client ID Login : http://dhis2:8080/ Password: the client secret you saved in step 2 Url: http://localhost:8081/ 5 Create a new user in Iaso, grant it some rights In DHIS2 retrieve the id for the user Current way I have found it is to go to http://localhost:8080/api/me and copy the id field But you can also find a user here and it's in the url http://localhost:8080/dhis-web-user/index.html#/users Add the dhis2 id to the Iaso user : Open the target user in the iaso Admin http://localhost:8081/admin/iaso/profile/ and add it to the dhis2 id field, save. Unlog from iaso or in a separate session/container Try the feature by opening : http://localhost:8080/uaa/oauth/authorize?client_id={your_dhis2_client_id}&response_type=code","title":"17. Set up Single Sign On (SSO) with a local DHIS2"},{"location":"pages/dev/how_to/setup_dev_env/setup_dev_env.html#18-test-forms-from-iaso-mobile-application","text":"","title":"18. Test forms from Iaso mobile application"},{"location":"pages/dev/how_to/setup_dev_env/setup_dev_env.html#1-setup-ngrok","text":"Download and setup Ngrok on https://ngrok.com/. Once Ngrok installed and running you must add your ngrok server url in settings.py by adding the following line : FILE_SERVER_URL = os.environ.get(\"FILE_SERVER_URL\", \"YOUR_NGROK_SERVER_URL\") After this step you have to import settings.py and add FILE_SERVER_URL to forms.py in iaso/models/forms as shown on the following lines : \"file\": settings.FILE_SERVER_URL + self.file.url, \"xls_file\": settings.FILE_SERVER_URL + self.xls_file.url if self.xls_file else None","title":"1 - Setup Ngrok"},{"location":"pages/dev/how_to/setup_dev_env/setup_dev_env.html#2-setup-the-mobile-app","text":"Once Ngrok installed and running you have to run the app in developer mode (tap 10 times on the Iaso icon at start ) and connect the mobile app to your server by selecting the 3 dots in the top right corner and select \"change server url\". When connected to your server, refresh all data and your app will be ready and connected to your development server.","title":"2 - Setup the mobile app"},{"location":"pages/dev/how_to/setup_dev_env/setup_dev_env.html#19-sso-with-dhis2","text":"You can use DHIS2 as identity provider to login on Iaso. It requires a little configuration on DHIS2 and Iaso in order to achieve that.","title":"19. SSO with DHIS2"},{"location":"pages/dev/how_to/setup_dev_env/setup_dev_env.html#1-setup-oauth2-clients-in-dhis2","text":"In DHIS2 settings you must setup your Iaso instance as Oauth2 Clients. Client ID and Grant types must be : * Client ID : What you want (Must be the same as your external credential name in Iaso) * Grant Types : Authorization code Redirect URIs is your iaso server followed by : /api/dhis2/{your_dhis2_client_id}/login/ For example : https://myiaso.com/api/dhis2/dhis2_client_id/login/","title":"1 - Setup OAuth2 clients in DHIS2"},{"location":"pages/dev/how_to/setup_dev_env/setup_dev_env.html#2-configure-the-oauth2-connection-in-iaso","text":"In iaso you must setup your dhis2 server credentials. To do so, go to /admin and setup as follow : Name: {your_dhis2_client_id} ( It must be exactly as it is in your DHIS2 client_id and DHIS2 Redirect URIs) Login: Your DHIS2 url (Ex : https://sandbox.dhis2.org/ ) Password: The secret provided by DHIS2 when you created your OAuth2 client. Url: Your Iaso Url (Ex: https://myiaso.com/) Don't forget the / at the end of the urls.","title":"2 - Configure the OAuth2 connection in Iaso"},{"location":"pages/dev/how_to/setup_dev_env/setup_dev_env.html#3-workflow-for-single-sign-on-as-a-sequence-diagram","text":"sequenceDiagram autonumber Note right of Browser: user open url to login Browser->>DHIS2: GET /uaa/oauth/authorize<br>?client_id={your_dhis2_client_id} loop if not logged DHIS2->>Browser: Login screen Browser->>DHIS2: Enter credentials DHIS2->>Browser: Login ok end DHIS2 -->> Browser: 200 Authorize Iaso? Authorize/Deny Browser ->> DHIS2: POST /authorize DHIS2 -->> Browser: 303 redirect Browser ->> IASO: GET /api/dhis2/<dhis2_slug>/login/?code= IASO ->> DHIS2: POST /uaa/oauth/token/ DHIS2 -->> IASO: access token IASO ->> DHIS2 : GET /api/me DHIS2 -->> IASO: credential info Note right of IASO: find matching IASO user Note right of IASO: Log in session IASO -->> Browser: 303 Redirect & set cookies Browser ->> IASO: Use iaso normally as logged user.","title":"3. Workflow for Single Sign On as a sequence diagram"},{"location":"pages/dev/how_to/setup_dev_env/setup_dev_env.html#20live-bluesquare-components","text":"It is possible to configure the project to load a version of Bluesquare components from a local git repository instead of the one installed from a package. This enabled to develop feature necessitating modification in the components code. To do so: * place the repository in the parent repository of Iaso ../bluesquare-components/ * install the dependency for bluesquare-component by running npm install in its directory * set the environment variable LIVE_COMPONENTS=true * start your docker compose cd .. git clone git@github.com:BLSQ/bluesquare-components.git cd bluesquare-components npm install cd ../iaso LIVE_COMPONENTS=true docker compose up This way the page will reload automatically if you make a change to the bluesquare-components code. This functionality also works if you launch webpack outside of docker. If you encounter any problem, first check that your repo is on the correct branch and the deps are up-to-date","title":"20.Live Bluesquare components"},{"location":"pages/dev/how_to/setup_dev_env/setup_dev_env.html#21-task-worker","text":"In local development, you can run a worker for background tasks by using the command: docker compose run iaso manage tasks_worker Alternatively, you can call the url tasks/run_all which will run all the pending tasks in queue.","title":"21. Task worker"},{"location":"pages/dev/how_to/setup_dev_env/setup_dev_env.html#22-customization","text":"You can override default application title, logo and colors using the .env file and specify those variables: THEME_PRIMARY_COLOR=\"<hexa_color>\" THEME_PRIMARY_BACKGROUND_COLOR=\"<hexa_color>\" THEME_SECONDARY_COLOR=\"<hexa_color>\" APP_TITLE=\"<app_title>\" FAVICON_PATH=\"<path_in_static_folder>\" LOGO_PATH=\"<path_in_static_folder>\" SHOW_NAME_WITH_LOGO=\"<'yes' or 'no'>\" Those settings are optional and are using a default value if nothing is provided","title":"22. Customization"},{"location":"pages/dev/how_to/setup_dev_env/setuper.html","text":"Setuper # Introduction # The setuper.py script: kickstarts a fully working Iaso environment by generating contents for the database using the Iaso API It will: generate a random account name create the corresponding account, data source, source version, first user import an org unit sample import a test form create a few submissions of this form create a few entities Once the script has run, you can log in to your server using the account name as login and password. How To Use # Backup your DB docker compose exec db pg_dump -U postgres iaso -Fc > ~/Desktop/iaso.dump Use an empty DB # Find your Iaso DB. docker compose exec db psql -U postgres -l # Delete your Iaso DB. docker compose exec db psql -U postgres -c \"drop database if exists iaso\" # Create your Iaso DB. docker compose exec db psql -U postgres -c \"create database iaso\" Run the Django server in a first terminal (this will run DB migrations) docker compose up iaso Run a worker in a second terminal docker compose run iaso manage tasks_worker Create a superuser docker compose exec iaso ./manage.py createsuperuser Prepare the setuper (it requires a local Python 3) cd setuper Create a virtual env for your local Python: python3 -m venv venv source venv/bin/activate Install requirements: pip install -r requirements.txt Update credentials.py because we need a user with API access (use your superuser credentials) cp data/sample-credentials.py credentials.py Run the setuper python3 setuper.py","title":"Setuper"},{"location":"pages/dev/how_to/setup_dev_env/setuper.html#setuper","text":"","title":"Setuper"},{"location":"pages/dev/how_to/setup_dev_env/setuper.html#introduction","text":"The setuper.py script: kickstarts a fully working Iaso environment by generating contents for the database using the Iaso API It will: generate a random account name create the corresponding account, data source, source version, first user import an org unit sample import a test form create a few submissions of this form create a few entities Once the script has run, you can log in to your server using the account name as login and password.","title":"Introduction"},{"location":"pages/dev/how_to/setup_dev_env/setuper.html#how-to-use","text":"Backup your DB docker compose exec db pg_dump -U postgres iaso -Fc > ~/Desktop/iaso.dump Use an empty DB # Find your Iaso DB. docker compose exec db psql -U postgres -l # Delete your Iaso DB. docker compose exec db psql -U postgres -c \"drop database if exists iaso\" # Create your Iaso DB. docker compose exec db psql -U postgres -c \"create database iaso\" Run the Django server in a first terminal (this will run DB migrations) docker compose up iaso Run a worker in a second terminal docker compose run iaso manage tasks_worker Create a superuser docker compose exec iaso ./manage.py createsuperuser Prepare the setuper (it requires a local Python 3) cd setuper Create a virtual env for your local Python: python3 -m venv venv source venv/bin/activate Install requirements: pip install -r requirements.txt Update credentials.py because we need a user with API access (use your superuser credentials) cp data/sample-credentials.py credentials.py Run the setuper python3 setuper.py","title":"How To Use"},{"location":"pages/dev/how_to/use_iaso_apis/use_iaso_apis.html","text":"It's a relatively standard json based API built using the Django Rest Framework. Here is a sample Python script showing how to fetch your list of submissions: import os import requests # API setup server = \"https://iaso.bluesquare.org\" creds = { \"username\": USERNAME, \"password\": PASSWORD } instances_endpoint = server + \"/api/instances/\" # get API token r = requests.post(server + \"/api/token/\", json=creds) token = r.json().get('access') headers = {\"Authorization\": \"Bearer %s\" % token} # request submissions data r = requests.get(instances_endpoint, headers=headers) j = r.json() Most endpoints of Iaso provide exports to csv through the mechanisms provided by the Django Rest Framework (by adding format=csv to the url) and some of them provide exports to xlsx ( xlsx=true ) and geopackage ( gpkg=true ) formats.","title":"Use iaso apis"},{"location":"pages/dev/how_to/write_visit_on_nfc/write_visit_on_nfc.html","text":"Forewords # In the context of CODA2, Iaso will have to write some forms\u2019 information on an NFC card. The NFC card\u2019s size may vary in the future, but the current size of the card is 8k. Yet, the card is currently split into two partitions; one is used by CODA and the other by SCOPE. SCOPE has 6kB out of the 8, leaving 2kB to CODA. Famoco provided the implementation for the CODA 1.5 application. We know that the patient\u2019s profile can take up to 500B, and the subsequent visits can take up to 144B with a total of 8 visits maximum. This gives us a total of 1652B if all slots are filled. I assume that the remaining 396B (2048 - 1652) is the encryption overhead. Assuming Famoco is using an AES/CBC symmetric encryption with a salt of 256B and an IV (initialization vector) of 16B over the whole data, the assumption would hold. Famoco\u2019s split # In the documentation provided by Famoco, called DESFireService_v1.0.1 , they mention two types of writing: File \u201c01\u201d, which we\u2019ll call the profile, is up to 500B File \u201c02\u201d, which we\u2019ll call the visits, is of variable length based > on the type of card used. The profile is marked as a binary file overridden on each writing. The visits are marked as a cyclic record. Every time a visit is recorded, it is added to the previous ones. If the max length is reached, the oldest record is deleted to make room for the new one (FIFO). \u2753 It is yet to be defined if a model outside of Famoco should follow the same split and enforce the writing of one record at a time. NDEF Messages and NDEF Records # N FC D ata E xchange F ormat (or NDEF) is a lightweight binary format, used to encapsulate typed data. It is specified by the NFC Forum, for transmission and storage with NFC. However, it is transport agnostic. The format defines Messages and Records: An NDEF Record contains typed data, such as MIME-type media, a URI, > or a custom application payload. An NDEF Message is a container for one or more NDEF Records. Why use NDEF? # As described in the Android documentation , It is mandatory for all Android devices with NFC to correctly enumerate Ndef on NFC Forum Tag Types 1-4, and implement all NDEF operations as defined in said documentation. Therefore, it guarantees that a perfectly written tag will be readable by all Android devices with NFC. Finally, the overhead of NDEF is existent but can be considered negligible compared to the advantages it brings. Based on this StackOverflow answer , the overhead is roughly 12 bytes: NDEF Header byte: 1 byte NDEF type length field: 1 byte NDEF payload length field: 1-4 bytes NDEF type name \"iaso:p\" (external type): 6 bytes Encryption # Famoco\u2019s devices are relying on a S ecure A ccess M odule (or SAM) chip which encrypts and guarantees a secured shared secret across the authorized devices. Unfortunately, regular Android devices can't rely on such a chip. Therefore, we must find a solution to encrypt the card's data in a way only decipherable by another authorized device without an internet connection. Since all the authorized devices will need to be able to encrypt and decrypt the data, there is no need to go with asymmetric encryption. The current standard for symmetric encryption is AES. The overhead # As explained in this StackOverflow answer , AES doesn\u2019t expand data, but the padding will. The maximum amount of padding is up to the padding algorithm. In the case of PKCS7Padding , it should be up to 16 bytes as defined in the RFC3602 . On top of that, it\u2019s good practice to salt the password to make the deciphering even more complex, avoid rainbow tables attacks, and avoid being able to compare two identical records (which is more likely to happen with small forms). AES also comes with the concept of I nitialization V ector (or IV) randomly generated on each encryption. The salt and the IV will be communicated in clear text alongside the encrypted data to be able to decrypt it. Therefore, they will add up to the number of bytes written on the card. \ud83d\udd10 As advised by the N ational I nstitute of S tandards and T echnology (NIST), the length of the randomly-generated portion of the salt shall be at least 128 bits (16 bytes) . In the current PoC implementation, it\u2019s 256 bytes. \ud83d\udd10 AES requires an IV size of 16 bytes The total overhead is therefore of the size of the salt (256B), the size of the IV (16B), and the padding (up to 16B), which sums up to 288B but could be lowered to 48B if we reduce the salt to 16B for lesser security. How the data is split # The overhead discussed previously is computed per encryption; if we encrypt all the data at once, the overhead is of that amount. If we encrypt the profile and the visits separately, the overhead is multiplied by two. The overhead is much higher if we encrypt the profile and each visit individually. \ud83d\udd10 I don\u2019t have sufficient knowledge to tell if there is any security benefit in one or the other approach. Yet, based on the size of the available space on the card, I assume we should encrypt all the data at once or encrypt the profile and the visits separately but not all the visits apiece. Sharing the NFC password securely # Every security measure is as strong as its weakest link. The whole encryption mechanism is rendered useless if the password is too weak, easily guessable, or easily accessible. Therefore, we need to find a good way to share the password while considering the complexity for the end user to obtain it. \ud83d\ude08 Keep in mind that nothing is 100% secure. All the solutions we could come up with have flaws, even the SAM chip used by Famoco. Yet, we can only make it harder and harder for someone to retrieve the key to the point that they either can\u2019t retrieve it (missing skills or hardware) or don\u2019t find that it is worth their while. Embedded inside the APK # The easiest way to share a password across authorized devices is to embed it directly into the APK (an APK is a file containing the code and resources of an application that an Android device can interpret to install it). Yet, this solution is only viable if, and only if , the APK is distributed via a M obile D evice M anagement (or MDM) and that the MDM can securely prevent people from retrieving the APK from the device. If the APK is distributed via the Play Store (or any other means that is publicly available or that allow retrieving the APK), the password must be considered compromised and rendered useless. This solution is similar to what Famoco is doing since, in their case, the password is embedded and secured inside the SAM chip. Over the network # This solution is easy for the end user, but more vulnerable as anyone can make a network request. The client should make an authorized (given a valid token previously retrieved with valid credentials) request to a specific endpoint. The endpoint would receive a public key (from an asymmetric encryption scheme like RSA) of a hardware-backed key pair as described in Android\u2019s documentation . The backend would be able to verify the validity of the key and its certificate chain, pointing to a Google valid certificate, and containing the correct application ID and signature. The password would then be encrypted by the backend with the public key and communicated back to the phone. The application should then be able to decrypt the password and store it securely. This solution involves that only the application can decrypt the given password. \ud83d\udd11 This is the investigated solution at the moment of this writing but we are unsure how secure this would be on a rooted Android device. This solution involves security measures that can be hard for attackers to obtain: Valid credentials A compromised phone with the application on it. A way to compromise the device in a way it is not detected by > Android. Over a physical device # If the password is stored inside a physical device (like a USB key, a specific phone application, etc.) that is provided in limited quantities to trusted members of the organization, it can be shared through physical contact between the device to authorize and the trusted member with the physical device. The password is then securely stored on the authorized device for later use. This solution is secure but could be cumbersome. For example, if there are many devices to authorize, it can take a long time to transfer the password on each device. There could also be an issue if the devices are spread across the country, and the trusted members must go to each location to authorize the devices. A mix of the above solutions # The solutions provided above are not exhaustive and can also be mixed. For example, we could consider storing the password on a physical device to be encrypted with a key that needs to be retrieved via an authorized network request. The more barrier we put in recovering the key, the more secure it is. Yet, it also makes the logistics for genuine authorized devices more complex.","title":"Forewords"},{"location":"pages/dev/how_to/write_visit_on_nfc/write_visit_on_nfc.html#forewords","text":"In the context of CODA2, Iaso will have to write some forms\u2019 information on an NFC card. The NFC card\u2019s size may vary in the future, but the current size of the card is 8k. Yet, the card is currently split into two partitions; one is used by CODA and the other by SCOPE. SCOPE has 6kB out of the 8, leaving 2kB to CODA. Famoco provided the implementation for the CODA 1.5 application. We know that the patient\u2019s profile can take up to 500B, and the subsequent visits can take up to 144B with a total of 8 visits maximum. This gives us a total of 1652B if all slots are filled. I assume that the remaining 396B (2048 - 1652) is the encryption overhead. Assuming Famoco is using an AES/CBC symmetric encryption with a salt of 256B and an IV (initialization vector) of 16B over the whole data, the assumption would hold.","title":"Forewords"},{"location":"pages/dev/how_to/write_visit_on_nfc/write_visit_on_nfc.html#famocos-split","text":"In the documentation provided by Famoco, called DESFireService_v1.0.1 , they mention two types of writing: File \u201c01\u201d, which we\u2019ll call the profile, is up to 500B File \u201c02\u201d, which we\u2019ll call the visits, is of variable length based > on the type of card used. The profile is marked as a binary file overridden on each writing. The visits are marked as a cyclic record. Every time a visit is recorded, it is added to the previous ones. If the max length is reached, the oldest record is deleted to make room for the new one (FIFO). \u2753 It is yet to be defined if a model outside of Famoco should follow the same split and enforce the writing of one record at a time.","title":"Famoco\u2019s split"},{"location":"pages/dev/how_to/write_visit_on_nfc/write_visit_on_nfc.html#ndef-messages-and-ndef-records","text":"N FC D ata E xchange F ormat (or NDEF) is a lightweight binary format, used to encapsulate typed data. It is specified by the NFC Forum, for transmission and storage with NFC. However, it is transport agnostic. The format defines Messages and Records: An NDEF Record contains typed data, such as MIME-type media, a URI, > or a custom application payload. An NDEF Message is a container for one or more NDEF Records.","title":"NDEF Messages and NDEF Records"},{"location":"pages/dev/how_to/write_visit_on_nfc/write_visit_on_nfc.html#why-use-ndef","text":"As described in the Android documentation , It is mandatory for all Android devices with NFC to correctly enumerate Ndef on NFC Forum Tag Types 1-4, and implement all NDEF operations as defined in said documentation. Therefore, it guarantees that a perfectly written tag will be readable by all Android devices with NFC. Finally, the overhead of NDEF is existent but can be considered negligible compared to the advantages it brings. Based on this StackOverflow answer , the overhead is roughly 12 bytes: NDEF Header byte: 1 byte NDEF type length field: 1 byte NDEF payload length field: 1-4 bytes NDEF type name \"iaso:p\" (external type): 6 bytes","title":"Why use NDEF?"},{"location":"pages/dev/how_to/write_visit_on_nfc/write_visit_on_nfc.html#encryption","text":"Famoco\u2019s devices are relying on a S ecure A ccess M odule (or SAM) chip which encrypts and guarantees a secured shared secret across the authorized devices. Unfortunately, regular Android devices can't rely on such a chip. Therefore, we must find a solution to encrypt the card's data in a way only decipherable by another authorized device without an internet connection. Since all the authorized devices will need to be able to encrypt and decrypt the data, there is no need to go with asymmetric encryption. The current standard for symmetric encryption is AES.","title":"Encryption"},{"location":"pages/dev/how_to/write_visit_on_nfc/write_visit_on_nfc.html#the-overhead","text":"As explained in this StackOverflow answer , AES doesn\u2019t expand data, but the padding will. The maximum amount of padding is up to the padding algorithm. In the case of PKCS7Padding , it should be up to 16 bytes as defined in the RFC3602 . On top of that, it\u2019s good practice to salt the password to make the deciphering even more complex, avoid rainbow tables attacks, and avoid being able to compare two identical records (which is more likely to happen with small forms). AES also comes with the concept of I nitialization V ector (or IV) randomly generated on each encryption. The salt and the IV will be communicated in clear text alongside the encrypted data to be able to decrypt it. Therefore, they will add up to the number of bytes written on the card. \ud83d\udd10 As advised by the N ational I nstitute of S tandards and T echnology (NIST), the length of the randomly-generated portion of the salt shall be at least 128 bits (16 bytes) . In the current PoC implementation, it\u2019s 256 bytes. \ud83d\udd10 AES requires an IV size of 16 bytes The total overhead is therefore of the size of the salt (256B), the size of the IV (16B), and the padding (up to 16B), which sums up to 288B but could be lowered to 48B if we reduce the salt to 16B for lesser security.","title":"The overhead"},{"location":"pages/dev/how_to/write_visit_on_nfc/write_visit_on_nfc.html#how-the-data-is-split","text":"The overhead discussed previously is computed per encryption; if we encrypt all the data at once, the overhead is of that amount. If we encrypt the profile and the visits separately, the overhead is multiplied by two. The overhead is much higher if we encrypt the profile and each visit individually. \ud83d\udd10 I don\u2019t have sufficient knowledge to tell if there is any security benefit in one or the other approach. Yet, based on the size of the available space on the card, I assume we should encrypt all the data at once or encrypt the profile and the visits separately but not all the visits apiece.","title":"How the data is split"},{"location":"pages/dev/how_to/write_visit_on_nfc/write_visit_on_nfc.html#sharing-the-nfc-password-securely","text":"Every security measure is as strong as its weakest link. The whole encryption mechanism is rendered useless if the password is too weak, easily guessable, or easily accessible. Therefore, we need to find a good way to share the password while considering the complexity for the end user to obtain it. \ud83d\ude08 Keep in mind that nothing is 100% secure. All the solutions we could come up with have flaws, even the SAM chip used by Famoco. Yet, we can only make it harder and harder for someone to retrieve the key to the point that they either can\u2019t retrieve it (missing skills or hardware) or don\u2019t find that it is worth their while.","title":"Sharing the NFC password securely"},{"location":"pages/dev/how_to/write_visit_on_nfc/write_visit_on_nfc.html#embedded-inside-the-apk","text":"The easiest way to share a password across authorized devices is to embed it directly into the APK (an APK is a file containing the code and resources of an application that an Android device can interpret to install it). Yet, this solution is only viable if, and only if , the APK is distributed via a M obile D evice M anagement (or MDM) and that the MDM can securely prevent people from retrieving the APK from the device. If the APK is distributed via the Play Store (or any other means that is publicly available or that allow retrieving the APK), the password must be considered compromised and rendered useless. This solution is similar to what Famoco is doing since, in their case, the password is embedded and secured inside the SAM chip.","title":"Embedded inside the APK"},{"location":"pages/dev/how_to/write_visit_on_nfc/write_visit_on_nfc.html#over-the-network","text":"This solution is easy for the end user, but more vulnerable as anyone can make a network request. The client should make an authorized (given a valid token previously retrieved with valid credentials) request to a specific endpoint. The endpoint would receive a public key (from an asymmetric encryption scheme like RSA) of a hardware-backed key pair as described in Android\u2019s documentation . The backend would be able to verify the validity of the key and its certificate chain, pointing to a Google valid certificate, and containing the correct application ID and signature. The password would then be encrypted by the backend with the public key and communicated back to the phone. The application should then be able to decrypt the password and store it securely. This solution involves that only the application can decrypt the given password. \ud83d\udd11 This is the investigated solution at the moment of this writing but we are unsure how secure this would be on a rooted Android device. This solution involves security measures that can be hard for attackers to obtain: Valid credentials A compromised phone with the application on it. A way to compromise the device in a way it is not detected by > Android.","title":"Over the network"},{"location":"pages/dev/how_to/write_visit_on_nfc/write_visit_on_nfc.html#over-a-physical-device","text":"If the password is stored inside a physical device (like a USB key, a specific phone application, etc.) that is provided in limited quantities to trusted members of the organization, it can be shared through physical contact between the device to authorize and the trusted member with the physical device. The password is then securely stored on the authorized device for later use. This solution is secure but could be cumbersome. For example, if there are many devices to authorize, it can take a long time to transfer the password on each device. There could also be an issue if the devices are spread across the country, and the trusted members must go to each location to authorize the devices.","title":"Over a physical device"},{"location":"pages/dev/how_to/write_visit_on_nfc/write_visit_on_nfc.html#a-mix-of-the-above-solutions","text":"The solutions provided above are not exhaustive and can also be mixed. For example, we could consider storing the password on a physical device to be encrypted with a key that needs to be retrieved via an authorized network request. The more barrier we put in recovering the key, the more secure it is. Yet, it also makes the logistics for genuine authorized devices more complex.","title":"A mix of the above solutions"},{"location":"pages/dev/reference/API/entity.html","text":"API reference: Entity # Entity and related models The entity concept might feel a bit abstract, so it might be useful to reason about them using a concrete example (beneficiaries): Entities are used to track beneficiaries (=people who will benefit from the help an organization provides). Those beneficiaries can be of different types (E.g.: Children under 5, Pregnant or lactating women, etc.). Those beneficiaries are visited multiple times, so multiple submissions/instances (that we call \"records\") are attached to them via the entity_id foreign key of Instance. In addition to those records, we also want to track some core metadata about the beneficiary, such as their name, age,... Because entities can be of very different natures, we avoid hardcoding those fields in the Entity model, and also reuse the form mechanism: each EntityType has a foreign key to a reference form, and each entity has a foreign key (attributes) to an instance/submission of that form. Entity # Bases: SoftDeletableModel An entity represents a physical object or person with a known Entity Type Contrary to forms, they are not linked to a specific OrgUnit. The core attributes that define this entity are not stored as fields in the Entity model, but in an Instance / submission Source code in iaso/models/entity.py 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 class Entity ( SoftDeletableModel ): \"\"\"An entity represents a physical object or person with a known Entity Type Contrary to forms, they are not linked to a specific OrgUnit. The core attributes that define this entity are not stored as fields in the Entity model, but in an Instance / submission \"\"\" name = models . CharField ( max_length = 255 , blank = True ) # this field is not used, name value is taken from attributes uuid = models . UUIDField ( default = uuid . uuid4 , editable = False ) created_at = models . DateTimeField ( auto_now_add = True ) updated_at = models . DateTimeField ( auto_now = True ) entity_type = models . ForeignKey ( EntityType , blank = True , on_delete = models . PROTECT ) attributes = models . OneToOneField ( Instance , on_delete = models . PROTECT , help_text = \"instance\" , related_name = \"attributes\" , blank = True , null = True ) account = models . ForeignKey ( Account , on_delete = models . PROTECT ) merged_to = models . ForeignKey ( \"self\" , null = True , blank = True , on_delete = models . PROTECT ) objects = DefaultSoftDeletableManager . from_queryset ( EntityQuerySet )() objects_only_deleted = OnlyDeletedSoftDeletableManager . from_queryset ( EntityQuerySet )() objects_include_deleted = IncludeDeletedSoftDeletableManager . from_queryset ( EntityQuerySet )() class Meta : verbose_name_plural = \"Entities\" def __str__ ( self ): return f \" { self . name } \" def as_small_dict ( self ): return { \"id\" : self . pk , \"uuid\" : self . uuid , \"name\" : self . name , \"created_at\" : self . created_at , \"updated_at\" : self . updated_at , \"entity_type\" : self . entity_type_id , \"entity_type_name\" : self . entity_type and self . entity_type . name , \"attributes\" : self . attributes and self . attributes . as_dict (), } def as_dict ( self ): instances = dict () for i in self . instances . all (): instances [ \"uuid\" ] = i . uuid instances [ \"file_name\" ]: i . file_name instances [ str ( i . name )] = i . name return { \"id\" : self . pk , \"uuid\" : self . uuid , \"created_at\" : self . created_at , \"updated_at\" : self . updated_at , \"entity_type\" : self . entity_type . as_dict (), \"attributes\" : self . attributes . as_dict (), \"instances\" : instances , \"account\" : self . account . as_dict (), } def soft_delete_with_instances_and_pending_duplicates ( self , audit_source , user ): \"\"\" This method does a proper soft-deletion of the entity: - soft delete the entity - soft delete its attached form instances - delete relevant pending EntityDuplicate pairs \"\"\" from iaso.models.deduplication import ValidationStatus original = copy ( self ) self . delete () # soft delete log_modification ( original , self , audit_source , user = user ) for instance in set ([ self . attributes ] + list ( self . instances . all ())): original = copy ( instance ) instance . soft_delete () log_modification ( original , instance , audit_source , user = user ) self . duplicates1 . filter ( validation_status = ValidationStatus . PENDING ) . delete () self . duplicates2 . filter ( validation_status = ValidationStatus . PENDING ) . delete () return self soft_delete_with_instances_and_pending_duplicates ( audit_source , user ) # This method does a proper soft-deletion of the entity: - soft delete the entity - soft delete its attached form instances - delete relevant pending EntityDuplicate pairs Source code in iaso/models/entity.py 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 def soft_delete_with_instances_and_pending_duplicates ( self , audit_source , user ): \"\"\" This method does a proper soft-deletion of the entity: - soft delete the entity - soft delete its attached form instances - delete relevant pending EntityDuplicate pairs \"\"\" from iaso.models.deduplication import ValidationStatus original = copy ( self ) self . delete () # soft delete log_modification ( original , self , audit_source , user = user ) for instance in set ([ self . attributes ] + list ( self . instances . all ())): original = copy ( instance ) instance . soft_delete () log_modification ( original , instance , audit_source , user = user ) self . duplicates1 . filter ( validation_status = ValidationStatus . PENDING ) . delete () self . duplicates2 . filter ( validation_status = ValidationStatus . PENDING ) . delete () return self EntityType # Bases: models . Model Its reference_form describes the core attributes/metadata about the entity type (in case it refers to a person: name, age, ...) Source code in iaso/models/entity.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 class EntityType ( models . Model ): \"\"\"Its `reference_form` describes the core attributes/metadata about the entity type (in case it refers to a person: name, age, ...)\"\"\" name = models . CharField ( max_length = 255 ) # Example: \"Child under 5\" code = models . CharField ( max_length = 255 , null = True , blank = True ) # As the name could change over the time, this field will never change once the entity type created and ETL script will rely on that created_at = models . DateTimeField ( auto_now_add = True ) updated_at = models . DateTimeField ( auto_now = True ) # Link to the reference form that contains the core attribute/metadata specific to this entity type reference_form = models . ForeignKey ( Form , blank = True , null = True , on_delete = models . PROTECT ) account = models . ForeignKey ( Account , on_delete = models . PROTECT , blank = True , null = True ) is_active = models . BooleanField ( default = False ) # Fields (subset of the fields from the reference form) that will be shown in the UI - entity list view fields_list_view = ArrayField ( models . CharField ( max_length = 255 , blank = True , db_collation = \"case_insensitive\" ), size = 100 , null = True , blank = True ) # Fields (subset of the fields from the reference form) that will be shown in the UI - entity detail view fields_detail_info_view = ArrayField ( models . CharField ( max_length = 255 , blank = True , db_collation = \"case_insensitive\" ), size = 100 , null = True , blank = True ) # Fields (subset of the fields from the reference form) that will be used to search for duplicate entities fields_duplicate_search = ArrayField ( models . CharField ( max_length = 255 , blank = True , db_collation = \"case_insensitive\" ), size = 100 , null = True , blank = True ) prevent_add_if_duplicate_found = models . BooleanField ( default = False , ) class Meta : unique_together = [ \"name\" , \"account\" ] def __str__ ( self ): return f \" { self . name } \" def as_dict ( self ): return { \"name\" : self . name , \"created_at\" : self . created_at , \"updated_at\" : self . updated_at , \"reference_form\" : self . reference_form . as_dict (), \"account\" : self . account . as_dict (), }","title":"API reference: Entity"},{"location":"pages/dev/reference/API/entity.html#api-reference-entity","text":"Entity and related models The entity concept might feel a bit abstract, so it might be useful to reason about them using a concrete example (beneficiaries): Entities are used to track beneficiaries (=people who will benefit from the help an organization provides). Those beneficiaries can be of different types (E.g.: Children under 5, Pregnant or lactating women, etc.). Those beneficiaries are visited multiple times, so multiple submissions/instances (that we call \"records\") are attached to them via the entity_id foreign key of Instance. In addition to those records, we also want to track some core metadata about the beneficiary, such as their name, age,... Because entities can be of very different natures, we avoid hardcoding those fields in the Entity model, and also reuse the form mechanism: each EntityType has a foreign key to a reference form, and each entity has a foreign key (attributes) to an instance/submission of that form.","title":"API reference: Entity"},{"location":"pages/dev/reference/API/entity.html#iaso.models.entity.Entity","text":"Bases: SoftDeletableModel An entity represents a physical object or person with a known Entity Type Contrary to forms, they are not linked to a specific OrgUnit. The core attributes that define this entity are not stored as fields in the Entity model, but in an Instance / submission Source code in iaso/models/entity.py 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 class Entity ( SoftDeletableModel ): \"\"\"An entity represents a physical object or person with a known Entity Type Contrary to forms, they are not linked to a specific OrgUnit. The core attributes that define this entity are not stored as fields in the Entity model, but in an Instance / submission \"\"\" name = models . CharField ( max_length = 255 , blank = True ) # this field is not used, name value is taken from attributes uuid = models . UUIDField ( default = uuid . uuid4 , editable = False ) created_at = models . DateTimeField ( auto_now_add = True ) updated_at = models . DateTimeField ( auto_now = True ) entity_type = models . ForeignKey ( EntityType , blank = True , on_delete = models . PROTECT ) attributes = models . OneToOneField ( Instance , on_delete = models . PROTECT , help_text = \"instance\" , related_name = \"attributes\" , blank = True , null = True ) account = models . ForeignKey ( Account , on_delete = models . PROTECT ) merged_to = models . ForeignKey ( \"self\" , null = True , blank = True , on_delete = models . PROTECT ) objects = DefaultSoftDeletableManager . from_queryset ( EntityQuerySet )() objects_only_deleted = OnlyDeletedSoftDeletableManager . from_queryset ( EntityQuerySet )() objects_include_deleted = IncludeDeletedSoftDeletableManager . from_queryset ( EntityQuerySet )() class Meta : verbose_name_plural = \"Entities\" def __str__ ( self ): return f \" { self . name } \" def as_small_dict ( self ): return { \"id\" : self . pk , \"uuid\" : self . uuid , \"name\" : self . name , \"created_at\" : self . created_at , \"updated_at\" : self . updated_at , \"entity_type\" : self . entity_type_id , \"entity_type_name\" : self . entity_type and self . entity_type . name , \"attributes\" : self . attributes and self . attributes . as_dict (), } def as_dict ( self ): instances = dict () for i in self . instances . all (): instances [ \"uuid\" ] = i . uuid instances [ \"file_name\" ]: i . file_name instances [ str ( i . name )] = i . name return { \"id\" : self . pk , \"uuid\" : self . uuid , \"created_at\" : self . created_at , \"updated_at\" : self . updated_at , \"entity_type\" : self . entity_type . as_dict (), \"attributes\" : self . attributes . as_dict (), \"instances\" : instances , \"account\" : self . account . as_dict (), } def soft_delete_with_instances_and_pending_duplicates ( self , audit_source , user ): \"\"\" This method does a proper soft-deletion of the entity: - soft delete the entity - soft delete its attached form instances - delete relevant pending EntityDuplicate pairs \"\"\" from iaso.models.deduplication import ValidationStatus original = copy ( self ) self . delete () # soft delete log_modification ( original , self , audit_source , user = user ) for instance in set ([ self . attributes ] + list ( self . instances . all ())): original = copy ( instance ) instance . soft_delete () log_modification ( original , instance , audit_source , user = user ) self . duplicates1 . filter ( validation_status = ValidationStatus . PENDING ) . delete () self . duplicates2 . filter ( validation_status = ValidationStatus . PENDING ) . delete () return self","title":"Entity"},{"location":"pages/dev/reference/API/entity.html#iaso.models.entity.Entity.soft_delete_with_instances_and_pending_duplicates","text":"This method does a proper soft-deletion of the entity: - soft delete the entity - soft delete its attached form instances - delete relevant pending EntityDuplicate pairs Source code in iaso/models/entity.py 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 def soft_delete_with_instances_and_pending_duplicates ( self , audit_source , user ): \"\"\" This method does a proper soft-deletion of the entity: - soft delete the entity - soft delete its attached form instances - delete relevant pending EntityDuplicate pairs \"\"\" from iaso.models.deduplication import ValidationStatus original = copy ( self ) self . delete () # soft delete log_modification ( original , self , audit_source , user = user ) for instance in set ([ self . attributes ] + list ( self . instances . all ())): original = copy ( instance ) instance . soft_delete () log_modification ( original , instance , audit_source , user = user ) self . duplicates1 . filter ( validation_status = ValidationStatus . PENDING ) . delete () self . duplicates2 . filter ( validation_status = ValidationStatus . PENDING ) . delete () return self","title":"soft_delete_with_instances_and_pending_duplicates()"},{"location":"pages/dev/reference/API/entity.html#iaso.models.entity.EntityType","text":"Bases: models . Model Its reference_form describes the core attributes/metadata about the entity type (in case it refers to a person: name, age, ...) Source code in iaso/models/entity.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 class EntityType ( models . Model ): \"\"\"Its `reference_form` describes the core attributes/metadata about the entity type (in case it refers to a person: name, age, ...)\"\"\" name = models . CharField ( max_length = 255 ) # Example: \"Child under 5\" code = models . CharField ( max_length = 255 , null = True , blank = True ) # As the name could change over the time, this field will never change once the entity type created and ETL script will rely on that created_at = models . DateTimeField ( auto_now_add = True ) updated_at = models . DateTimeField ( auto_now = True ) # Link to the reference form that contains the core attribute/metadata specific to this entity type reference_form = models . ForeignKey ( Form , blank = True , null = True , on_delete = models . PROTECT ) account = models . ForeignKey ( Account , on_delete = models . PROTECT , blank = True , null = True ) is_active = models . BooleanField ( default = False ) # Fields (subset of the fields from the reference form) that will be shown in the UI - entity list view fields_list_view = ArrayField ( models . CharField ( max_length = 255 , blank = True , db_collation = \"case_insensitive\" ), size = 100 , null = True , blank = True ) # Fields (subset of the fields from the reference form) that will be shown in the UI - entity detail view fields_detail_info_view = ArrayField ( models . CharField ( max_length = 255 , blank = True , db_collation = \"case_insensitive\" ), size = 100 , null = True , blank = True ) # Fields (subset of the fields from the reference form) that will be used to search for duplicate entities fields_duplicate_search = ArrayField ( models . CharField ( max_length = 255 , blank = True , db_collation = \"case_insensitive\" ), size = 100 , null = True , blank = True ) prevent_add_if_duplicate_found = models . BooleanField ( default = False , ) class Meta : unique_together = [ \"name\" , \"account\" ] def __str__ ( self ): return f \" { self . name } \" def as_dict ( self ): return { \"name\" : self . name , \"created_at\" : self . created_at , \"updated_at\" : self . updated_at , \"reference_form\" : self . reference_form . as_dict (), \"account\" : self . account . as_dict (), }","title":"EntityType"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html","text":"OrgUnitChangeRequestConfiguration API # This document is a first draft of the OrgUnitChangeRequestConfiguration API that was designed by Benjamin in August 2024 and updated by Thibault. It still needs to be updated and completed, once the developments are over. 1 - POST /api/orgunits/changes/configs/ # API used to create or modify a Change Request configuration. Permissions # Change Request Configuration Body # { \"uuid\": \"UUID? - OrgUnitChangeRequestConfiguration UUID\", \"project_id\": \"Int - Project ID\", \"org_unit_type_id\": \"Int - OrgUnit Type ID\", \"org_units_editable\": \"Boolean? - Whether or not OrgUnits of this OrgUnit Type are editable\", \"editable_fields\": [\"Array<String> - List of possible fields\"], \"possible_type_ids\": [\"Array<Int> - List of possible OrgUnit Type IDs that are allowed as new type for this OrgUnit Type\"], \"possible_parent_type_ids\": [\"Array<Int> - List of possible OrgUnit Type IDs that are allowed as new parent for this OrgUnit Type\"], \"group_set_ids\": [\"Array<Int> - List of GroupSet IDs for this OrgUnit Type\"], \"editable_reference_form_ids\": [\"Array<Int> - List of reference Form ID that can be modified\"], \"other_group_ids\": [\"Array<Int> - List of possible Group IDs for this OrgUnit Type\"] } Possible responses # 201 - Created # # Do we return ID/UUID when something is successfully created? Let's try to return it, or even the full OUCRC 400 - Bad request # A non-nullable field was null or omitted org_unit_type_id is not assigned to the given project_id One or more editable_fields value is unknown One or more possible_parent_type_ids is not a suitable for as a parent for the given OrgUnit Type One or more editable_reference_forms is not a reference form for the given OrgUnit Type project_id is not null and doesn't exist org_unit_type_id is not null and doesn't exist One or more possible_type_ids don't exist One or more possible_parent_type_ids don't exist One or more group_set_ids don't exist One or more editable_reference_form_ids don't exist One or more other_group_ids don't exist 401 - Unauthorized # No authentication token or an invalid one was provided 403 - Forbidden # User doesn't have the proper permission 2 - GET /api/orgunits/changes/configs/ # API used to list all Change Request configurations. Permissions # Change Request Configuration Query parameters # page: Int (optional) - Current page (default: 1) limit: Int (optional) - Number of entities returned by page (default: 20) org_unit_type_id: Int (optional) - ID of the OrgUnitType to filter on project_id: Int (optional) - ID of the Project to filter on Possible responses # 200 - OK # { \"count\": \"Long\", \"has_next\": \"Boolean\", \"has_previous\": \"Boolean\", \"page\": \"Long\", \"pages\": \"Long\", \"limit\": \"Long\", \"results\": [ { \"id\": \"Int - ID in the database\", \"uuid\": \"UUID - UUID in the database\", \"project\": { \"id\": \"Int - Project ID\", \"name\": \"String - Project name\" }, \"org_unit_type\": { \"id\": \"Int - OrgUnit Type ID\", \"name\": \"String - OrgUnit Type name\" }, \"org_units_editable\": \"Boolean - Whether or not OrgUnits of this OrgUnit Type are editable\", \"editable_fields\": \"Array<String> - List of possible fields\", \"created_at\": \"Timestamp\", \"created_by\": { \"id\": \"Int - User ID\", \"username\": \"String\", \"first_name\": \"String\", \"last_name\": \"String\" }, \"updated_at\": \"Timestamp\", \"updated_by\": { \"id\": \"Int - User ID\", \"username\": \"String\", \"first_name\": \"String\", \"last_name\": \"String\" } } ] } 400 - Bad request # One or more parameters provided couldn't be parsed One or more parameters provided couldn't be matched with the related resource ( e.g. : unknown project_id ) A given parameter was not recognized 401 - Unauthorized # No authentication token or an invalid one was provided 403 - Forbidden # User doesn't have the proper permission to access this resource. 3 - GET /api/orgunits/changes/configs/{id}/ # API used to fully retrieve a Change Request configuration. Permissions # Change Request Configuration Possible responses # 200 - OK # { \"id\": \"Int - ID in the database\", \"uuid\": \"UUID - UUID in the database\", \"project\": { \"id\": \"Int - Project ID\", \"name\": \"String - Project name\" }, \"org_unit_type\": { \"id\": \"Int - OrgUnit Type ID\", \"name\": \"String - OrgUnit Type name\" }, \"org_units_editable\": \"Boolean - Whether or not OrgUnits of this OrgUnit Type are editable\", \"editable_fields\": \"Array<String> - List of possible fields\", \"possible_types\": [ { \"id\": \"Int - OrgUnit Type ID\", \"name\": \"String - OrgUnit Type name\" } ], \"possible_parent_types\": [ { \"id\": \"Int - OrgUnit Type ID\", \"name\": \"String - OrgUnit Type name\" } ], \"group_sets\": [ { \"id\": \"Int - GroupSet ID\", \"name\": \"String - GroupSet name\" } ], \"editable_reference_forms\": [ { \"id\": \"Int - Form ID\", \"name\": \"String - Form name\" } ], \"other_groups\": [ { \"id\": \"Int - Group ID\", \"name\": \"String - Group name\" } ], \"created_at\": \"Timestamp\", \"created_by\": { \"id\": \"Int - User ID\", \"username\": \"String\", \"first_name\": \"String\", \"last_name\": \"String\" }, \"updated_at\": \"Timestamp\", \"updated_by\": { \"id\": \"Int - User ID\", \"username\": \"String\", \"first_name\": \"String\", \"last_name\": \"String\" } } 401 - Unauthorized # No authentication token or an invalid one was provided 403 - Forbidden # User doesn't have the proper permission to access this resource. 404 - Not found # The given ID was not found 4 - GET /api/mobile/orgunits/changes/configs/ # API used to list all Change Request configurations for the mobile app. Permissions # User must be authenticated Query parameters # app_id: String - Application ID for which to retrieve the configuration page: Int (optional) - Current page (default: 1) limit: Int (optional) - Number of entities returned by page (default: 20) Possible responses # 200 - OK # { \"count\": \"Long\", \"has_next\": \"Boolean\", \"has_previous\": \"Boolean\", \"page\": \"Long\", \"pages\": \"Long\", \"limit\": \"Long\", \"results\": [ { \"org_unit_type_id\": \"Int - OrgUnit Type ID\", \"org_units_editable\": \"Boolean - Whether or not OrgUnits of this OrgUnit Type are editable\", \"editable_fields\": [\"Array<String> - List of possible fields\"], \"possible_type_ids\": [\"Array<Int> - List of possible OrgUnit Type IDs that are allowed as new type for this OrgUnit Type\"], \"possible_parent_types\": [\"Array<Int> - List of possible OrgUnit Type IDs that are allowed as new parent for this OrgUnit Type\"], \"group_sets\": [\"Array<Int> - List of GroupSet IDs for this OrgUnit Type\"], \"editable_reference_forms\": [\"Array<Int> - List of reference Form ID that can be modified\"], \"other_groups\": [\"Array<Int> - List of other Group IDs for this OrgUnit Type\"], \"created_at\": \"Timestamp\", \"updated_at\": \"Timestamp\" } ] } 400 - Bad request # One or more of the parameters provided couldn't be parsed One or more of the parameters provided couldn't be matched with the related resource ( e.g. : unknown project_id ) A given parameter was not recognized 401 - Unauthorized # No authentication token or an invalid one was provided 403 - Forbidden # User doesn't have the proper permission to access this resource.","title":"`OrgUnitChangeRequestConfiguration` API"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#orgunitchangerequestconfiguration-api","text":"This document is a first draft of the OrgUnitChangeRequestConfiguration API that was designed by Benjamin in August 2024 and updated by Thibault. It still needs to be updated and completed, once the developments are over.","title":"OrgUnitChangeRequestConfiguration API"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#1-post-apiorgunitschangesconfigs","text":"API used to create or modify a Change Request configuration.","title":"1 - POST /api/orgunits/changes/configs/"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#permissions","text":"Change Request Configuration","title":"Permissions"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#body","text":"{ \"uuid\": \"UUID? - OrgUnitChangeRequestConfiguration UUID\", \"project_id\": \"Int - Project ID\", \"org_unit_type_id\": \"Int - OrgUnit Type ID\", \"org_units_editable\": \"Boolean? - Whether or not OrgUnits of this OrgUnit Type are editable\", \"editable_fields\": [\"Array<String> - List of possible fields\"], \"possible_type_ids\": [\"Array<Int> - List of possible OrgUnit Type IDs that are allowed as new type for this OrgUnit Type\"], \"possible_parent_type_ids\": [\"Array<Int> - List of possible OrgUnit Type IDs that are allowed as new parent for this OrgUnit Type\"], \"group_set_ids\": [\"Array<Int> - List of GroupSet IDs for this OrgUnit Type\"], \"editable_reference_form_ids\": [\"Array<Int> - List of reference Form ID that can be modified\"], \"other_group_ids\": [\"Array<Int> - List of possible Group IDs for this OrgUnit Type\"] }","title":"Body"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#possible-responses","text":"","title":"Possible responses"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#201-created","text":"# Do we return ID/UUID when something is successfully created? Let's try to return it, or even the full OUCRC","title":"201 - Created"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#400-bad-request","text":"A non-nullable field was null or omitted org_unit_type_id is not assigned to the given project_id One or more editable_fields value is unknown One or more possible_parent_type_ids is not a suitable for as a parent for the given OrgUnit Type One or more editable_reference_forms is not a reference form for the given OrgUnit Type project_id is not null and doesn't exist org_unit_type_id is not null and doesn't exist One or more possible_type_ids don't exist One or more possible_parent_type_ids don't exist One or more group_set_ids don't exist One or more editable_reference_form_ids don't exist One or more other_group_ids don't exist","title":"400 - Bad request"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#401-unauthorized","text":"No authentication token or an invalid one was provided","title":"401 - Unauthorized"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#403-forbidden","text":"User doesn't have the proper permission","title":"403 - Forbidden"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#2-get-apiorgunitschangesconfigs","text":"API used to list all Change Request configurations.","title":"2 - GET /api/orgunits/changes/configs/"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#permissions_1","text":"Change Request Configuration","title":"Permissions"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#query-parameters","text":"page: Int (optional) - Current page (default: 1) limit: Int (optional) - Number of entities returned by page (default: 20) org_unit_type_id: Int (optional) - ID of the OrgUnitType to filter on project_id: Int (optional) - ID of the Project to filter on","title":"Query parameters"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#possible-responses_1","text":"","title":"Possible responses"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#200-ok","text":"{ \"count\": \"Long\", \"has_next\": \"Boolean\", \"has_previous\": \"Boolean\", \"page\": \"Long\", \"pages\": \"Long\", \"limit\": \"Long\", \"results\": [ { \"id\": \"Int - ID in the database\", \"uuid\": \"UUID - UUID in the database\", \"project\": { \"id\": \"Int - Project ID\", \"name\": \"String - Project name\" }, \"org_unit_type\": { \"id\": \"Int - OrgUnit Type ID\", \"name\": \"String - OrgUnit Type name\" }, \"org_units_editable\": \"Boolean - Whether or not OrgUnits of this OrgUnit Type are editable\", \"editable_fields\": \"Array<String> - List of possible fields\", \"created_at\": \"Timestamp\", \"created_by\": { \"id\": \"Int - User ID\", \"username\": \"String\", \"first_name\": \"String\", \"last_name\": \"String\" }, \"updated_at\": \"Timestamp\", \"updated_by\": { \"id\": \"Int - User ID\", \"username\": \"String\", \"first_name\": \"String\", \"last_name\": \"String\" } } ] }","title":"200 - OK"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#400-bad-request_1","text":"One or more parameters provided couldn't be parsed One or more parameters provided couldn't be matched with the related resource ( e.g. : unknown project_id ) A given parameter was not recognized","title":"400 - Bad request"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#401-unauthorized_1","text":"No authentication token or an invalid one was provided","title":"401 - Unauthorized"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#403-forbidden_1","text":"User doesn't have the proper permission to access this resource.","title":"403 - Forbidden"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#3-get-apiorgunitschangesconfigsid","text":"API used to fully retrieve a Change Request configuration.","title":"3 - GET /api/orgunits/changes/configs/{id}/"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#permissions_2","text":"Change Request Configuration","title":"Permissions"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#possible-responses_2","text":"","title":"Possible responses"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#200-ok_1","text":"{ \"id\": \"Int - ID in the database\", \"uuid\": \"UUID - UUID in the database\", \"project\": { \"id\": \"Int - Project ID\", \"name\": \"String - Project name\" }, \"org_unit_type\": { \"id\": \"Int - OrgUnit Type ID\", \"name\": \"String - OrgUnit Type name\" }, \"org_units_editable\": \"Boolean - Whether or not OrgUnits of this OrgUnit Type are editable\", \"editable_fields\": \"Array<String> - List of possible fields\", \"possible_types\": [ { \"id\": \"Int - OrgUnit Type ID\", \"name\": \"String - OrgUnit Type name\" } ], \"possible_parent_types\": [ { \"id\": \"Int - OrgUnit Type ID\", \"name\": \"String - OrgUnit Type name\" } ], \"group_sets\": [ { \"id\": \"Int - GroupSet ID\", \"name\": \"String - GroupSet name\" } ], \"editable_reference_forms\": [ { \"id\": \"Int - Form ID\", \"name\": \"String - Form name\" } ], \"other_groups\": [ { \"id\": \"Int - Group ID\", \"name\": \"String - Group name\" } ], \"created_at\": \"Timestamp\", \"created_by\": { \"id\": \"Int - User ID\", \"username\": \"String\", \"first_name\": \"String\", \"last_name\": \"String\" }, \"updated_at\": \"Timestamp\", \"updated_by\": { \"id\": \"Int - User ID\", \"username\": \"String\", \"first_name\": \"String\", \"last_name\": \"String\" } }","title":"200 - OK"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#401-unauthorized_2","text":"No authentication token or an invalid one was provided","title":"401 - Unauthorized"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#403-forbidden_2","text":"User doesn't have the proper permission to access this resource.","title":"403 - Forbidden"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#404-not-found","text":"The given ID was not found","title":"404 - Not found"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#4-get-apimobileorgunitschangesconfigs","text":"API used to list all Change Request configurations for the mobile app.","title":"4 - GET /api/mobile/orgunits/changes/configs/"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#permissions_3","text":"User must be authenticated","title":"Permissions"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#query-parameters_1","text":"app_id: String - Application ID for which to retrieve the configuration page: Int (optional) - Current page (default: 1) limit: Int (optional) - Number of entities returned by page (default: 20)","title":"Query parameters"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#possible-responses_3","text":"","title":"Possible responses"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#200-ok_2","text":"{ \"count\": \"Long\", \"has_next\": \"Boolean\", \"has_previous\": \"Boolean\", \"page\": \"Long\", \"pages\": \"Long\", \"limit\": \"Long\", \"results\": [ { \"org_unit_type_id\": \"Int - OrgUnit Type ID\", \"org_units_editable\": \"Boolean - Whether or not OrgUnits of this OrgUnit Type are editable\", \"editable_fields\": [\"Array<String> - List of possible fields\"], \"possible_type_ids\": [\"Array<Int> - List of possible OrgUnit Type IDs that are allowed as new type for this OrgUnit Type\"], \"possible_parent_types\": [\"Array<Int> - List of possible OrgUnit Type IDs that are allowed as new parent for this OrgUnit Type\"], \"group_sets\": [\"Array<Int> - List of GroupSet IDs for this OrgUnit Type\"], \"editable_reference_forms\": [\"Array<Int> - List of reference Form ID that can be modified\"], \"other_groups\": [\"Array<Int> - List of other Group IDs for this OrgUnit Type\"], \"created_at\": \"Timestamp\", \"updated_at\": \"Timestamp\" } ] }","title":"200 - OK"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#400-bad-request_2","text":"One or more of the parameters provided couldn't be parsed One or more of the parameters provided couldn't be matched with the related resource ( e.g. : unknown project_id ) A given parameter was not recognized","title":"400 - Bad request"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#401-unauthorized_3","text":"No authentication token or an invalid one was provided","title":"401 - Unauthorized"},{"location":"pages/dev/reference/API/org_unit_change_request_configuration.html#403-forbidden_3","text":"User doesn't have the proper permission to access this resource.","title":"403 - Forbidden"},{"location":"pages/dev/reference/API/org_unit_registry.html","text":"OrgUnitChangeRequest API # \"Change Requests\" can be submitted for an OrgUnit and then reviewed (approved or rejected). This API allows the DHIS2 Health pyramid to be updated using Iaso. The Django model that stores \"Change Requests\" is OrgUnitChangeRequest . Create an OrgUnitChangeRequest object - Web + Mobile (IA-2421) # POST /api/orgunits/changes/?app_id=\u2026 Permissions # User must be authenticated Query parameters # app_id : String - Optional, project for which this is created. Body # { \"uuid\": \"UUID - Client generated UUID\", \"org_unit_id\": \"String - id or UUID of the OrgUnit to change\", \"new_parent_id\": \"String? - id or UUID of the parent OrgUnit, null to erase, omitted to ignore.\", \"new_name\": \"String? - Name of the OrgUnit, \\\"\\\" (empty string) to erase, omitted to ignore.\", \"new_org_unit_type_id\": \"Int? - id of the OrgUnitType, null to erase, omitted to ignore.\", \"new_groups\": \"Array of Group ids? - empty array to erase, omitted to ignore.\", \"new_location\": { \"\": \"New geopoint for the OrgUnit, null to erase, omitted to ignore.\", \"latitude\": \"Double - New latitude of the OrgUnit\", \"longitude\": \"Double - New longitude of the OrgUnit\", \"altitude\": \"Double - New altitude of the OrgUnit\" }, \"new_location_accuracy\": \"Double - New accuracy of the OrgUnit, null to erase, omitted to ignore.\", \"new_opening_date\": \"Timestamp, null to erase, omitted to ignore.\", \"new_closed_date\": \"Timestamp, null to erase, omitted to ignore.\", \"new_reference_instances\": \"Array of instance ids or UUIDs? - empty array to erase, omitted to ignore.\" } Possible responses # 201 - Created # 400 - Bad request # A not nullable field was null or omitted A String field has an empty value new_parent_id is not a valid OrgUnit new_org_unit_type_id is not a valid OrgUnitType One of the new_groups id is not a valid Group new_reference_instances only one reference instance can exist by org_unit/form pair new_org_unit_type_id is not part of the user account new_closed_date must be later than new_opening_date new_parent_id and org_unit_id must have the same version new_parent_id is already a child of org_unit_id 401 - Unauthorized # No authentication token or an invalid one was provided 404 - Not found # one or more of new_reference_instances ids is not found new_parent_id is not found new_org_unit_type_id is not found List OrgUnitChangeRequest objects - Web only (IA-2422) # GET /api/orgunits/changes/ Permissions # User must be authenticated Query parameters # page : Int (optional) - Current page (default: 1) limit : Int (optional) - Number of entities returned by page (default: 20) org_unit_id : Int (optional) - Id of the OrgUnit to which the changes apply (default: null) org_unit_type_id : Int (optional) - Id of the OrgUnitType to filter on, either the old OrgUnitType before the change or the new one after the change (default: null) status : Array > (optional) - One of new , validated , rejected to filter the requests (default: null) can be combined, e.g. &status=rejected&status=new parent_id : Int (optional) - Id of the old parent OrgUnit to filter on, before the change (default: null) project : Int (optional) - Id of the project to filter on. groups : List of int, comma separated (optional) - Ids of the old groups to filter on, before the change (default: null) e.g. &groups=1847,1846 forms : List of int, comma separated (optional) - Ids of the old forms to filter on, before the change (default: null) e.g. &forms=12,34 users : List of int, comma separated (optional) - Ids of the users who either created or last updated the change request (default: null) e.g. &users=56,78 user_roles : List of int, comma separated (optional) - Ids of the old user roles to filter on, specifically the roles associated with the user who created the change request (default: null) e.g. &user_roles=90,123 with_location : String (optional) - Filters the change requests based on the presence ( \"true\" ) or absence ( \"false\" ) of an old location, before the change (default: null) e.g. &with_location=true Possible responses # 200 - OK # { \"count\": \"Long\", \"has_next\": \"Boolean\", \"has_previous\": \"Boolean\", \"page\": \"Long\", \"pages\": \"Long\", \"limit\": \"Long\", \"results\": [ { \"id\": \"Int - id in the database\", \"uuid\": \"UUID - uuid in the database\", \"org_unit_id\": \"Int - id of the OrgUnit\", \"org_unit_uuid\": \"UUID - uuid of the OrgUnit\", \"org_unit_name\": \"String - name of the OrgUnit\", \"org_unit_type_id\": \"Int - id of the current OrgUnitType\", \"org_unit_type_name\": \"String - name of the current OrgUnitType\", \"status\": \"Enum<Status> - one of `new`, `validated`, `rejected`\", \"groups\": [ { \"id\": \"Int - id of the Group\", \"name\": \"String - name of the Group\" } ], \"requested_fields\": \"Array<String> - name of the properties that were requested to change\", \"approved_fields\": \"Array<String>? - name of the properties that were approved to change\", \"rejection_comment\": \"String? - Comment about why the changes were rejected\", \"created_by\": { \"id\": \"Int - id of the User who created that request\", \"username\": \"String?\", \"first_name\": \"String?\", \"last_name\": \"String?\" }, \"created_at\": \"Timestamp\", \"updated_by\": { \"\": \"May be null\", \"id\": \"Int - id of the User\", \"username\": \"String?\", \"first_name\": \"String?\", \"last_name\": \"String?\" }, \"updated_at\": \"Timestamp?\" } ] } 400 - Bad request # page or limit cannot be parsed to a correct integer value One or more of the parameters provided couldn't be parsed One or more of the parameters provided couldn't matched to the related resource (E.g.: unknown parent_id) A parameter was given that is not recognized 401 - Unauthorized # No authentication token or an invalid one was provided 403 - Forbidden # User doesn't have the proper permission to access this resource. List OrgUnitChangeRequest objects - Mobile only (IA-2425) # GET /api/mobile/orgunits/changes/?app_id=\u2026 Permissions # User must be authenticated Query parameter # app_id : String - Must be provided, project for which this is queried. last_sync : DateString - May be null or omitted. Limits the results to everything that was modified after this DateString last_sync filter is built with django.utils.dateparse.parse_datetime and allows: &last_sync=2023-09-26T17:21:22.921692Z &last_sync=2021-09-26T17:21:22Z &last_sync=2021-09-26T17:21:22 &last_sync=2021-09-26T17:21 page : Int (optional) - Current page (default: 1) limit : Int (optional) - Number of entities returned by page (default: 20) Possible responses # 200 - OK # { \"count\": \"Long\", \"has_next\": \"Boolean\", \"has_previous\": \"Boolean\", \"page\": \"Long\", \"pages\": \"Long\", \"limit\": \"Long\", \"results\": [ { \"id\": \"Int - id in the database\", \"uuid\": \"UUID - uuid in the database\", \"org_unit_id\": \"Int - id of the OrgUnit\", \"org_unit_uuid\": \"UUID - uuid of the OrgUnit\", \"status\": \"Enum<Status> - one of `new`, `validated`, `rejected`\", \"approved_fields\": \"Array<String>? - name of the properties that were approved to change\", \"rejection_comment\": \"String? - Comment about why the changes were rejected\", \"created_at\": \"Timestamp in double\", \"updated_at\": \"Timestamp in double\", \"new_parent_id\": \"String? - id or UUID of the parent OrgUnit, may be null or omitted.\", \"new_name\": \"String? - Name of the OrgUnit, may be null or omitted.\", \"new_org_unit_type_id\": \"Int? - id of the OrgUnitType, may be null or omitted\", \"new_groups\": \"Array of Group ids? - can be empty, null or omitted. Empty means we want to remove all values\", \"new_location\": { \"\": \"New geopoint for the OrgUnit, may be null or omitted\", \"latitude\": \"Double - New latitude of the OrgUnit\", \"longitude\": \"Double - New longitude of the OrgUnit\", \"altitude\": \"Double - New altitude of the OrgUnit\" }, \"new_location_accuracy\": \"Double - New accuracy of the OrgUnit\", \"new_opening_date\": \"Timestamp in double\", \"new_closed_date\": \"Timestamp in double\", \"new_reference_instances\": [ { \"id\": \"Int\", \"uuid\": \"UUID - provided by the client\", \"form_id\": \"Int\", \"form_version_id\": \"Int\", \"created_at\": \"Timestamp in double\", \"updated_at\": \"Timestamp in double\", \"json\": \"JSONObject - contains the key/value of the instance\" } ] } ] } 400 - Bad request # app_id was not provided page or limit cannot be parsed to a correct integer value last_sync cannot be parsed to a correct date time. 401 - Unauthorized # No authentication token or an invalid one was provided Get an OrgUnitChangeRequest object - Web only (IA-2423) # GET /api/orgunits/changes/{id}/ Permissions # User must be authenticated Possible responses # 200 - OK # { \"id\": \"Int - id in the database\", \"uuid\": \"UUID - uuid in the database\", \"status\": \"Enum<Status> - one of `new`, `validated`, `rejected`\", \"created_by\": { \"id\": \"Int - id of the User who created that request\", \"username\": \"String?\", \"first_name\": \"String?\", \"last_name\": \"String?\" }, \"created_at\": \"Timestamp\", \"updated_by\": { \"\": \"May be null\", \"id\": \"Int - id of the User who updated that request\", \"username\": \"String?\", \"first_name\": \"String?\", \"last_name\": \"String?\" }, \"updated_at\": \"Timestamp?\", \"requested_fields\": \"Array<String> - name of the properties that were requested to change\", \"approved_fields\": \"Array<String>? - name of the properties that were approved to change\", \"rejection_comment\": \"String? - Comment about why the changes were rejected\", \"org_unit\": { \"id\": \"Int - id in the database\", \"parent\": { \"id\": \"Int - id of the parent OrgUnit\", \"name\": \"String - name of the parent OrgUnit\" }, \"name\": \"String - Name of the OrgUnit.\", \"org_unit_type\": { \"id\": \"Int - id of the OrgUnitType\", \"name\": \"String - name of the OrgUnitType\", \"short_name\": \"String - short name of the OrgUnitType\" }, \"groups\": [ { \"id\": \"Int - id of the Group\", \"name\": \"String - name of the Group\" } ], \"location\": { \"\": \"Geopoint for the OrgUnit\", \"latitude\": \"Double - New latitude of the OrgUnit\", \"longitude\": \"Double - New longitude of the OrgUnit\", \"altitude\": \"Double - New altitude of the OrgUnit\" }, \"opening_date\": \"Timestamp?\", \"closed_date\": \"Timestamp?\", \"reference_instances\": [ \"Array of form objects - can be empty\", { \"id\": \"Int - id in the database\", \"form_id\": \"id of the form\", \"form_name\": \"Name of the form\", \"values\": [ { \"key\": \"String\", \"label\": \"String or translated object\", \"value\": \"String\" } ] } ] }, \"new_parent\": { \"\": \"May be null\", \"id\": \"Int - id of the new parent OrgUnit in the database\", \"name\": \"String? - name of the new parent OrgUnit\" }, \"new_name\": \"String? - New name of the OrgUnit, may be null or omitted\", \"new_org_unit_type\": { \"\": \"May be null\", \"id\": \"Int? - id of the new OrgUnitType\", \"name\": \"String? - name of the new OrgUnitType\", \"short_name\": \"String? - short name of the new OrgUnitType\" }, \"new_groups\": [ { \"id\": \"Int - id of the Group\", \"name\": \"String - name of the Group\" } ], \"new_location\": { \"\": \"New GeoPoint? for the OrgUnit, may be null or omitted\", \"latitude\": \"Double - New latitude of the OrgUnit\", \"longitude\": \"Double - New longitude of the OrgUnit\", \"altitude\": \"Double - New altitude of the OrgUnit\" }, \"new_location_accuracy\": \"Double? - New accuracy of the OrgUnit\", \"new_opening_date\": \"Timestamp?\", \"new_closed_date\": \"Timestamp?\", \"new_reference_instances\": [ \"Array of form objects? - may be null or omitted, cannot be empty\", { \"id\": \"Int - id in the database\", \"form_id\": \"id of the form\", \"form_name\": \"Name of the form\", \"values\": [ { \"key\": \"String\", \"label\": \"String or translated object\", \"value\": \"String\" } ] } ], \"old_name\": \"String? - Old name of the OrgUnit, may be an empty\", \"old_org_unit_type\": { \"\": \"May be null\", \"id\": \"Int? - id of the old OrgUnitType\", \"name\": \"String? - name of the old OrgUnitType\", \"short_name\": \"String? - short name of the old OrgUnitType\" }, \"old_groups\": [ \"Array of old groups objects? - may be empty\", { \"id\": \"Int - id of the Group\", \"name\": \"String - name of the Group\" } ], \"old_location\": { \"\": \"Old GeoPoint? for the OrgUnit, may be null\", \"latitude\": \"Double - New latitude of the OrgUnit\", \"longitude\": \"Double - New longitude of the OrgUnit\", \"altitude\": \"Double - New altitude of the OrgUnit\" }, \"old_opening_date\": \"Timestamp? - may be null\", \"old_closed_date\": \"Timestamp? - may be null\", \"old_reference_instances\": [ \"Array of old form instance objects? - may be empty\", { \"id\": \"Int - id in the database\", \"form_id\": \"id of the form\", \"form_name\": \"Name of the form\", \"values\": [ { \"key\": \"String\", \"label\": \"String or translated object\", \"value\": \"String\" } ] } ] } 400 - Bad request # One or more of the parameters provided couldn't be parsed One or more of the parameters provided couldn't matched to the related resource (E.g.: unknown parent_id) A parameter was given that is not recognized 401 - Unauthorized # No authentication token or an invalid one was provided 403 - Forbidden # User doesn't have the proper permission to access this resource. Approve or reject an OrgUnitChangeRequest - Web only (IA-2424) # PATCH /api/orgunits/changes/{id}/ API to change the status of on change request. Permissions # User must be authenticated User must have the ORG_UNITS_CHANGE_REQUEST_REVIEW permission Body # { \"status\": \"Enum<Status> - One of `validated` or `rejected`\", \"approved_fields\": \"Array<Enum<Field>>? - name of the properties that were approved to change\", \"rejection_comment\": \"String? - Comment about why the changes were rejected\" } Possible responses # 204 - No content # Change were applied successfully 400 - Bad request # status of the change to be patched is not new status must be approved or rejected status was validated but approved_fields was null, omitted or empty: at least one approved_fields must be provided approved_fields contains one or more unknown fields status was rejected but rejection_comment was null, omitted or empty: a rejection_comment must be provided List reference_instances objects for a given OrgUnit - Mobile only (IA-2420) # GET /api/mobile/orgunits/{id or UUID}/reference_instances?app_id=\u2026 Returns Instance objects marked as reference_instances for an OrgUnit from newest to oldest. Permission # Same as downloading instances Query parameters # page : Int (optional) - Current page (default: 1) limit : Int (optional) - Number of entities returned by page (default: 20) app_id : String - project for which this is queried. last_sync : DateString - May be null or omitted. Limits the results to everything that was modified after this DateString last_sync filter is built with django.utils.dateparse.parse_datetime and allows: &last_sync=2023-09-26T17:21:22.921692Z &last_sync=2021-09-26T17:21:22Z &last_sync=2021-09-26T17:21:22 &last_sync=2021-09-26T17:21 Possible response # 200 - OK # { \"count\": \"Long\", \"instances\": [ { \"id\": \"Int\", \"uuid\": \"UUID - provided by the client\", \"form_id\": \"Int\", \"form_version_id\": \"Int\", \"created_at\": \"Timestamp in double\", \"updated_at\": \"Timestamp in double\", \"json\": \"JSONObject - contains the key/value of the instance\" } ], \"has_next\": \"Boolean\", \"has_previous\": \"Boolean\", \"page\": \"Long\", \"pages\": \"Long\", \"limit\": \"Long\" } 400 - Bad request # app_id was not provided page , limit or version_count cannot be parsed to a correct integer value last_sync cannot be parsed to a correct date time. 401 - Unauthorized # No authentication token or an invalid one was provided (if needed) 403 - Forbidden # User doesn't have the proper permission to access this resource (if needed)","title":"`OrgUnitChangeRequest` API"},{"location":"pages/dev/reference/API/org_unit_registry.html#orgunitchangerequest-api","text":"\"Change Requests\" can be submitted for an OrgUnit and then reviewed (approved or rejected). This API allows the DHIS2 Health pyramid to be updated using Iaso. The Django model that stores \"Change Requests\" is OrgUnitChangeRequest .","title":"OrgUnitChangeRequest API"},{"location":"pages/dev/reference/API/org_unit_registry.html#create-an-orgunitchangerequest-object-web-mobile-ia-2421","text":"POST /api/orgunits/changes/?app_id=\u2026","title":"Create an OrgUnitChangeRequest object - Web + Mobile (IA-2421)"},{"location":"pages/dev/reference/API/org_unit_registry.html#permissions","text":"User must be authenticated","title":"Permissions"},{"location":"pages/dev/reference/API/org_unit_registry.html#query-parameters","text":"app_id : String - Optional, project for which this is created.","title":"Query parameters"},{"location":"pages/dev/reference/API/org_unit_registry.html#body","text":"{ \"uuid\": \"UUID - Client generated UUID\", \"org_unit_id\": \"String - id or UUID of the OrgUnit to change\", \"new_parent_id\": \"String? - id or UUID of the parent OrgUnit, null to erase, omitted to ignore.\", \"new_name\": \"String? - Name of the OrgUnit, \\\"\\\" (empty string) to erase, omitted to ignore.\", \"new_org_unit_type_id\": \"Int? - id of the OrgUnitType, null to erase, omitted to ignore.\", \"new_groups\": \"Array of Group ids? - empty array to erase, omitted to ignore.\", \"new_location\": { \"\": \"New geopoint for the OrgUnit, null to erase, omitted to ignore.\", \"latitude\": \"Double - New latitude of the OrgUnit\", \"longitude\": \"Double - New longitude of the OrgUnit\", \"altitude\": \"Double - New altitude of the OrgUnit\" }, \"new_location_accuracy\": \"Double - New accuracy of the OrgUnit, null to erase, omitted to ignore.\", \"new_opening_date\": \"Timestamp, null to erase, omitted to ignore.\", \"new_closed_date\": \"Timestamp, null to erase, omitted to ignore.\", \"new_reference_instances\": \"Array of instance ids or UUIDs? - empty array to erase, omitted to ignore.\" }","title":"Body"},{"location":"pages/dev/reference/API/org_unit_registry.html#possible-responses","text":"","title":"Possible responses"},{"location":"pages/dev/reference/API/org_unit_registry.html#201-created","text":"","title":"201 - Created"},{"location":"pages/dev/reference/API/org_unit_registry.html#400-bad-request","text":"A not nullable field was null or omitted A String field has an empty value new_parent_id is not a valid OrgUnit new_org_unit_type_id is not a valid OrgUnitType One of the new_groups id is not a valid Group new_reference_instances only one reference instance can exist by org_unit/form pair new_org_unit_type_id is not part of the user account new_closed_date must be later than new_opening_date new_parent_id and org_unit_id must have the same version new_parent_id is already a child of org_unit_id","title":"400 - Bad request"},{"location":"pages/dev/reference/API/org_unit_registry.html#401-unauthorized","text":"No authentication token or an invalid one was provided","title":"401 - Unauthorized"},{"location":"pages/dev/reference/API/org_unit_registry.html#404-not-found","text":"one or more of new_reference_instances ids is not found new_parent_id is not found new_org_unit_type_id is not found","title":"404 - Not found"},{"location":"pages/dev/reference/API/org_unit_registry.html#list-orgunitchangerequest-objects-web-only-ia-2422","text":"GET /api/orgunits/changes/","title":"List OrgUnitChangeRequest objects - Web only (IA-2422)"},{"location":"pages/dev/reference/API/org_unit_registry.html#permissions_1","text":"User must be authenticated","title":"Permissions"},{"location":"pages/dev/reference/API/org_unit_registry.html#query-parameters_1","text":"page : Int (optional) - Current page (default: 1) limit : Int (optional) - Number of entities returned by page (default: 20) org_unit_id : Int (optional) - Id of the OrgUnit to which the changes apply (default: null) org_unit_type_id : Int (optional) - Id of the OrgUnitType to filter on, either the old OrgUnitType before the change or the new one after the change (default: null) status : Array > (optional) - One of new , validated , rejected to filter the requests (default: null) can be combined, e.g. &status=rejected&status=new parent_id : Int (optional) - Id of the old parent OrgUnit to filter on, before the change (default: null) project : Int (optional) - Id of the project to filter on. groups : List of int, comma separated (optional) - Ids of the old groups to filter on, before the change (default: null) e.g. &groups=1847,1846 forms : List of int, comma separated (optional) - Ids of the old forms to filter on, before the change (default: null) e.g. &forms=12,34 users : List of int, comma separated (optional) - Ids of the users who either created or last updated the change request (default: null) e.g. &users=56,78 user_roles : List of int, comma separated (optional) - Ids of the old user roles to filter on, specifically the roles associated with the user who created the change request (default: null) e.g. &user_roles=90,123 with_location : String (optional) - Filters the change requests based on the presence ( \"true\" ) or absence ( \"false\" ) of an old location, before the change (default: null) e.g. &with_location=true","title":"Query parameters"},{"location":"pages/dev/reference/API/org_unit_registry.html#possible-responses_1","text":"","title":"Possible responses"},{"location":"pages/dev/reference/API/org_unit_registry.html#200-ok","text":"{ \"count\": \"Long\", \"has_next\": \"Boolean\", \"has_previous\": \"Boolean\", \"page\": \"Long\", \"pages\": \"Long\", \"limit\": \"Long\", \"results\": [ { \"id\": \"Int - id in the database\", \"uuid\": \"UUID - uuid in the database\", \"org_unit_id\": \"Int - id of the OrgUnit\", \"org_unit_uuid\": \"UUID - uuid of the OrgUnit\", \"org_unit_name\": \"String - name of the OrgUnit\", \"org_unit_type_id\": \"Int - id of the current OrgUnitType\", \"org_unit_type_name\": \"String - name of the current OrgUnitType\", \"status\": \"Enum<Status> - one of `new`, `validated`, `rejected`\", \"groups\": [ { \"id\": \"Int - id of the Group\", \"name\": \"String - name of the Group\" } ], \"requested_fields\": \"Array<String> - name of the properties that were requested to change\", \"approved_fields\": \"Array<String>? - name of the properties that were approved to change\", \"rejection_comment\": \"String? - Comment about why the changes were rejected\", \"created_by\": { \"id\": \"Int - id of the User who created that request\", \"username\": \"String?\", \"first_name\": \"String?\", \"last_name\": \"String?\" }, \"created_at\": \"Timestamp\", \"updated_by\": { \"\": \"May be null\", \"id\": \"Int - id of the User\", \"username\": \"String?\", \"first_name\": \"String?\", \"last_name\": \"String?\" }, \"updated_at\": \"Timestamp?\" } ] }","title":"200 - OK"},{"location":"pages/dev/reference/API/org_unit_registry.html#400-bad-request_1","text":"page or limit cannot be parsed to a correct integer value One or more of the parameters provided couldn't be parsed One or more of the parameters provided couldn't matched to the related resource (E.g.: unknown parent_id) A parameter was given that is not recognized","title":"400 - Bad request"},{"location":"pages/dev/reference/API/org_unit_registry.html#401-unauthorized_1","text":"No authentication token or an invalid one was provided","title":"401 - Unauthorized"},{"location":"pages/dev/reference/API/org_unit_registry.html#403-forbidden","text":"User doesn't have the proper permission to access this resource.","title":"403 - Forbidden"},{"location":"pages/dev/reference/API/org_unit_registry.html#list-orgunitchangerequest-objects-mobile-only-ia-2425","text":"GET /api/mobile/orgunits/changes/?app_id=\u2026","title":"List OrgUnitChangeRequest objects - Mobile only (IA-2425)"},{"location":"pages/dev/reference/API/org_unit_registry.html#permissions_2","text":"User must be authenticated","title":"Permissions"},{"location":"pages/dev/reference/API/org_unit_registry.html#query-parameter","text":"app_id : String - Must be provided, project for which this is queried. last_sync : DateString - May be null or omitted. Limits the results to everything that was modified after this DateString last_sync filter is built with django.utils.dateparse.parse_datetime and allows: &last_sync=2023-09-26T17:21:22.921692Z &last_sync=2021-09-26T17:21:22Z &last_sync=2021-09-26T17:21:22 &last_sync=2021-09-26T17:21 page : Int (optional) - Current page (default: 1) limit : Int (optional) - Number of entities returned by page (default: 20)","title":"Query parameter"},{"location":"pages/dev/reference/API/org_unit_registry.html#possible-responses_2","text":"","title":"Possible responses"},{"location":"pages/dev/reference/API/org_unit_registry.html#200-ok_1","text":"{ \"count\": \"Long\", \"has_next\": \"Boolean\", \"has_previous\": \"Boolean\", \"page\": \"Long\", \"pages\": \"Long\", \"limit\": \"Long\", \"results\": [ { \"id\": \"Int - id in the database\", \"uuid\": \"UUID - uuid in the database\", \"org_unit_id\": \"Int - id of the OrgUnit\", \"org_unit_uuid\": \"UUID - uuid of the OrgUnit\", \"status\": \"Enum<Status> - one of `new`, `validated`, `rejected`\", \"approved_fields\": \"Array<String>? - name of the properties that were approved to change\", \"rejection_comment\": \"String? - Comment about why the changes were rejected\", \"created_at\": \"Timestamp in double\", \"updated_at\": \"Timestamp in double\", \"new_parent_id\": \"String? - id or UUID of the parent OrgUnit, may be null or omitted.\", \"new_name\": \"String? - Name of the OrgUnit, may be null or omitted.\", \"new_org_unit_type_id\": \"Int? - id of the OrgUnitType, may be null or omitted\", \"new_groups\": \"Array of Group ids? - can be empty, null or omitted. Empty means we want to remove all values\", \"new_location\": { \"\": \"New geopoint for the OrgUnit, may be null or omitted\", \"latitude\": \"Double - New latitude of the OrgUnit\", \"longitude\": \"Double - New longitude of the OrgUnit\", \"altitude\": \"Double - New altitude of the OrgUnit\" }, \"new_location_accuracy\": \"Double - New accuracy of the OrgUnit\", \"new_opening_date\": \"Timestamp in double\", \"new_closed_date\": \"Timestamp in double\", \"new_reference_instances\": [ { \"id\": \"Int\", \"uuid\": \"UUID - provided by the client\", \"form_id\": \"Int\", \"form_version_id\": \"Int\", \"created_at\": \"Timestamp in double\", \"updated_at\": \"Timestamp in double\", \"json\": \"JSONObject - contains the key/value of the instance\" } ] } ] }","title":"200 - OK"},{"location":"pages/dev/reference/API/org_unit_registry.html#400-bad-request_2","text":"app_id was not provided page or limit cannot be parsed to a correct integer value last_sync cannot be parsed to a correct date time.","title":"400 - Bad request"},{"location":"pages/dev/reference/API/org_unit_registry.html#401-unauthorized_2","text":"No authentication token or an invalid one was provided","title":"401 - Unauthorized"},{"location":"pages/dev/reference/API/org_unit_registry.html#get-an-orgunitchangerequest-object-web-only-ia-2423","text":"GET /api/orgunits/changes/{id}/","title":"Get an OrgUnitChangeRequest object - Web only (IA-2423)"},{"location":"pages/dev/reference/API/org_unit_registry.html#permissions_3","text":"User must be authenticated","title":"Permissions"},{"location":"pages/dev/reference/API/org_unit_registry.html#possible-responses_3","text":"","title":"Possible responses"},{"location":"pages/dev/reference/API/org_unit_registry.html#200-ok_2","text":"{ \"id\": \"Int - id in the database\", \"uuid\": \"UUID - uuid in the database\", \"status\": \"Enum<Status> - one of `new`, `validated`, `rejected`\", \"created_by\": { \"id\": \"Int - id of the User who created that request\", \"username\": \"String?\", \"first_name\": \"String?\", \"last_name\": \"String?\" }, \"created_at\": \"Timestamp\", \"updated_by\": { \"\": \"May be null\", \"id\": \"Int - id of the User who updated that request\", \"username\": \"String?\", \"first_name\": \"String?\", \"last_name\": \"String?\" }, \"updated_at\": \"Timestamp?\", \"requested_fields\": \"Array<String> - name of the properties that were requested to change\", \"approved_fields\": \"Array<String>? - name of the properties that were approved to change\", \"rejection_comment\": \"String? - Comment about why the changes were rejected\", \"org_unit\": { \"id\": \"Int - id in the database\", \"parent\": { \"id\": \"Int - id of the parent OrgUnit\", \"name\": \"String - name of the parent OrgUnit\" }, \"name\": \"String - Name of the OrgUnit.\", \"org_unit_type\": { \"id\": \"Int - id of the OrgUnitType\", \"name\": \"String - name of the OrgUnitType\", \"short_name\": \"String - short name of the OrgUnitType\" }, \"groups\": [ { \"id\": \"Int - id of the Group\", \"name\": \"String - name of the Group\" } ], \"location\": { \"\": \"Geopoint for the OrgUnit\", \"latitude\": \"Double - New latitude of the OrgUnit\", \"longitude\": \"Double - New longitude of the OrgUnit\", \"altitude\": \"Double - New altitude of the OrgUnit\" }, \"opening_date\": \"Timestamp?\", \"closed_date\": \"Timestamp?\", \"reference_instances\": [ \"Array of form objects - can be empty\", { \"id\": \"Int - id in the database\", \"form_id\": \"id of the form\", \"form_name\": \"Name of the form\", \"values\": [ { \"key\": \"String\", \"label\": \"String or translated object\", \"value\": \"String\" } ] } ] }, \"new_parent\": { \"\": \"May be null\", \"id\": \"Int - id of the new parent OrgUnit in the database\", \"name\": \"String? - name of the new parent OrgUnit\" }, \"new_name\": \"String? - New name of the OrgUnit, may be null or omitted\", \"new_org_unit_type\": { \"\": \"May be null\", \"id\": \"Int? - id of the new OrgUnitType\", \"name\": \"String? - name of the new OrgUnitType\", \"short_name\": \"String? - short name of the new OrgUnitType\" }, \"new_groups\": [ { \"id\": \"Int - id of the Group\", \"name\": \"String - name of the Group\" } ], \"new_location\": { \"\": \"New GeoPoint? for the OrgUnit, may be null or omitted\", \"latitude\": \"Double - New latitude of the OrgUnit\", \"longitude\": \"Double - New longitude of the OrgUnit\", \"altitude\": \"Double - New altitude of the OrgUnit\" }, \"new_location_accuracy\": \"Double? - New accuracy of the OrgUnit\", \"new_opening_date\": \"Timestamp?\", \"new_closed_date\": \"Timestamp?\", \"new_reference_instances\": [ \"Array of form objects? - may be null or omitted, cannot be empty\", { \"id\": \"Int - id in the database\", \"form_id\": \"id of the form\", \"form_name\": \"Name of the form\", \"values\": [ { \"key\": \"String\", \"label\": \"String or translated object\", \"value\": \"String\" } ] } ], \"old_name\": \"String? - Old name of the OrgUnit, may be an empty\", \"old_org_unit_type\": { \"\": \"May be null\", \"id\": \"Int? - id of the old OrgUnitType\", \"name\": \"String? - name of the old OrgUnitType\", \"short_name\": \"String? - short name of the old OrgUnitType\" }, \"old_groups\": [ \"Array of old groups objects? - may be empty\", { \"id\": \"Int - id of the Group\", \"name\": \"String - name of the Group\" } ], \"old_location\": { \"\": \"Old GeoPoint? for the OrgUnit, may be null\", \"latitude\": \"Double - New latitude of the OrgUnit\", \"longitude\": \"Double - New longitude of the OrgUnit\", \"altitude\": \"Double - New altitude of the OrgUnit\" }, \"old_opening_date\": \"Timestamp? - may be null\", \"old_closed_date\": \"Timestamp? - may be null\", \"old_reference_instances\": [ \"Array of old form instance objects? - may be empty\", { \"id\": \"Int - id in the database\", \"form_id\": \"id of the form\", \"form_name\": \"Name of the form\", \"values\": [ { \"key\": \"String\", \"label\": \"String or translated object\", \"value\": \"String\" } ] } ] }","title":"200 - OK"},{"location":"pages/dev/reference/API/org_unit_registry.html#400-bad-request_3","text":"One or more of the parameters provided couldn't be parsed One or more of the parameters provided couldn't matched to the related resource (E.g.: unknown parent_id) A parameter was given that is not recognized","title":"400 - Bad request"},{"location":"pages/dev/reference/API/org_unit_registry.html#401-unauthorized_3","text":"No authentication token or an invalid one was provided","title":"401 - Unauthorized"},{"location":"pages/dev/reference/API/org_unit_registry.html#403-forbidden_1","text":"User doesn't have the proper permission to access this resource.","title":"403 - Forbidden"},{"location":"pages/dev/reference/API/org_unit_registry.html#approve-or-reject-an-orgunitchangerequest-web-only-ia-2424","text":"PATCH /api/orgunits/changes/{id}/ API to change the status of on change request.","title":"Approve or reject an OrgUnitChangeRequest - Web only (IA-2424)"},{"location":"pages/dev/reference/API/org_unit_registry.html#permissions_4","text":"User must be authenticated User must have the ORG_UNITS_CHANGE_REQUEST_REVIEW permission","title":"Permissions"},{"location":"pages/dev/reference/API/org_unit_registry.html#body_1","text":"{ \"status\": \"Enum<Status> - One of `validated` or `rejected`\", \"approved_fields\": \"Array<Enum<Field>>? - name of the properties that were approved to change\", \"rejection_comment\": \"String? - Comment about why the changes were rejected\" }","title":"Body"},{"location":"pages/dev/reference/API/org_unit_registry.html#possible-responses_4","text":"","title":"Possible responses"},{"location":"pages/dev/reference/API/org_unit_registry.html#204-no-content","text":"Change were applied successfully","title":"204 - No content"},{"location":"pages/dev/reference/API/org_unit_registry.html#400-bad-request_4","text":"status of the change to be patched is not new status must be approved or rejected status was validated but approved_fields was null, omitted or empty: at least one approved_fields must be provided approved_fields contains one or more unknown fields status was rejected but rejection_comment was null, omitted or empty: a rejection_comment must be provided","title":"400 - Bad request"},{"location":"pages/dev/reference/API/org_unit_registry.html#list-reference_instances-objects-for-a-given-orgunit-mobile-only-ia-2420","text":"GET /api/mobile/orgunits/{id or UUID}/reference_instances?app_id=\u2026 Returns Instance objects marked as reference_instances for an OrgUnit from newest to oldest.","title":"List reference_instances objects for a given OrgUnit - Mobile only (IA-2420)"},{"location":"pages/dev/reference/API/org_unit_registry.html#permission","text":"Same as downloading instances","title":"Permission"},{"location":"pages/dev/reference/API/org_unit_registry.html#query-parameters_2","text":"page : Int (optional) - Current page (default: 1) limit : Int (optional) - Number of entities returned by page (default: 20) app_id : String - project for which this is queried. last_sync : DateString - May be null or omitted. Limits the results to everything that was modified after this DateString last_sync filter is built with django.utils.dateparse.parse_datetime and allows: &last_sync=2023-09-26T17:21:22.921692Z &last_sync=2021-09-26T17:21:22Z &last_sync=2021-09-26T17:21:22 &last_sync=2021-09-26T17:21","title":"Query parameters"},{"location":"pages/dev/reference/API/org_unit_registry.html#possible-response","text":"","title":"Possible response"},{"location":"pages/dev/reference/API/org_unit_registry.html#200-ok_3","text":"{ \"count\": \"Long\", \"instances\": [ { \"id\": \"Int\", \"uuid\": \"UUID - provided by the client\", \"form_id\": \"Int\", \"form_version_id\": \"Int\", \"created_at\": \"Timestamp in double\", \"updated_at\": \"Timestamp in double\", \"json\": \"JSONObject - contains the key/value of the instance\" } ], \"has_next\": \"Boolean\", \"has_previous\": \"Boolean\", \"page\": \"Long\", \"pages\": \"Long\", \"limit\": \"Long\" }","title":"200 - OK"},{"location":"pages/dev/reference/API/org_unit_registry.html#400-bad-request_5","text":"app_id was not provided page , limit or version_count cannot be parsed to a correct integer value last_sync cannot be parsed to a correct date time.","title":"400 - Bad request"},{"location":"pages/dev/reference/API/org_unit_registry.html#401-unauthorized_4","text":"No authentication token or an invalid one was provided (if needed)","title":"401 - Unauthorized"},{"location":"pages/dev/reference/API/org_unit_registry.html#403-forbidden_2","text":"User doesn't have the proper permission to access this resource (if needed)","title":"403 - Forbidden"},{"location":"pages/dev/reference/API/payments/payments.html","text":"PaymentStatus API # Mock-ups This API allows the status of payments linked to multiple OrgUnitChangeRequest by the same user to be updated and queried. The Django model that stores \"Payment Status\" is PaymentStatus . The PaymentStatus model has a status field which can have one of the following values: PENDING : This is the default status. It indicates that the payment is yet to be processed. SENT : This status indicates that the payment has been processed and sent. REJECTED : This status indicates that the payment was not successful and has been rejected. These statuses are stored as a list of tuples in the STATUS_CHOICES field. Get a PaymentStatus list # Permissions # User must be authenticated User needs iaso_payments permission Query Parameters - Filters # page : Int (optional) - Specifies the current page number. If not provided, the default value is 1. order : String (optional) - Specifies the order in which the results should be returned. If not provided, the default ordering value is id . limit : Int (optional) - Defines the number of entities to be returned per page. The default value is 20 if not specified. user_ids : String (optional) - A comma-separated list of User IDs associated with the payments Example: &user_ids=10,9 user_role_ids : String (optional) - A comma-separated list of User Role IDs associated with the payments Example: &user_role_ids=10,9 org_unit_id : Int (optional) - The ID of the parent organization unit linked to the change requests. This should also include child units. from_date : Date - 'YYYY-MM-DD' (optional) - The start date for when the change request has been validated. to_date : Date - 'YYYY-MM-DD' (optional) - The end date for when the change request has been validated. Possible responses # 200 - OK # { \"count\": \"Long\", \"has_next\": \"Boolean\", \"has_previous\": \"Boolean\", \"page\": \"Long\", \"pages\": \"Long\", \"limit\": \"Long\", \"results\": [ \"id\": \"Int - unique id\", \"status\": \"String - PENDING or SENT or REJECTED\", \"change_requests\": [ { \"id\": \"Int - change request unique id\", \"org_unit_id\": \"String - id or UUID of the OrgUnit to change\", } ], \"created_by\": { \"id\": \"Int - id of the User who created that payment\", \"username\": \"String - username of user\", \"first_name\": \"String - first name of user\", \"last_name\": \"String - last name of user\", }, \"created_at\": \"Timestamp\", \"updated_by\": { \"id\": \"Int - id of the User who updated that payment\", \"username\": \"String - username of user\", \"first_name\": \"String - first name of user\", \"last_name\": \"String - last name of user\", }, \"updated_at\": \"Timestamp\", \"user\": { \"id\": \"Int - user unique id\", \"username\": \"String - username of user\", \"first_name\": \"String - first name of user\", \"last_name\": \"String - last name of user\", \"user_role_id\": \"Int - user role id if one\", \"user_role_name\": \"String - user role name if one\", \"telephone\": \"String? - This type of field should be specified\", }, ] } 400 - Bad request # page or limit cannot be parsed to a correct integer value 401 - Unauthorized # No authentication token or an invalid one was provided 403 - Forbidden # User doesn't have the proper permission to access this resource. 404 - Not found # payment not fount user_id , user_role_id , org_unit_id not found Model # class PaymentStatus(models.Model): \"\"\" Model to store the status of payments linked to multiple OrgUnitChangeRequest by the same user. \"\"\" class Statuses(models.TextChoices): PENDING = \"pending\", _(\"Pending\") SENT = \"sent\", _(\"Sent\") REJECTED = \"rejected\", _(\"Rejected\") status = models.CharField(choices=Statuses.choices, default=Statuses.PENDING, max_length=40) change_requests = models.ManyToManyField(OrgUnitChangeRequest, related_name=\"payment_statuses\") user = models.ForeignKey(User, on_delete=models.CASCADE, related_name=\"payment_statuses\") created_by = models.ForeignKey(User, null=True, blank=True, on_delete=models.SET_NULL, related_name=\"payment_created_set\") updated_by = models.ForeignKey(User, null=True, blank=True, on_delete=models.SET_NULL, related_name=\"payment_updated_set\") created_at = models.DateTimeField(auto_now_add=True) updated_at = models.DateTimeField(auto_now=True) Remarks # Who creates the payments? Typically, a payment is created when a user initiates a transaction. This could be done automatically when a change request is made or manually by an admin user. The creation of a payment could be triggered in the backend code where the change request is processed. Marking change requests as paid: We could add a payment_status field to the OrgUnitChangeRequest model. This field would reference the PaymentStatus of the associated payment. When a payment is processed, We can update this field accordingly.","title":"`PaymentStatus` API"},{"location":"pages/dev/reference/API/payments/payments.html#paymentstatus-api","text":"Mock-ups This API allows the status of payments linked to multiple OrgUnitChangeRequest by the same user to be updated and queried. The Django model that stores \"Payment Status\" is PaymentStatus . The PaymentStatus model has a status field which can have one of the following values: PENDING : This is the default status. It indicates that the payment is yet to be processed. SENT : This status indicates that the payment has been processed and sent. REJECTED : This status indicates that the payment was not successful and has been rejected. These statuses are stored as a list of tuples in the STATUS_CHOICES field.","title":"PaymentStatus API"},{"location":"pages/dev/reference/API/payments/payments.html#get-a-paymentstatus-list","text":"","title":"Get a PaymentStatus list"},{"location":"pages/dev/reference/API/payments/payments.html#permissions","text":"User must be authenticated User needs iaso_payments permission","title":"Permissions"},{"location":"pages/dev/reference/API/payments/payments.html#query-parameters-filters","text":"page : Int (optional) - Specifies the current page number. If not provided, the default value is 1. order : String (optional) - Specifies the order in which the results should be returned. If not provided, the default ordering value is id . limit : Int (optional) - Defines the number of entities to be returned per page. The default value is 20 if not specified. user_ids : String (optional) - A comma-separated list of User IDs associated with the payments Example: &user_ids=10,9 user_role_ids : String (optional) - A comma-separated list of User Role IDs associated with the payments Example: &user_role_ids=10,9 org_unit_id : Int (optional) - The ID of the parent organization unit linked to the change requests. This should also include child units. from_date : Date - 'YYYY-MM-DD' (optional) - The start date for when the change request has been validated. to_date : Date - 'YYYY-MM-DD' (optional) - The end date for when the change request has been validated.","title":"Query Parameters - Filters"},{"location":"pages/dev/reference/API/payments/payments.html#possible-responses","text":"","title":"Possible responses"},{"location":"pages/dev/reference/API/payments/payments.html#200-ok","text":"{ \"count\": \"Long\", \"has_next\": \"Boolean\", \"has_previous\": \"Boolean\", \"page\": \"Long\", \"pages\": \"Long\", \"limit\": \"Long\", \"results\": [ \"id\": \"Int - unique id\", \"status\": \"String - PENDING or SENT or REJECTED\", \"change_requests\": [ { \"id\": \"Int - change request unique id\", \"org_unit_id\": \"String - id or UUID of the OrgUnit to change\", } ], \"created_by\": { \"id\": \"Int - id of the User who created that payment\", \"username\": \"String - username of user\", \"first_name\": \"String - first name of user\", \"last_name\": \"String - last name of user\", }, \"created_at\": \"Timestamp\", \"updated_by\": { \"id\": \"Int - id of the User who updated that payment\", \"username\": \"String - username of user\", \"first_name\": \"String - first name of user\", \"last_name\": \"String - last name of user\", }, \"updated_at\": \"Timestamp\", \"user\": { \"id\": \"Int - user unique id\", \"username\": \"String - username of user\", \"first_name\": \"String - first name of user\", \"last_name\": \"String - last name of user\", \"user_role_id\": \"Int - user role id if one\", \"user_role_name\": \"String - user role name if one\", \"telephone\": \"String? - This type of field should be specified\", }, ] }","title":"200 - OK"},{"location":"pages/dev/reference/API/payments/payments.html#400-bad-request","text":"page or limit cannot be parsed to a correct integer value","title":"400 - Bad request"},{"location":"pages/dev/reference/API/payments/payments.html#401-unauthorized","text":"No authentication token or an invalid one was provided","title":"401 - Unauthorized"},{"location":"pages/dev/reference/API/payments/payments.html#403-forbidden","text":"User doesn't have the proper permission to access this resource.","title":"403 - Forbidden"},{"location":"pages/dev/reference/API/payments/payments.html#404-not-found","text":"payment not fount user_id , user_role_id , org_unit_id not found","title":"404 - Not found"},{"location":"pages/dev/reference/API/payments/payments.html#model","text":"class PaymentStatus(models.Model): \"\"\" Model to store the status of payments linked to multiple OrgUnitChangeRequest by the same user. \"\"\" class Statuses(models.TextChoices): PENDING = \"pending\", _(\"Pending\") SENT = \"sent\", _(\"Sent\") REJECTED = \"rejected\", _(\"Rejected\") status = models.CharField(choices=Statuses.choices, default=Statuses.PENDING, max_length=40) change_requests = models.ManyToManyField(OrgUnitChangeRequest, related_name=\"payment_statuses\") user = models.ForeignKey(User, on_delete=models.CASCADE, related_name=\"payment_statuses\") created_by = models.ForeignKey(User, null=True, blank=True, on_delete=models.SET_NULL, related_name=\"payment_created_set\") updated_by = models.ForeignKey(User, null=True, blank=True, on_delete=models.SET_NULL, related_name=\"payment_updated_set\") created_at = models.DateTimeField(auto_now_add=True) updated_at = models.DateTimeField(auto_now=True)","title":"Model"},{"location":"pages/dev/reference/API/payments/payments.html#remarks","text":"Who creates the payments? Typically, a payment is created when a user initiates a transaction. This could be done automatically when a change request is made or manually by an admin user. The creation of a payment could be triggered in the backend code where the change request is processed. Marking change requests as paid: We could add a payment_status field to the OrgUnitChangeRequest model. This field would reference the PaymentStatus of the associated payment. When a payment is processed, We can update this field accordingly.","title":"Remarks"},{"location":"pages/dev/reference/audit/audit.html","text":"Allow keeping a history of modification done on a Model instance. It is not automatic, model that wish to implement this have to call log_modification manually when changed. Diff are stored in audit.Modification model.","title":"Audit"},{"location":"pages/dev/reference/background_tasks/background_tasks.html","text":"Background tasks & worker # Iaso queue certains functions (task) for later execution, so they can run outside an HTTP request. This is used for functions that take a long time to execute so they don't canceled in the middle by a timeout of a connection closed. e.g: bulk import, modifications or export of OrgUnits. Theses are the functions marked by the decorator @task_decorator, when called they get added to a Queue and get executed by a worker. The logic is based on a fork of the library django-beanstalk-worker from tolomea, please consult it's doc for reference. If you want to develop a new background task, the endpoint /api/copy_version/ is a good example of how to create a task and to plug it to the api. To call a function with the @task decorator, you need to pass it a User objects, in addition to the other function's arguments, this arg represent which user is launching the task. At execution time the task will receive a iaso.models.Task instance in argument that should be used to report progress. It's mandatory for the function, at the end of a successful execution to call task.report_success() to mark its proper completion.","title":"Background tasks & worker"},{"location":"pages/dev/reference/background_tasks/background_tasks.html#background-tasks-worker","text":"Iaso queue certains functions (task) for later execution, so they can run outside an HTTP request. This is used for functions that take a long time to execute so they don't canceled in the middle by a timeout of a connection closed. e.g: bulk import, modifications or export of OrgUnits. Theses are the functions marked by the decorator @task_decorator, when called they get added to a Queue and get executed by a worker. The logic is based on a fork of the library django-beanstalk-worker from tolomea, please consult it's doc for reference. If you want to develop a new background task, the endpoint /api/copy_version/ is a good example of how to create a task and to plug it to the api. To call a function with the @task decorator, you need to pass it a User objects, in addition to the other function's arguments, this arg represent which user is launching the task. At execution time the task will receive a iaso.models.Task instance in argument that should be used to report progress. It's mandatory for the function, at the end of a successful execution to call task.report_success() to mark its proper completion.","title":"Background tasks &amp; worker"},{"location":"pages/dev/reference/campaigns/subactivities.html","text":"SubActivity and SubActivityScope Models and APIs # Models # SubActivity # The SubActivity model represents a sub-activity within a round of a campaign. It has the following fields: round : A foreign key to the Round model, representing the round to which the sub-activity belongs. name : A string field representing the name of the sub-activity. age_unit : A choice field representing the unit of age targeted by the sub-activity. The choices are \"Months\" and \"Years\". age_min : An integer field representing the minimum age targeted by the sub-activity. age_max : An integer field representing the maximum age targeted by the sub-activity. start_date : A date field representing the start date of the sub-activity. end_date : A date field representing the end date of the sub-activity. SubActivityScope # The SubActivityScope model represents the scope of a sub-activity, including the selection of an organizational unit and the vaccines used. It has the following fields: group : A one-to-one field to the Group model, representing the group of organizational units for the sub-activity. subactivity : A foreign key to the SubActivity model, representing the sub-activity to which the scope belongs. vaccine : A choice field representing the vaccine used in the sub-activity. The choices are \"mOPV2\", \"nOPV2\", and \"bOPV\". APIs # The SubActivity API allows for the creation, retrieval, update, and deletion of sub-activities. The API endpoint is /api/polio/campaigns_subactivities/ . Create # To create a new sub-activity, send a POST request to the endpoint with the following data: { \"round_number\": <round_number>, \"campaign\": <campaign_obr_name>, \"name\": <subactivity_name>, \"start_date\": <start_date>, \"end_date\": <end_date>, \"scopes\": [ { \"group\": { \"name\": <group_name>, \"org_units\": [<org_unit_id>] }, \"vaccine\": <vaccine_choice> } ] } Retrieve # To retrieve all sub-activities, send a GET request to the endpoint. To retrieve a specific sub-activity, send a GET request to /api/polio/campaigns_subactivities/<subactivity_id>/ . Update # To update a sub-activity, send a PUT request to /api/polio/campaigns_subactivities/<subactivity_id>/ with the new data. Delete # To delete a sub-activity, send a DELETE request to /api/polio/campaigns_subactivities/<subactivity_id>/ . Permissions # Only authenticated users can interact with the SubActivity API. The user must belong to the same account as the campaign associated with the round of the sub-activity.","title":"SubActivity and SubActivityScope Models and APIs"},{"location":"pages/dev/reference/campaigns/subactivities.html#subactivity-and-subactivityscope-models-and-apis","text":"","title":"SubActivity and SubActivityScope Models and APIs"},{"location":"pages/dev/reference/campaigns/subactivities.html#models","text":"","title":"Models"},{"location":"pages/dev/reference/campaigns/subactivities.html#subactivity","text":"The SubActivity model represents a sub-activity within a round of a campaign. It has the following fields: round : A foreign key to the Round model, representing the round to which the sub-activity belongs. name : A string field representing the name of the sub-activity. age_unit : A choice field representing the unit of age targeted by the sub-activity. The choices are \"Months\" and \"Years\". age_min : An integer field representing the minimum age targeted by the sub-activity. age_max : An integer field representing the maximum age targeted by the sub-activity. start_date : A date field representing the start date of the sub-activity. end_date : A date field representing the end date of the sub-activity.","title":"SubActivity"},{"location":"pages/dev/reference/campaigns/subactivities.html#subactivityscope","text":"The SubActivityScope model represents the scope of a sub-activity, including the selection of an organizational unit and the vaccines used. It has the following fields: group : A one-to-one field to the Group model, representing the group of organizational units for the sub-activity. subactivity : A foreign key to the SubActivity model, representing the sub-activity to which the scope belongs. vaccine : A choice field representing the vaccine used in the sub-activity. The choices are \"mOPV2\", \"nOPV2\", and \"bOPV\".","title":"SubActivityScope"},{"location":"pages/dev/reference/campaigns/subactivities.html#apis","text":"The SubActivity API allows for the creation, retrieval, update, and deletion of sub-activities. The API endpoint is /api/polio/campaigns_subactivities/ .","title":"APIs"},{"location":"pages/dev/reference/campaigns/subactivities.html#create","text":"To create a new sub-activity, send a POST request to the endpoint with the following data: { \"round_number\": <round_number>, \"campaign\": <campaign_obr_name>, \"name\": <subactivity_name>, \"start_date\": <start_date>, \"end_date\": <end_date>, \"scopes\": [ { \"group\": { \"name\": <group_name>, \"org_units\": [<org_unit_id>] }, \"vaccine\": <vaccine_choice> } ] }","title":"Create"},{"location":"pages/dev/reference/campaigns/subactivities.html#retrieve","text":"To retrieve all sub-activities, send a GET request to the endpoint. To retrieve a specific sub-activity, send a GET request to /api/polio/campaigns_subactivities/<subactivity_id>/ .","title":"Retrieve"},{"location":"pages/dev/reference/campaigns/subactivities.html#update","text":"To update a sub-activity, send a PUT request to /api/polio/campaigns_subactivities/<subactivity_id>/ with the new data.","title":"Update"},{"location":"pages/dev/reference/campaigns/subactivities.html#delete","text":"To delete a sub-activity, send a DELETE request to /api/polio/campaigns_subactivities/<subactivity_id>/ .","title":"Delete"},{"location":"pages/dev/reference/campaigns/subactivities.html#permissions","text":"Only authenticated users can interact with the SubActivity API. The user must belong to the same account as the campaign associated with the round of the sub-activity.","title":"Permissions"},{"location":"pages/dev/reference/data_model_glossary/data_model_glossary.html","text":"Some terminology in Iaso come from DHIS2, some from ODK which mean that it can be a bit confusing. We will highlight some equivalences that might help you. This is not (yet) the complete Data Model, but here are the main concepts/model in Iaso: Iaso is multi tenant. Tenant are called and represented by the model Account . It represents roughly one client org or country. It also represents the natural limit of right for a user. Each Django's User has a linked Iaso Profile that link it to an Account and store extra parameters for the user. Each tenant can have multiple Project . Projects are linked to one android version App via the app_id . We use the link to control what a user can see from that app. DHIS2 is a standard server application and web UI in the industry to handle Health Data. Iaso can import and export data (forms and org unit) to it. OrgUnit (Organizational Unit) is a Node of the GeoRegistry tree. e.g a particular Country, City or Hospital. each belonging to each other via a parent relationship. They can have a type OrgUnitType e.g. Country, City, Hospital they can belong to multiple Group , e.g. Urban Region or Campaign 2017 DHIS2 has the concept of Group but not Type so when importing from a DHIS2 Instance all the type will be Unknown and OrgUnit will belong to group like Clinic GroupSet are Group of group. Used when we export Group to DHIS2 OrgUnit may have a position in space, it can be an area, the geom field is then used, or just a Point, the location field is then used. It's technically possible to have both a OrgUnit may have no geographical info a OrgUnit may geographically be outside its parent. DataSource links OrgUnit and Group imported from the same source, e.g a DHIS2 instance, a CSV or a GeoPackage. A source_ref on the imported instance is used to keep the reference from the original source, so we can match it again in the future (when updating the import or exporting it back) SourceVersion is used to keep each version separated. e.g each time we import from DHIS2 we create a new version. OrgUnit (for their parent) and Group should only reference other OrgUnit and Group in the same version. (This is not enforced everywhere yet) Task are asynchronous function that will be run by a background worker in production. eg: Importing Data from DHIS2. see Worker section below for more info. Form is the definition of a Form (list of question and their presentation). The model contain the metadata, the actual definition is done in a XSLForm as an attached file. Form are linked to one or more Project. This is used to know which Form are presented in the Mobile App. Form can have multiple versions Instance or Form instance is the Submission of a form. A form that has actually been filed by a user. Instance can be GeoTagged and/or linked to a OrgUnit Note: We are moving to use Submission everywhere in the UI, but it is still in progress. please submit PR. Submission cannot be done via the Iaso UI itself but through Enketo or the Mobile App. APIImport are used to log some request from the mobile app so we can replay them in case of error. See vector_control wiki audit.Modification are used to keep a history of modification on some models (mainly orgunit). See audit wiki Link are used to match two OrgUnit (in different sources or not) that should be the same in the real world. Links have a confidence score indicating how much we trust that the two OrgUnit are actually the same. They are usually generated via AlgorithmRun , or the matching is done in a Notebook and uploaded via the API.","title":"Data model glossary"},{"location":"pages/dev/reference/docker/docker.html","text":"Docker # Run commands inside the docker container # Each docker container uses the entrypoint. The entrypoint.sh script offers a range of commands to start services or run commands. The full list of commands can be seen in the script. The pattern to run a command is docker compose run <container-name> <entrypoint-command> <...args> The following are some examples: Run tests docker compose exec iaso ./manage.py test Create a shell inside the container docker compose run iaso bash Run a shell command docker compose run iaso eval curl http://google.com Run Django manage.py docker compose exec iaso ./manage.py help Launch a python shell docker compose exec iaso ./manage.py shell Launch a postgresql shell docker compose exec iaso ./manage.py dbshell Create pending ORM migration files docker compose exec iaso ./manage.py makemigrations Apply pending ORM migrations docker compose exec iaso ./manage.py migrate Show ORM migrations docker compose exec iaso ./manage.py showmigrations To run a background worker docker compose run iaso manage tasks_worker Containers and services # iaso The python backend in Django webpack The JS frontend in react db PostgreSQL database All the container definitions for development can be found in docker-compose.yml . docker compose run vs. docker compose exec # docker compose run launches a new docker container, docker compose exec launches a command in the existing container. So run will ensure the dependencies like the database are up before executing. exec main advantage is that it is faster but the containers must already be running (launched manually) run will launch the entrypoint.sh script but exec will take a bash command to run which is why if you want to run the django manage.py you will need to use run iaso manage but exec iaso ./manage.py Also take care that run unless evoked with the --rm will leave you with a lot of left over containers that take up disk space and need to be cleaned occasionally with docker compose rm to reclaim disk space.","title":"Docker"},{"location":"pages/dev/reference/docker/docker.html#docker","text":"","title":"Docker"},{"location":"pages/dev/reference/docker/docker.html#run-commands-inside-the-docker-container","text":"Each docker container uses the entrypoint. The entrypoint.sh script offers a range of commands to start services or run commands. The full list of commands can be seen in the script. The pattern to run a command is docker compose run <container-name> <entrypoint-command> <...args> The following are some examples: Run tests docker compose exec iaso ./manage.py test Create a shell inside the container docker compose run iaso bash Run a shell command docker compose run iaso eval curl http://google.com Run Django manage.py docker compose exec iaso ./manage.py help Launch a python shell docker compose exec iaso ./manage.py shell Launch a postgresql shell docker compose exec iaso ./manage.py dbshell Create pending ORM migration files docker compose exec iaso ./manage.py makemigrations Apply pending ORM migrations docker compose exec iaso ./manage.py migrate Show ORM migrations docker compose exec iaso ./manage.py showmigrations To run a background worker docker compose run iaso manage tasks_worker","title":"Run commands inside the docker container"},{"location":"pages/dev/reference/docker/docker.html#containers-and-services","text":"iaso The python backend in Django webpack The JS frontend in react db PostgreSQL database All the container definitions for development can be found in docker-compose.yml .","title":"Containers and services"},{"location":"pages/dev/reference/docker/docker.html#docker-compose-run-vs-docker-compose-exec","text":"docker compose run launches a new docker container, docker compose exec launches a command in the existing container. So run will ensure the dependencies like the database are up before executing. exec main advantage is that it is faster but the containers must already be running (launched manually) run will launch the entrypoint.sh script but exec will take a bash command to run which is why if you want to run the django manage.py you will need to use run iaso manage but exec iaso ./manage.py Also take care that run unless evoked with the --rm will leave you with a lot of left over containers that take up disk space and need to be cleaned occasionally with docker compose rm to reclaim disk space.","title":"docker compose run vs. docker compose exec"},{"location":"pages/dev/reference/entities_in_iaso/entities_in_iaso.html","text":"Table of contents # Table of contents 2 What are entities? 3 How to create an entity? 3 Enable the feature 3 Create and upload the profile form 3 Create the entity type 4 Create an entity 4 How to configure how we display an entity? 6 In the web interface 6 In the list 6 In the details screen 7 In the mobile application 7 In the list 7 In the details screen 8 Searching for an entity 8 On the web 8 In the application 9 What are workflows? 9 Create a workflow 9 Follow-ups and changes 10 Follow-ups 10 Changes 10 Using values from the profile in subsequent forms 11 Publishing workflows 11 What are entities? # We call an \u201c Entity \u201d anything that can move or be moved and that we want to track through time and Org Units. For example, a beneficiary, a car, a vaccination card, etc. To differentiate between different kinds of entities, Iaso has a concept of \u201c Entity Type \u201d. Iaso heavily relies on XLSForms , and entities are no exceptions. Therefore, an entity is represented by a submission to a form. This submission is referred to as the profile . The entity type defines which form has to be filled in. How to create an entity? # Enable the feature # In order to create an entity, your project must first enable the entity feature flag. You can set this flag either during its creation or by updating it later. Create and upload the profile form # Using the sheet application of your choosing, create an XLSForm which will contain all the questions related to your entity that are either fixed (I.e., first name and last name) or can evolve through time (I.e., a program to which an entity can be affiliated to). Upload it on the server using the web application. Note: The questions that can evolve through time should not be editable. Create the entity type # In the entity types screen, click on the \u201cCREATE\u201d button. Give the entity type a name and select the newly uploaded form as a reference form: Note: We\u2019ll see later what \u201cList fields\u201d and \u201cDetail info fields\u201d are. Create an entity # In the mobile application, make sure that the data has been refreshed and are up to date with the backend server. You will now be able to see the entity screen. At the moment, it is not possible to create an Entity from a web interface. Click the \u201cAdd\u201d button in the application. Select the entity type you want to create. You will be prompted to confirm your selection. You can then fill out the form to finalize your first entity. How to configure how we display an entity? # Within the entity type\u2019s configuration, it is possible for administrators to define which questions are displayed within lists and within the details screen. This impacts how the web and mobile applications display entities, as shown below. In the web interface # In the list # In the details screen # In the mobile application # In the list # In the details screen # Searching for an entity # On the web # In the beneficiary list, you can filter by type and/or enter a query to filter based on the identifier or any of the list fields values. In the application # Clicking on the magnifying glass icon on the entity screen will lead you to the list of all entities and allow you to filter them quickly based on the identifier or any of the list fields values. If you need a more fine-grained selection, you can click on the funnel icon, select a type and fill out the search form (second picture) What are workflows? # As stated before, an entity is tracked through time and Org Units. In order to achieve this, Iaso links the subsequent submissions for an entity together and allows subsequent submissions to change the profile. In order for you to choose which forms should be presented next and what values override the properties of the profile, you can define a workflow. High Level Schema of the workflow's models # classDiagram class WorkflowVersion { Workflow workflow String name Form reference_form Enum status } class Workflow { EntityType entity_type } class EntityType { String name Form reference_form Account account Bool is_active } class Form { String form_id String namer String device_field String location_field String correlation_field Bool correlatable JSON possible_fields String period_ty pe Bool single_per_period Int periods_before_allowed Int periods_after_allowed Bool derived UUID uuid } class FormVersion { Form form File file File xls_file JSON form_descriptor String version_id } WorkflowVersion --> Form : Foreign Key (reference_form) EntityType --> Form : Foreign Key (reference_form) EntityType -- Workflow : One To One (entity_type) WorkflowVersion --> Workflow : Foreign Key (form) FormVersion --> Form : Foreign Key (form) Create a workflow # In the entity types\u2019 list, click on the workflow icon In the list of the workflow versions, create the \u201cCREATE\u201d button and give the version a name: Follow-ups and changes # Follow-ups # They represent the next possible forms based on the state of the profile. They are based on a condition. In the following example, the mobile application will offer \u201cU5 Registration WFP\u201d as the next possible form if the first name is \u201cBill\u201d. Reminder : \u201cFirst Name\u201d is one of the questions in the Entity Type\u2019s form. Changes # They represent the mapping of what value from a form will change the values in the profile. In the example below, the \u201cTarget form\u201d is the Entity Type\u2019s form, and the \u201cSource form\u201d is the subsequent submission. When a \u201cU5 Registration WFP\u201d form is filled out, the value entered in \u201cChild\u2019s Age in months\u201d will be copied into the profile\u2019s \u201cAge (Months)\u201d question. And the value entered in \u201cChild\u2019s Name\u201d will be copied into the profile\u2019s \u201cFirst Name\u201d question. Using values from the profile in subsequent forms # Sometimes, you want a subsequent form to use values from the profile. In order to do so, just add a question with the same identifier and type as the value from the profile. I.e., Let\u2019s assume the profile has 2 questions of type \u201ctext\u201d: first_name and last_name. By adding a read-only similar question in your subsequent forms, the value will be available to you. Publishing workflows # Once a workflow version has been published, it is marked as finalized, and it cannot be edited anymore. Only workflows in \u201cdraft\u201d can be edited. If you want to edit a finalized workflow, you first need to duplicate it using the \u201cCopy version\u201d button. A new draft version is then created with the same content.","title":"Table of contents"},{"location":"pages/dev/reference/entities_in_iaso/entities_in_iaso.html#table-of-contents","text":"Table of contents 2 What are entities? 3 How to create an entity? 3 Enable the feature 3 Create and upload the profile form 3 Create the entity type 4 Create an entity 4 How to configure how we display an entity? 6 In the web interface 6 In the list 6 In the details screen 7 In the mobile application 7 In the list 7 In the details screen 8 Searching for an entity 8 On the web 8 In the application 9 What are workflows? 9 Create a workflow 9 Follow-ups and changes 10 Follow-ups 10 Changes 10 Using values from the profile in subsequent forms 11 Publishing workflows 11","title":"Table of contents"},{"location":"pages/dev/reference/entities_in_iaso/entities_in_iaso.html#what-are-entities","text":"We call an \u201c Entity \u201d anything that can move or be moved and that we want to track through time and Org Units. For example, a beneficiary, a car, a vaccination card, etc. To differentiate between different kinds of entities, Iaso has a concept of \u201c Entity Type \u201d. Iaso heavily relies on XLSForms , and entities are no exceptions. Therefore, an entity is represented by a submission to a form. This submission is referred to as the profile . The entity type defines which form has to be filled in.","title":"What are entities?"},{"location":"pages/dev/reference/entities_in_iaso/entities_in_iaso.html#how-to-create-an-entity","text":"","title":"How to create an entity?"},{"location":"pages/dev/reference/entities_in_iaso/entities_in_iaso.html#enable-the-feature","text":"In order to create an entity, your project must first enable the entity feature flag. You can set this flag either during its creation or by updating it later.","title":"Enable the feature"},{"location":"pages/dev/reference/entities_in_iaso/entities_in_iaso.html#create-and-upload-the-profile-form","text":"Using the sheet application of your choosing, create an XLSForm which will contain all the questions related to your entity that are either fixed (I.e., first name and last name) or can evolve through time (I.e., a program to which an entity can be affiliated to). Upload it on the server using the web application. Note: The questions that can evolve through time should not be editable.","title":"Create and upload the profile form"},{"location":"pages/dev/reference/entities_in_iaso/entities_in_iaso.html#create-the-entity-type","text":"In the entity types screen, click on the \u201cCREATE\u201d button. Give the entity type a name and select the newly uploaded form as a reference form: Note: We\u2019ll see later what \u201cList fields\u201d and \u201cDetail info fields\u201d are.","title":"Create the entity type"},{"location":"pages/dev/reference/entities_in_iaso/entities_in_iaso.html#create-an-entity","text":"In the mobile application, make sure that the data has been refreshed and are up to date with the backend server. You will now be able to see the entity screen. At the moment, it is not possible to create an Entity from a web interface. Click the \u201cAdd\u201d button in the application. Select the entity type you want to create. You will be prompted to confirm your selection. You can then fill out the form to finalize your first entity.","title":"Create an entity"},{"location":"pages/dev/reference/entities_in_iaso/entities_in_iaso.html#how-to-configure-how-we-display-an-entity","text":"Within the entity type\u2019s configuration, it is possible for administrators to define which questions are displayed within lists and within the details screen. This impacts how the web and mobile applications display entities, as shown below.","title":"How to configure how we display an entity?"},{"location":"pages/dev/reference/entities_in_iaso/entities_in_iaso.html#in-the-web-interface","text":"","title":"In the web interface"},{"location":"pages/dev/reference/entities_in_iaso/entities_in_iaso.html#in-the-list","text":"","title":"In the list"},{"location":"pages/dev/reference/entities_in_iaso/entities_in_iaso.html#in-the-details-screen","text":"","title":"In the details screen"},{"location":"pages/dev/reference/entities_in_iaso/entities_in_iaso.html#in-the-mobile-application","text":"","title":"In the mobile application"},{"location":"pages/dev/reference/entities_in_iaso/entities_in_iaso.html#in-the-list_1","text":"","title":"In the list"},{"location":"pages/dev/reference/entities_in_iaso/entities_in_iaso.html#in-the-details-screen_1","text":"","title":"In the details screen"},{"location":"pages/dev/reference/entities_in_iaso/entities_in_iaso.html#searching-for-an-entity","text":"","title":"Searching for an entity"},{"location":"pages/dev/reference/entities_in_iaso/entities_in_iaso.html#on-the-web","text":"In the beneficiary list, you can filter by type and/or enter a query to filter based on the identifier or any of the list fields values.","title":"On the web"},{"location":"pages/dev/reference/entities_in_iaso/entities_in_iaso.html#in-the-application","text":"Clicking on the magnifying glass icon on the entity screen will lead you to the list of all entities and allow you to filter them quickly based on the identifier or any of the list fields values. If you need a more fine-grained selection, you can click on the funnel icon, select a type and fill out the search form (second picture)","title":"In the application"},{"location":"pages/dev/reference/entities_in_iaso/entities_in_iaso.html#what-are-workflows","text":"As stated before, an entity is tracked through time and Org Units. In order to achieve this, Iaso links the subsequent submissions for an entity together and allows subsequent submissions to change the profile. In order for you to choose which forms should be presented next and what values override the properties of the profile, you can define a workflow.","title":"What are workflows?"},{"location":"pages/dev/reference/entities_in_iaso/entities_in_iaso.html#high-level-schema-of-the-workflows-models","text":"classDiagram class WorkflowVersion { Workflow workflow String name Form reference_form Enum status } class Workflow { EntityType entity_type } class EntityType { String name Form reference_form Account account Bool is_active } class Form { String form_id String namer String device_field String location_field String correlation_field Bool correlatable JSON possible_fields String period_ty pe Bool single_per_period Int periods_before_allowed Int periods_after_allowed Bool derived UUID uuid } class FormVersion { Form form File file File xls_file JSON form_descriptor String version_id } WorkflowVersion --> Form : Foreign Key (reference_form) EntityType --> Form : Foreign Key (reference_form) EntityType -- Workflow : One To One (entity_type) WorkflowVersion --> Workflow : Foreign Key (form) FormVersion --> Form : Foreign Key (form)","title":"High Level Schema of the workflow's models"},{"location":"pages/dev/reference/entities_in_iaso/entities_in_iaso.html#create-a-workflow","text":"In the entity types\u2019 list, click on the workflow icon In the list of the workflow versions, create the \u201cCREATE\u201d button and give the version a name:","title":"Create a workflow"},{"location":"pages/dev/reference/entities_in_iaso/entities_in_iaso.html#follow-ups-and-changes","text":"","title":"Follow-ups and changes"},{"location":"pages/dev/reference/entities_in_iaso/entities_in_iaso.html#follow-ups","text":"They represent the next possible forms based on the state of the profile. They are based on a condition. In the following example, the mobile application will offer \u201cU5 Registration WFP\u201d as the next possible form if the first name is \u201cBill\u201d. Reminder : \u201cFirst Name\u201d is one of the questions in the Entity Type\u2019s form.","title":"Follow-ups"},{"location":"pages/dev/reference/entities_in_iaso/entities_in_iaso.html#changes","text":"They represent the mapping of what value from a form will change the values in the profile. In the example below, the \u201cTarget form\u201d is the Entity Type\u2019s form, and the \u201cSource form\u201d is the subsequent submission. When a \u201cU5 Registration WFP\u201d form is filled out, the value entered in \u201cChild\u2019s Age in months\u201d will be copied into the profile\u2019s \u201cAge (Months)\u201d question. And the value entered in \u201cChild\u2019s Name\u201d will be copied into the profile\u2019s \u201cFirst Name\u201d question.","title":"Changes"},{"location":"pages/dev/reference/entities_in_iaso/entities_in_iaso.html#using-values-from-the-profile-in-subsequent-forms","text":"Sometimes, you want a subsequent form to use values from the profile. In order to do so, just add a question with the same identifier and type as the value from the profile. I.e., Let\u2019s assume the profile has 2 questions of type \u201ctext\u201d: first_name and last_name. By adding a read-only similar question in your subsequent forms, the value will be available to you.","title":"Using values from the profile in subsequent forms"},{"location":"pages/dev/reference/entities_in_iaso/entities_in_iaso.html#publishing-workflows","text":"Once a workflow version has been published, it is marked as finalized, and it cannot be edited anymore. Only workflows in \u201cdraft\u201d can be edited. If you want to edit a finalized workflow, you first need to duplicate it using the \u201cCopy version\u201d button. A new draft version is then created with the same content.","title":"Publishing workflows"},{"location":"pages/dev/reference/env_variables/env_variables.html","text":"Environnement variables # DB connection related # the url is build based on the following env variables RDS_USERNAME RDS_PASSWORD RDS_HOSTNAME RDS_DB_NAME RDS_PORT the SQL dashboard use a dedicated user/password with readonly access to the data DB_READONLY_USERNAME DB_READONLY_PASSWORD AWS related # Storing the various files like js/css/... static assets raw forms (xlsform), submissions (xml and media),... is done in s3 (or an s3 compatible api like minio) AWS_ACCESS_KEY_ID: AWS_SECRET_ACCESS_KEY: AWS_S3_REGION_NAME AWS_STORAGE_BUCKET_NAME: AWS_S3_ENDPOINT_URL: (used to for ex to point to minio) for async task BACKGROUND_TASK_SERVICE : default to SQS : possible values are SQS POSTGRES BEANSTALK_SQS_REGION BEANSTALK_SQS_URL Security Settings # Django settings # Iaso allows to set some of Django security settings as environment variable. To activate these features set the environment variable to \"true\" . Default is \"false\" CSRF_COOKIE_HTTPONLY CSRF_COOKIE_SECURE SESSION_COOKIE_SECURE CORS # It is possible to setup a IASO server with CORS authorizing access from any server with the following environment variable \"ENABLE_CORS\" . Default is \"true\" Disabling login through passwords # Set the environment variable DISABLE_PASSWORD_LOGINS to the value \"true\" in case you wish to deactivate passwords using login: in the basic login page to connect to the admin through /api/token , which is used by default by the mobile application Sentry related # If you don't provide a SENTRY_URL, sentry won't be configured name optional default value description --- SENTRY_URL true - url specific to your sentry account SENTRY_ENVIRONMENT true development environnement (dev, staging, prod,...) SENTRY_TRACES_SAMPLE_RATE true 0.1 float between 0 and 1 : send 10% SENTRY_ERRORS_SAMPLE_RATE true 1.0 float between 0 and 1 : send everything SENTRY_ERRORS_HTTPERROR_SAMPLE_RATE true 0.8 float between 0 and 1 : send 80% of the errors Maintenance mode # MAINTENANCE_MODE (default is \"false\" ) If you need to set up IASO in maintenance mode, meaning that it will display at / a page indicating that the server is under maintenance, and give a 404 answer to all requests except for /health or /_health (wich we encourage to use for status monitoring), you can set the environment variable MAINTENANCE_MODE to the value \"true\"","title":"Environnement variables"},{"location":"pages/dev/reference/env_variables/env_variables.html#environnement-variables","text":"","title":"Environnement variables"},{"location":"pages/dev/reference/env_variables/env_variables.html#db-connection-related","text":"the url is build based on the following env variables RDS_USERNAME RDS_PASSWORD RDS_HOSTNAME RDS_DB_NAME RDS_PORT the SQL dashboard use a dedicated user/password with readonly access to the data DB_READONLY_USERNAME DB_READONLY_PASSWORD","title":"DB connection related"},{"location":"pages/dev/reference/env_variables/env_variables.html#aws-related","text":"Storing the various files like js/css/... static assets raw forms (xlsform), submissions (xml and media),... is done in s3 (or an s3 compatible api like minio) AWS_ACCESS_KEY_ID: AWS_SECRET_ACCESS_KEY: AWS_S3_REGION_NAME AWS_STORAGE_BUCKET_NAME: AWS_S3_ENDPOINT_URL: (used to for ex to point to minio) for async task BACKGROUND_TASK_SERVICE : default to SQS : possible values are SQS POSTGRES BEANSTALK_SQS_REGION BEANSTALK_SQS_URL","title":"AWS related"},{"location":"pages/dev/reference/env_variables/env_variables.html#security-settings","text":"","title":"Security Settings"},{"location":"pages/dev/reference/env_variables/env_variables.html#django-settings","text":"Iaso allows to set some of Django security settings as environment variable. To activate these features set the environment variable to \"true\" . Default is \"false\" CSRF_COOKIE_HTTPONLY CSRF_COOKIE_SECURE SESSION_COOKIE_SECURE","title":"Django settings"},{"location":"pages/dev/reference/env_variables/env_variables.html#cors","text":"It is possible to setup a IASO server with CORS authorizing access from any server with the following environment variable \"ENABLE_CORS\" . Default is \"true\"","title":"CORS"},{"location":"pages/dev/reference/env_variables/env_variables.html#disabling-login-through-passwords","text":"Set the environment variable DISABLE_PASSWORD_LOGINS to the value \"true\" in case you wish to deactivate passwords using login: in the basic login page to connect to the admin through /api/token , which is used by default by the mobile application","title":"Disabling login through passwords"},{"location":"pages/dev/reference/env_variables/env_variables.html#sentry-related","text":"If you don't provide a SENTRY_URL, sentry won't be configured name optional default value description --- SENTRY_URL true - url specific to your sentry account SENTRY_ENVIRONMENT true development environnement (dev, staging, prod,...) SENTRY_TRACES_SAMPLE_RATE true 0.1 float between 0 and 1 : send 10% SENTRY_ERRORS_SAMPLE_RATE true 1.0 float between 0 and 1 : send everything SENTRY_ERRORS_HTTPERROR_SAMPLE_RATE true 0.8 float between 0 and 1 : send 80% of the errors","title":"Sentry related"},{"location":"pages/dev/reference/env_variables/env_variables.html#maintenance-mode","text":"MAINTENANCE_MODE (default is \"false\" ) If you need to set up IASO in maintenance mode, meaning that it will display at / a page indicating that the server is under maintenance, and give a 404 answer to all requests except for /health or /_health (wich we encourage to use for status monitoring), you can set the environment variable MAINTENANCE_MODE to the value \"true\"","title":"Maintenance mode"},{"location":"pages/dev/reference/front-end_reference/front-end_reference.html","text":"Front-end reference # Frontend assets include JS, CSS, translations and images. They are all handled by webpack. Most of the structure is taken from this blog post: http://owaislone.org/blog/webpack-plus-reactjs-and-django/ Frontend assets are mounted on the pages via the django-webpack-loader <https://github.com/owais/django-webpack-loader> __ Build # The 2 builds, dev and prod # There are two webpack configuration files: webpack.dev.js and webpack.prod.js . A JS production build is created inside the docker-file, via npm run build the start_dev entry point starts a webpack development server, that watches assets, rebuilds and does hot reloading of JS Components. CSS Build # The CSS build is separate, and can contain both .sass and .css files. They spit out a webpack build called styles.css . JS Build # Each page has their own JS entry point (needs to be defined in both webpack files). On top of that, they load a common chunk, containing react , react-intl and other stuff that the webpack common chunk plugin finds is shared between the apps. Including a JS bundle via django-webpack-loader ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ If we have created a new JS app MyCustomApp in hat/assets/js/apps/ . The entrypoint should be /dashboard/my-custom-app Folders and files affected:: + hat/ + assets/ + js/ + apps/ + MyCustomApp . index.js . MyCustomApp.js . MyCustomAppContainer.js + dashboard/ . urls.py . views.py + templates/ + dashboard/ . my_custom_app.html . webpack.dev.js . webpack.prod.js These are the steps to visualize it within the dashboard: In hat/webpack.dev.js include a new entry . 'my_custom_app': [ 'webpack-dev-server/client?' + WEBPACK_URL, 'webpack/hot/only-dev-server', './assets/js/apps/MyCustomApp/index' ], In hat/webpack.prod.js include a new entry . 'my_custom_app': './assets/js/apps/MyCustomApp/index', In hat/dashboard/views.py include a new view. @login_required() # needs login? @permission_required('cases.view') # the needed permissions @require_http_methods(['GET']) # http methods allowed def my_custom_app(request: HttpRequest) -> HttpResponse: return render(request, 'dashboard/my_custom_app.html') In hat/dashboard/urls.py include a new url pattern. url(r'^my-custom-app/.*$', views.my_custom_app, name='my_custom_app'), url(r'^my-custom-app/.*$', views.my_custom_app, name='my_custom_app'), In hat/templates/dashboard create a new template file my_custom_app.html . {% extends 'app.html' %} {% load i18n %} {% load render_bundle from webpack_loader %} {% block header %} <h1 class=\"header__title\">{% trans 'My Custom App' %}</h1> {% endblock %} {% block content %} <div class=\"content\"> <div id=\"app-container\"></div> </div> {% render_bundle 'common' %} {% render_bundle 'my_custom_app' %} <script> HAT.MyCustomApp.default( document.getElementById('app-container'), '/dashboard/my-custom-app/' ) </script> {% endblock %} Testing the production build # . Stop any containers that might be currently running. # . Start the containers with: # .. code:: shell TEST_PROD=true docker compose up When the setup is run with TEST_PROD=true , it will exit the unneeded containers webpack and jupyter . It will also run the webpack build during startup, so that there is no need to rebuild the image for that. JS Unit Testing # docker compose run hat test_js Adding new assets in package.json # Unfortunately, for now you need to rebuild the container after adding or upgrading packages in package.json . .. code:: shell docker compose build or .. code:: shell docker compose up --build Translations # Translations are extracted on the first webpack build. Just like the django translation strings; translations are downloaded for every Travis CI <https://travis-ci.com> __ build, and uploaded on the development branch. Set up VSCode for front-end development # See also: this pull request <https://github.com/BLSQ/iaso/pull/120> __ The script show-lint-problems can be turned into a VSCode task that will show all linter errors in VSCode's PROBLEMS Tab. Steps to follow: Go to Terminal>Configure task Select npm: show-lint-problems Add $eslint-stylish to the problemMatcher array Run the task: Terminal>Run Task...> npm: show-lint-problems. IMPORTANT: you need to run the task this way. Running the script directly from the terminal using npm will not enable VS Code to display the problems in the PROBLEMS tab You should be able to see and track the problems through the dedicated tab. CAUTION: if you navigate to a file through the tab, then close the file, it will be removed from the problems list, even if it wasn't changed. This seems to be a problem with using npm through VSCode's tasks Depend on bluesquare-components library # See the library's README <https://github.com/BLSQ/bluesquare-components/blob/main/README.md> __ for the general setup. When depending on a local version of the library: Your local folder should be on the same level as the iaso folder, so that the path to the tgz file in your package.json is : ../bluesquare-components/bluesquare-components-0.1.0.tgz Run docker compose build --build-arg LIBRARY=<name-of-the-library-image>","title":"Front-end reference"},{"location":"pages/dev/reference/front-end_reference/front-end_reference.html#front-end-reference","text":"Frontend assets include JS, CSS, translations and images. They are all handled by webpack. Most of the structure is taken from this blog post: http://owaislone.org/blog/webpack-plus-reactjs-and-django/ Frontend assets are mounted on the pages via the django-webpack-loader <https://github.com/owais/django-webpack-loader> __","title":"Front-end reference"},{"location":"pages/dev/reference/front-end_reference/front-end_reference.html#build","text":"","title":"Build"},{"location":"pages/dev/reference/front-end_reference/front-end_reference.html#the-2-builds-dev-and-prod","text":"There are two webpack configuration files: webpack.dev.js and webpack.prod.js . A JS production build is created inside the docker-file, via npm run build the start_dev entry point starts a webpack development server, that watches assets, rebuilds and does hot reloading of JS Components.","title":"The 2 builds, dev and prod"},{"location":"pages/dev/reference/front-end_reference/front-end_reference.html#css-build","text":"The CSS build is separate, and can contain both .sass and .css files. They spit out a webpack build called styles.css .","title":"CSS Build"},{"location":"pages/dev/reference/front-end_reference/front-end_reference.html#js-build","text":"Each page has their own JS entry point (needs to be defined in both webpack files). On top of that, they load a common chunk, containing react , react-intl and other stuff that the webpack common chunk plugin finds is shared between the apps. Including a JS bundle via django-webpack-loader ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ If we have created a new JS app MyCustomApp in hat/assets/js/apps/ . The entrypoint should be /dashboard/my-custom-app Folders and files affected:: + hat/ + assets/ + js/ + apps/ + MyCustomApp . index.js . MyCustomApp.js . MyCustomAppContainer.js + dashboard/ . urls.py . views.py + templates/ + dashboard/ . my_custom_app.html . webpack.dev.js . webpack.prod.js These are the steps to visualize it within the dashboard: In hat/webpack.dev.js include a new entry . 'my_custom_app': [ 'webpack-dev-server/client?' + WEBPACK_URL, 'webpack/hot/only-dev-server', './assets/js/apps/MyCustomApp/index' ], In hat/webpack.prod.js include a new entry . 'my_custom_app': './assets/js/apps/MyCustomApp/index', In hat/dashboard/views.py include a new view. @login_required() # needs login? @permission_required('cases.view') # the needed permissions @require_http_methods(['GET']) # http methods allowed def my_custom_app(request: HttpRequest) -> HttpResponse: return render(request, 'dashboard/my_custom_app.html') In hat/dashboard/urls.py include a new url pattern. url(r'^my-custom-app/.*$', views.my_custom_app, name='my_custom_app'), url(r'^my-custom-app/.*$', views.my_custom_app, name='my_custom_app'), In hat/templates/dashboard create a new template file my_custom_app.html . {% extends 'app.html' %} {% load i18n %} {% load render_bundle from webpack_loader %} {% block header %} <h1 class=\"header__title\">{% trans 'My Custom App' %}</h1> {% endblock %} {% block content %} <div class=\"content\"> <div id=\"app-container\"></div> </div> {% render_bundle 'common' %} {% render_bundle 'my_custom_app' %} <script> HAT.MyCustomApp.default( document.getElementById('app-container'), '/dashboard/my-custom-app/' ) </script> {% endblock %}","title":"JS Build"},{"location":"pages/dev/reference/front-end_reference/front-end_reference.html#testing-the-production-build","text":"","title":"Testing the production build"},{"location":"pages/dev/reference/front-end_reference/front-end_reference.html#stop-any-containers-that-might-be-currently-running","text":"","title":". Stop any containers that might be currently running."},{"location":"pages/dev/reference/front-end_reference/front-end_reference.html#start-the-containers-with","text":".. code:: shell TEST_PROD=true docker compose up When the setup is run with TEST_PROD=true , it will exit the unneeded containers webpack and jupyter . It will also run the webpack build during startup, so that there is no need to rebuild the image for that.","title":". Start the containers with:"},{"location":"pages/dev/reference/front-end_reference/front-end_reference.html#js-unit-testing","text":"docker compose run hat test_js","title":"JS Unit Testing"},{"location":"pages/dev/reference/front-end_reference/front-end_reference.html#adding-new-assets-in-packagejson","text":"Unfortunately, for now you need to rebuild the container after adding or upgrading packages in package.json . .. code:: shell docker compose build or .. code:: shell docker compose up --build","title":"Adding new assets in package.json"},{"location":"pages/dev/reference/front-end_reference/front-end_reference.html#translations","text":"Translations are extracted on the first webpack build. Just like the django translation strings; translations are downloaded for every Travis CI <https://travis-ci.com> __ build, and uploaded on the development branch.","title":"Translations"},{"location":"pages/dev/reference/front-end_reference/front-end_reference.html#set-up-vscode-for-front-end-development","text":"See also: this pull request <https://github.com/BLSQ/iaso/pull/120> __ The script show-lint-problems can be turned into a VSCode task that will show all linter errors in VSCode's PROBLEMS Tab. Steps to follow: Go to Terminal>Configure task Select npm: show-lint-problems Add $eslint-stylish to the problemMatcher array Run the task: Terminal>Run Task...> npm: show-lint-problems. IMPORTANT: you need to run the task this way. Running the script directly from the terminal using npm will not enable VS Code to display the problems in the PROBLEMS tab You should be able to see and track the problems through the dedicated tab. CAUTION: if you navigate to a file through the tab, then close the file, it will be removed from the problems list, even if it wasn't changed. This seems to be a problem with using npm through VSCode's tasks","title":"Set up VSCode for front-end development"},{"location":"pages/dev/reference/front-end_reference/front-end_reference.html#depend-on-bluesquare-components-library","text":"See the library's README <https://github.com/BLSQ/bluesquare-components/blob/main/README.md> __ for the general setup. When depending on a local version of the library: Your local folder should be on the same level as the iaso folder, so that the path to the tgz file in your package.json is : ../bluesquare-components/bluesquare-components-0.1.0.tgz Run docker compose build --build-arg LIBRARY=<name-of-the-library-image>","title":"Depend on bluesquare-components library"},{"location":"pages/dev/reference/guidelines/back-end/back-end.html","text":"Backend and API Guidelines # Important considerations # Please do a rough design before any implementation and discuss it with the rest of the team. It doesn't need to be too detailed but you should have at least a list of Model, the important fields on it, the security model and what endpoint you will add. Security # When Adding New feature that will add Model and API please think about the security model. You can start by asking yourself these questions: Which user should have access to this? How to implement the multi-tenant Are new permission needed? Is the item listable/readable by user without the permission to implement Filter dropdown. For example users without the Form permission but with the Submission permission can still list Form from the API to be able to filter Instance by Form Tenancy # Iaso is multi tenant. Tenant are called and represented by the model Account . It represents roughly one client org or country. It also represents the natural limit of right for a user. So all new model and API per default should support tenancy. It's kind of annoying to add it later. We have two kind of tenancy, one per Project, one per Account. A Project represent a mobile app, there might be several linked to an account. You will have to consider which want you one to use. In some case it might be both. In some case if your new model is linked to existing one it might derive the tenancy from there (for example FormVersion derive their tenancy from Form). In practice this will consist on: 1. adding a ForeignKey to Account or Project on your model. 2. At creation 2. in your ViewSet filtering on the Object in the account (see filtering for user) In most case if this an API for the Mobile the tenancy will be per project. But if that's not the case and you are really not sure, there is nobody to ask and you need to advance, add it on the Account it will be simpler. Don't hesitate to ask if you don't understand what tenancy means or how it works. In the broad lines adding a complete new feature will consist of # The model(s): The modelisation in the Database The serializer(s): Which decide which field are returned to the client. But also which field(s) are accepted for creating and modifying object The ViewSet(s) which represent the Endpoints (GET PATCH, POST DELETE etc...) The routing, tell which url we use. /api/yourmodel The security model : Who can see and modify what and how. New Model implementation # Always add the field created_at , updated_at . This allow us the minimum of traceability and is useful in debug. created_at = models.DateTimeField(auto_now_add=True) updated_at = models.DateTimeField(auto_now=True) You might need Soft delete (see Soft Delete section) Don't forget the tenancy. Examples: There is a very simple Model/API example in the directory plugins/tests that you can use as a template. API # Please use serializers ! This will allow the API to be autodocumented in the swagger and the browsable API interface. You can check the swagger at /swagger/ For the ViewSet, always^ inherit ModelViewSet from iaso.api.common, not the one from DRF ! This will handle the Pagination that is particular to Django correctly out of the box. ^ Except in some case obviously but it should be the default For the default case you ModelViewSet should be very simple, and you should not have to reimplement def list() and def create() etc... if you properly did the Serializer and inherited from iaso.api.common.ModelViewset Filtering for user # Per default you will want to filter what is viewable by the correctly connected user (at minimum for the tenancy, see relevant section) To do so add a get_queryset() method on your ViewSet which will filter the queryset on the user. It's not a bad idea to move the logic of that code directly on your Model queryset by adding a Queryset.for_user(user: User) on your model so we can reuse it on other models. See for example TeamQuerySet. Permissions # We use the DRF system with permission_class see DRF Doc. See also plugins/test/api.py for an example. By default all the API require to be logged but any user can post GET / POST / PATCH / DELETE so beware of that. Further restriction can be added using http_method_names = [\"put\"] if you want to be extra sure, but that shouldn't be the only check method. Do not hesitate to put test to check that the method are effectively restricted to both authorized and unauthenticated user so they are not re-enabled by default. If you want to check if an user has a permission there is a HasPermission class in iaso.api.common.py TODO : expand section Filtering # Set the filter_backends config key in your ViewSet, with per default at least, the backends filters.OrderingFilter and DjangoFilterBackend filter_backends = [ filters.OrderingFilter, DjangoFilterBackend, ] This will allow ordering and filtering on the key present on the model automatically. The front dev will push you to include special filter with Javascript case name like FormId or stuff which will require special case in list() because that's what they are used to but in 99% of the case this is not needed and there is already a filter in python case form_id . The normal django operator can also be used __in for list, __gte for >= , iexact to ignore case, etc.. See the field lookup for the complete reference https://docs.djangoproject.com/en/4.1/ref/models/querysets/#field-lookups All these filters are conveniently listed in the swagger for each endpoint and in the browsable API If your model use SoftDelete include the DeletionFilterBackend filter. See the SoftDelete section DeletionFilterBackend, If you need more control on how fields can be used for ordering and filtering you can respectively use ordering_fields and filterset_fields . See the django-filter and drf doc. Frontend expect \"big\" api to accept a search filter which usually does a icontains on any of the model StringField (e.g. name or description) or related model (e.g the org unit name). The filters.OrderingFilter use the ?order_by query parameters, multiple field can be specified, separated by , , - in front of the field can be used to specify to reverse the order Annotation for ordering and filtering # In very special case if you need strange manipulation for ordering or filtering, adding an annotation on the queryset might help a lot. Since it does all the calculation on the database side, this allows use to add filter on fields that would otherwise not be possible without retrieving a lot of data on the backend. You might need to add them in ordering_fields and filterset_fields . (TODO Olivier : check) Mobile # If this API is accessible via mobile, add a separate endpoint for the mobile to use, in /api/mobile , even if it is the same as the \"regular\" web endpoint and that you connect it to the same ViewSet. This allows us flexibility if we have to break compatibility in the future. For date in new API endpoint we use the RFC format (2022-03-02 23:34...) that is the default in DRF so there is nothing to be done. Old endpoint might still use the old format in Timestamp. In the endpoint for mobile we always use Timestamp. You can use TimestampField and DateTimestampField in your Serializer for this. Take special care when modifying the API used by the mobile, we don't have a complete list, but we still have old version of the APP using very old endpoints that newer version don't use anymore. For API endpoint that the mobile APP will POST to, you should check with Martin if you may need the decorator @safe_api_import to ensure no data is lost. See /iaso/hat/vector_control/README.md CSV and XLS export # For data that will be presented as a table, we will want to provide CSV and XLS export to the user in nearly all cases. We don't use the CSV export provided by DRF for that and use a bit of code that we copy past and should really be refactored. TODO: Expand section SoftDelete # Soft Delete is a way to mark an Object as deleted without actually deleting it from the database. That way we can still show them to user in the interface it they choose to and the user can restore it easily. We have a standard way to implement it: - Have your model inherit from the SoftDelete. - This will add the deleted_at field. When the field is null it's not deleted if it contains a data it is deleted. In the ViewSet add the filter DeletionFilterBackend. Test that you can restore by doing a patch on your row on the deleted_at fields Permissions # if you add a new permission, don't forget to add it in the Frontend, or it will not be displayed properly. See the instruction on the top of menupermissions/models.py Django Admin # If you add New model, add them in the Admin if you don't know which fields or filter to add just add at least the minimum, we can expand it latter. Minimum Admin for a Model (BlogPost in this Example), in admin.py class BlogPostAdmin(admin.ModelAdmin): pass admin.site.register(BlogPost, BlogPostAdmin) If you want a base to be a mot more fancy: search_fields = (\"title\", \"content\") list_display = (\"title\", \"author\", \"created_at\", \"updated_at\") date_hierarchy = \"created_at\" list_filter = (\"author\", \"updated_at\") readonly_fields = (\"created_at\", \"updated_at\") Configuration settings # We configure the Iaso deployement (the server) via environment flags. So if you add something configurable on the whole server level do it that way. See https://12factor.net/config if your are not familiar with the philosophy. Note :There are of course some exceptions and thus some settings are configured in the Database. Notably for the Polio plugins. But please keep that exceptional. You can change your own local configuration in the file .env . Do note that if you make any modification in your .env or in your docker-compose.yml file. You will need to restart the whole docker compose for it to take effect (Ctrl-c your current docker compose and bring it back up with docker compose up If you add a new Environement variable to allow some configuration: 1. Do not access the Enviroement variable directly from your python code ! 1. Instead add it as a variable in the settings.py . 1. Add a comment explaing what this variable does. 1. Always provide a default value 1. To allow developer to change the variable locally add it in docker-compose.yml Also KISS , the less configuration the better ! There is no comprehensive documentation of all the configuration settings except what is in settings.py so it's important that you comment it well ! Example # settings.py # Application customizations APP_TITLE = os.environ.get(\"APP_TITLE\", \"Iaso\") Docker-compose diff --git a/docker-compose.yml b/docker-compose.yml index 057b81e39..49b29ac30 100644 --- a/docker-compose.yml +++ b/docker-compose.yml @@ -44,6 +44,7 @@ services: THEME_PRIMARY_BACKGROUND_COLOR: FAVICON_PATH: LOGO_PATH: + APP_TITLE: SHOW_NAME_WITH_LOGO: RDS_USERNAME: postgres RDS_PASSWORD: postgres Your python code from django.conf import settings settings.APP_TITLE Feature Flags # Feature flags allow to enable special feature or behaviour for our clients. The use case are: certain workflow that are particular to a client use case or feature that are still in development and that we are co-developing with the client. Example of feature flag: Enable editing an org unit geography directly via the web map or requiring user to log in into the mobile app to submit. We have two kind of flags in iaso: Mobile and Web To control how the Mobile application behave. Model FeatureFlag that are linked to Project (there might have multiple Mobile application per account) Model AccountFeatureFlag for the whole account. It is mainly used to control the behaviour of the web frontend. The list of flags are stored in database tables, to add a new Flag migration are used. Usually client can control which Project/Mobile flag they have but not the one on the Account level. To toggle a Mobile Feature flag for a client, add it in the dashboard -> Admin -> Projects -> Edit a project -> Options . To toggle an Account Feature flag, it is in the django Admin Adding a new Feature Flag via a Migration # For example a Project Feature Flag Create an empty migration: python manage.py makemigrations --empty yourappname Open the generated migration file, and adapt it to Create the migration. It should look like this def create_feature_flags(apps, schema_editor): FeatureFlag = apps.get_model(\"iaso\", \"FeatureFlag\") FeatureFlag.objects.create( code=\"CHECK_POSITION_FOR_FORMS\", name=\"Mobile: Enforce users are within reach of the Org Unit before starting a form.\", ) def destroy_feature_flags(apps, schema_editor): FeatureFlag = apps.get_model(\"iaso\", \"FeatureFlag\") FeatureFlag.objects.filter(code=\"CHECK_POSITION_FOR_FORMS\").delete() class Migration(migrations.Migration): dependencies = [ (\"iaso\", \"0150_profile_home_page\"), ] operations = [ migrations.RunPython(create_feature_flags, destroy_feature_flags), ] Run black on it Add the file in git See https://docs.djangoproject.com/en/4.0/topics/migrations/#data-migrations Typing and annotations # If you use an annotate and mypy complains when using the field. You can add the field on the model using Annotated. for example: from typing_extensions import Annotated, TypedDict class LastBudgetAnnotation(TypedDict): budget_last_updated_at: datetime class MonSerializeur() def get_budget_last_updated_at(self, campaign: Annotated[Campaign, LastBudgetAnnotation]): if campaign.budget_last_updated_at: return campaign.budget_last_updated_at.strftime(\"%Y-%m-%d\") Do not use the WithAnnotations from django-stubs. it doesn't work with our setup. I think it's a problem of python 3.8 Glossary # DRF: Django Rest Framework, the magic framework we use to generate the API mypy: Tool used to check the ci: continuous integration, it the fact that we launch the test on github on each commit There is a Glossary of common Model in the Iaso root Readme. also check it FAQ # I added a new environement variable in my .env but it is not accessible from python or in the settings.py # The new environment variable need to be listed in the docker-compose.yml Logging is broken # Symptom : The request are not displayed in the the sever console, or in productoin /var/app/log Someone probably imported a function from the tests directory, which disable logging. Please don't do that. Move the imported code elsewhere. See https://github.com/BLSQ/iaso/commit/b22b1bcc31a5b05650b675a3c168285103f9bcf8 in prod how to see the log # journalctl -u web","title":"Back end"},{"location":"pages/dev/reference/guidelines/back-end/back-end.html#backend-and-api-guidelines","text":"","title":"Backend and API Guidelines"},{"location":"pages/dev/reference/guidelines/back-end/back-end.html#important-considerations","text":"Please do a rough design before any implementation and discuss it with the rest of the team. It doesn't need to be too detailed but you should have at least a list of Model, the important fields on it, the security model and what endpoint you will add.","title":"Important considerations"},{"location":"pages/dev/reference/guidelines/back-end/back-end.html#security","text":"When Adding New feature that will add Model and API please think about the security model. You can start by asking yourself these questions: Which user should have access to this? How to implement the multi-tenant Are new permission needed? Is the item listable/readable by user without the permission to implement Filter dropdown. For example users without the Form permission but with the Submission permission can still list Form from the API to be able to filter Instance by Form","title":"Security"},{"location":"pages/dev/reference/guidelines/back-end/back-end.html#tenancy","text":"Iaso is multi tenant. Tenant are called and represented by the model Account . It represents roughly one client org or country. It also represents the natural limit of right for a user. So all new model and API per default should support tenancy. It's kind of annoying to add it later. We have two kind of tenancy, one per Project, one per Account. A Project represent a mobile app, there might be several linked to an account. You will have to consider which want you one to use. In some case it might be both. In some case if your new model is linked to existing one it might derive the tenancy from there (for example FormVersion derive their tenancy from Form). In practice this will consist on: 1. adding a ForeignKey to Account or Project on your model. 2. At creation 2. in your ViewSet filtering on the Object in the account (see filtering for user) In most case if this an API for the Mobile the tenancy will be per project. But if that's not the case and you are really not sure, there is nobody to ask and you need to advance, add it on the Account it will be simpler. Don't hesitate to ask if you don't understand what tenancy means or how it works.","title":"Tenancy"},{"location":"pages/dev/reference/guidelines/back-end/back-end.html#in-the-broad-lines-adding-a-complete-new-feature-will-consist-of","text":"The model(s): The modelisation in the Database The serializer(s): Which decide which field are returned to the client. But also which field(s) are accepted for creating and modifying object The ViewSet(s) which represent the Endpoints (GET PATCH, POST DELETE etc...) The routing, tell which url we use. /api/yourmodel The security model : Who can see and modify what and how.","title":"In the broad lines adding a complete new feature will consist of"},{"location":"pages/dev/reference/guidelines/back-end/back-end.html#new-model-implementation","text":"Always add the field created_at , updated_at . This allow us the minimum of traceability and is useful in debug. created_at = models.DateTimeField(auto_now_add=True) updated_at = models.DateTimeField(auto_now=True) You might need Soft delete (see Soft Delete section) Don't forget the tenancy. Examples: There is a very simple Model/API example in the directory plugins/tests that you can use as a template.","title":"New Model implementation"},{"location":"pages/dev/reference/guidelines/back-end/back-end.html#api","text":"Please use serializers ! This will allow the API to be autodocumented in the swagger and the browsable API interface. You can check the swagger at /swagger/ For the ViewSet, always^ inherit ModelViewSet from iaso.api.common, not the one from DRF ! This will handle the Pagination that is particular to Django correctly out of the box. ^ Except in some case obviously but it should be the default For the default case you ModelViewSet should be very simple, and you should not have to reimplement def list() and def create() etc... if you properly did the Serializer and inherited from iaso.api.common.ModelViewset","title":"API"},{"location":"pages/dev/reference/guidelines/back-end/back-end.html#filtering-for-user","text":"Per default you will want to filter what is viewable by the correctly connected user (at minimum for the tenancy, see relevant section) To do so add a get_queryset() method on your ViewSet which will filter the queryset on the user. It's not a bad idea to move the logic of that code directly on your Model queryset by adding a Queryset.for_user(user: User) on your model so we can reuse it on other models. See for example TeamQuerySet.","title":"Filtering for user"},{"location":"pages/dev/reference/guidelines/back-end/back-end.html#permissions","text":"We use the DRF system with permission_class see DRF Doc. See also plugins/test/api.py for an example. By default all the API require to be logged but any user can post GET / POST / PATCH / DELETE so beware of that. Further restriction can be added using http_method_names = [\"put\"] if you want to be extra sure, but that shouldn't be the only check method. Do not hesitate to put test to check that the method are effectively restricted to both authorized and unauthenticated user so they are not re-enabled by default. If you want to check if an user has a permission there is a HasPermission class in iaso.api.common.py TODO : expand section","title":"Permissions"},{"location":"pages/dev/reference/guidelines/back-end/back-end.html#filtering","text":"Set the filter_backends config key in your ViewSet, with per default at least, the backends filters.OrderingFilter and DjangoFilterBackend filter_backends = [ filters.OrderingFilter, DjangoFilterBackend, ] This will allow ordering and filtering on the key present on the model automatically. The front dev will push you to include special filter with Javascript case name like FormId or stuff which will require special case in list() because that's what they are used to but in 99% of the case this is not needed and there is already a filter in python case form_id . The normal django operator can also be used __in for list, __gte for >= , iexact to ignore case, etc.. See the field lookup for the complete reference https://docs.djangoproject.com/en/4.1/ref/models/querysets/#field-lookups All these filters are conveniently listed in the swagger for each endpoint and in the browsable API If your model use SoftDelete include the DeletionFilterBackend filter. See the SoftDelete section DeletionFilterBackend, If you need more control on how fields can be used for ordering and filtering you can respectively use ordering_fields and filterset_fields . See the django-filter and drf doc. Frontend expect \"big\" api to accept a search filter which usually does a icontains on any of the model StringField (e.g. name or description) or related model (e.g the org unit name). The filters.OrderingFilter use the ?order_by query parameters, multiple field can be specified, separated by , , - in front of the field can be used to specify to reverse the order","title":"Filtering"},{"location":"pages/dev/reference/guidelines/back-end/back-end.html#annotation-for-ordering-and-filtering","text":"In very special case if you need strange manipulation for ordering or filtering, adding an annotation on the queryset might help a lot. Since it does all the calculation on the database side, this allows use to add filter on fields that would otherwise not be possible without retrieving a lot of data on the backend. You might need to add them in ordering_fields and filterset_fields . (TODO Olivier : check)","title":"Annotation for ordering and filtering"},{"location":"pages/dev/reference/guidelines/back-end/back-end.html#mobile","text":"If this API is accessible via mobile, add a separate endpoint for the mobile to use, in /api/mobile , even if it is the same as the \"regular\" web endpoint and that you connect it to the same ViewSet. This allows us flexibility if we have to break compatibility in the future. For date in new API endpoint we use the RFC format (2022-03-02 23:34...) that is the default in DRF so there is nothing to be done. Old endpoint might still use the old format in Timestamp. In the endpoint for mobile we always use Timestamp. You can use TimestampField and DateTimestampField in your Serializer for this. Take special care when modifying the API used by the mobile, we don't have a complete list, but we still have old version of the APP using very old endpoints that newer version don't use anymore. For API endpoint that the mobile APP will POST to, you should check with Martin if you may need the decorator @safe_api_import to ensure no data is lost. See /iaso/hat/vector_control/README.md","title":"Mobile"},{"location":"pages/dev/reference/guidelines/back-end/back-end.html#csv-and-xls-export","text":"For data that will be presented as a table, we will want to provide CSV and XLS export to the user in nearly all cases. We don't use the CSV export provided by DRF for that and use a bit of code that we copy past and should really be refactored. TODO: Expand section","title":"CSV and XLS export"},{"location":"pages/dev/reference/guidelines/back-end/back-end.html#softdelete","text":"Soft Delete is a way to mark an Object as deleted without actually deleting it from the database. That way we can still show them to user in the interface it they choose to and the user can restore it easily. We have a standard way to implement it: - Have your model inherit from the SoftDelete. - This will add the deleted_at field. When the field is null it's not deleted if it contains a data it is deleted. In the ViewSet add the filter DeletionFilterBackend. Test that you can restore by doing a patch on your row on the deleted_at fields","title":"SoftDelete"},{"location":"pages/dev/reference/guidelines/back-end/back-end.html#permissions_1","text":"if you add a new permission, don't forget to add it in the Frontend, or it will not be displayed properly. See the instruction on the top of menupermissions/models.py","title":"Permissions"},{"location":"pages/dev/reference/guidelines/back-end/back-end.html#django-admin","text":"If you add New model, add them in the Admin if you don't know which fields or filter to add just add at least the minimum, we can expand it latter. Minimum Admin for a Model (BlogPost in this Example), in admin.py class BlogPostAdmin(admin.ModelAdmin): pass admin.site.register(BlogPost, BlogPostAdmin) If you want a base to be a mot more fancy: search_fields = (\"title\", \"content\") list_display = (\"title\", \"author\", \"created_at\", \"updated_at\") date_hierarchy = \"created_at\" list_filter = (\"author\", \"updated_at\") readonly_fields = (\"created_at\", \"updated_at\")","title":"Django Admin"},{"location":"pages/dev/reference/guidelines/back-end/back-end.html#configuration-settings","text":"We configure the Iaso deployement (the server) via environment flags. So if you add something configurable on the whole server level do it that way. See https://12factor.net/config if your are not familiar with the philosophy. Note :There are of course some exceptions and thus some settings are configured in the Database. Notably for the Polio plugins. But please keep that exceptional. You can change your own local configuration in the file .env . Do note that if you make any modification in your .env or in your docker-compose.yml file. You will need to restart the whole docker compose for it to take effect (Ctrl-c your current docker compose and bring it back up with docker compose up If you add a new Environement variable to allow some configuration: 1. Do not access the Enviroement variable directly from your python code ! 1. Instead add it as a variable in the settings.py . 1. Add a comment explaing what this variable does. 1. Always provide a default value 1. To allow developer to change the variable locally add it in docker-compose.yml Also KISS , the less configuration the better ! There is no comprehensive documentation of all the configuration settings except what is in settings.py so it's important that you comment it well !","title":"Configuration settings"},{"location":"pages/dev/reference/guidelines/back-end/back-end.html#example","text":"settings.py # Application customizations APP_TITLE = os.environ.get(\"APP_TITLE\", \"Iaso\") Docker-compose diff --git a/docker-compose.yml b/docker-compose.yml index 057b81e39..49b29ac30 100644 --- a/docker-compose.yml +++ b/docker-compose.yml @@ -44,6 +44,7 @@ services: THEME_PRIMARY_BACKGROUND_COLOR: FAVICON_PATH: LOGO_PATH: + APP_TITLE: SHOW_NAME_WITH_LOGO: RDS_USERNAME: postgres RDS_PASSWORD: postgres Your python code from django.conf import settings settings.APP_TITLE","title":"Example"},{"location":"pages/dev/reference/guidelines/back-end/back-end.html#feature-flags","text":"Feature flags allow to enable special feature or behaviour for our clients. The use case are: certain workflow that are particular to a client use case or feature that are still in development and that we are co-developing with the client. Example of feature flag: Enable editing an org unit geography directly via the web map or requiring user to log in into the mobile app to submit. We have two kind of flags in iaso: Mobile and Web To control how the Mobile application behave. Model FeatureFlag that are linked to Project (there might have multiple Mobile application per account) Model AccountFeatureFlag for the whole account. It is mainly used to control the behaviour of the web frontend. The list of flags are stored in database tables, to add a new Flag migration are used. Usually client can control which Project/Mobile flag they have but not the one on the Account level. To toggle a Mobile Feature flag for a client, add it in the dashboard -> Admin -> Projects -> Edit a project -> Options . To toggle an Account Feature flag, it is in the django Admin","title":"Feature Flags"},{"location":"pages/dev/reference/guidelines/back-end/back-end.html#adding-a-new-feature-flag-via-a-migration","text":"For example a Project Feature Flag Create an empty migration: python manage.py makemigrations --empty yourappname Open the generated migration file, and adapt it to Create the migration. It should look like this def create_feature_flags(apps, schema_editor): FeatureFlag = apps.get_model(\"iaso\", \"FeatureFlag\") FeatureFlag.objects.create( code=\"CHECK_POSITION_FOR_FORMS\", name=\"Mobile: Enforce users are within reach of the Org Unit before starting a form.\", ) def destroy_feature_flags(apps, schema_editor): FeatureFlag = apps.get_model(\"iaso\", \"FeatureFlag\") FeatureFlag.objects.filter(code=\"CHECK_POSITION_FOR_FORMS\").delete() class Migration(migrations.Migration): dependencies = [ (\"iaso\", \"0150_profile_home_page\"), ] operations = [ migrations.RunPython(create_feature_flags, destroy_feature_flags), ] Run black on it Add the file in git See https://docs.djangoproject.com/en/4.0/topics/migrations/#data-migrations","title":"Adding a new Feature Flag via a Migration"},{"location":"pages/dev/reference/guidelines/back-end/back-end.html#typing-and-annotations","text":"If you use an annotate and mypy complains when using the field. You can add the field on the model using Annotated. for example: from typing_extensions import Annotated, TypedDict class LastBudgetAnnotation(TypedDict): budget_last_updated_at: datetime class MonSerializeur() def get_budget_last_updated_at(self, campaign: Annotated[Campaign, LastBudgetAnnotation]): if campaign.budget_last_updated_at: return campaign.budget_last_updated_at.strftime(\"%Y-%m-%d\") Do not use the WithAnnotations from django-stubs. it doesn't work with our setup. I think it's a problem of python 3.8","title":"Typing and annotations"},{"location":"pages/dev/reference/guidelines/back-end/back-end.html#glossary","text":"DRF: Django Rest Framework, the magic framework we use to generate the API mypy: Tool used to check the ci: continuous integration, it the fact that we launch the test on github on each commit There is a Glossary of common Model in the Iaso root Readme. also check it","title":"Glossary"},{"location":"pages/dev/reference/guidelines/back-end/back-end.html#faq","text":"","title":"FAQ"},{"location":"pages/dev/reference/guidelines/back-end/back-end.html#i-added-a-new-environement-variable-in-my-env-but-it-is-not-accessible-from-python-or-in-the-settingspy","text":"The new environment variable need to be listed in the docker-compose.yml","title":"I added a new environement variable in my .env but it is not accessible from python or in the settings.py"},{"location":"pages/dev/reference/guidelines/back-end/back-end.html#logging-is-broken","text":"Symptom : The request are not displayed in the the sever console, or in productoin /var/app/log Someone probably imported a function from the tests directory, which disable logging. Please don't do that. Move the imported code elsewhere. See https://github.com/BLSQ/iaso/commit/b22b1bcc31a5b05650b675a3c168285103f9bcf8","title":"Logging is broken"},{"location":"pages/dev/reference/guidelines/back-end/back-end.html#in-prod-how-to-see-the-log","text":"journalctl -u web","title":"in prod how to see the log"},{"location":"pages/dev/reference/guidelines/front-end/front-end.html","text":"Front-end guidelines # Prerequisite # First of all make sure your eslint, prettier, typescript environnement is set properly. On VSC code you can format code following IAOS rules while saving in the settings: \"[javascript]\": { \"editor.formatOnSave\": true, }, \"[typescript]\": { \"editor.formatOnSave\": true, }, Make sure you installed eslint extension too. On each file you can have only one component. Use constants, and config files to store static data. Don't be afraid to split your code into smaller parts, using understandable naming convention. It will help to understand what you are doing in your code. Legacy # Class component, redux, provider are still old way to create features in IASO. Please use hooks , typescript and arrow component . Redux can still be used with state that needs to be available everywhere in the application (current user, UI constants and states, ...). We already have a lot of typing done in each domain of the application (forms, submissions, org units, ... ) Bluesquare-components # Lots of components used in IASO has been moved to a separate repo . We tried to be the most generic has possible in this repo, people from outside IASO should be able to use it in their own project. To use it locally, checkout the repo on the same level has ISO and run: LIVE_COMPONENTS=true pm run dev in IASO folder. This will use directly the code from your local repo. To make it available too everybody you have to build new files with npm run clean && npm run build in bluesquare-component folder. Architecture # Main index file is located here: hat/assets/js/apps/Iaso/index This is the entrypoint of the app, setting up providers, theme, react-query query client, custom plugins, redux,... components Used to store generic components that can be used everywhere, like inputComponent , buttons , ... domains For every big feature entity in IASO (forms, org units, plannings, ...) we have a domain folder allowing to display related pages. - index is generally used to display a list of items - details the details of an item - config used to store constants for the domain (columns, default order, ...) - hooks : dedicated hooks to make requests or compute specitic data for the domain - components : mostly intermediate components using smaller ones to construct domain page - messages : translations messages used for this specific domain config: used to store constants like defaultOrder, columns, 'baseUrls' - types : All types related to the domain Styling components # In our effort to maintain readability and conciseness in our code, we are transitioning away from the makeStyles hook and adopting a new approach for styling our components. We will now use a separate object, styles , to define our styles outside of the component function. This object will then be referenced within the sx prop in our JSX. Here's how to apply this approach: Define your styles in a styles object using the SxStyles type from hat/assets/js/apps/Iaso/types/general.ts . This helps with readability and keeps the component code clean. Apply styles to your components using the sx prop by referencing the styles object properties. Example: const styles: SxStyles = { root: { cursor: 'pointer', }, tooltip: { color: 'text.primary', bgcolor: 'background.paper', boxShadow: (theme: Theme) => theme.shadows[1], '& .MuiTooltip-arrow': { color: 'background.paper', }, }, noResult: { textDecoration: 'underline dotted', }, }; ... <Box sx={styles.root}> ... Maps # We are using leaflet latest version and react-leaflet (LTS version 3). To use latest version of react-leaflet we need to upgrade to react 18. Styles are located in bluesquare-components , you have to import it on each map: const styles = (theme) => ({ mapContainer: { ...commonStyles(theme).mapContainer, }, }); From react-leaflet # MapContainer The main container of the Map. Props we use: - bounds : not required, bounds of markers and shapes displayed, used by fit to bound, doc here . - boundsOptions : not required, options related to bounds, doc here . - zoomControl : required and set to false , in order to use the CustomZoomControl . - whenCreated : not required,to use a ref of the map in the same component as the MapContainer, you get it by doing whenCreated={mapInstance => { map.current = mapInstance; }} default props: doubleClickZoom={false} scrollWheelZoom={false} maxZoom={currentTile.maxZoom} style={{ height: '100%' }} center={[0, 0]} zoomControl={false} keyboard={false} bounds={bounds} boundsOptions={boundsOptions} Scalecontrol Used to display a scale on the bottom left of the map. Props we use: - imperial : always set to false We use other component from react-leaflet not listed here as they are optionnal and used like describe in their docs . Custom components # CustomZoomControl This will display an extended zoom control on the top left of the map. You can zoom in and out, select an area to zoom in and fit the map to the bounds of the map. Props: - bounds : not required, computed bounds displayed on the map, doc here . - boundsOptions : not required, options related to bounds, doc here . - bound : not required, a boolean to fit to bounds on load, not working if bounds stays undefined. CustomTileLayer + TilesSwitchDialog Control to display a dialog allowing to change the tile layer of the map, on the top right of the map Those twot components are going together, maybe we should refactor it to a single component. CustomTileLayer Props: - currentTile : required, active tile of the map, usually setted in the map itself with a useState . TilesSwitchDialog Props: - currentTile : required, active tile of the map, usually setted in the map itself with a useState . - setCurrentTile : required, method to update current tile on the map. MapToggleTooltips A switch to show or hide tooltips on the map. Props: showTooltip : required, usually setted in the map itself with a useState . setShowTooltip : required, method to showTooltip or not. MapToggleFullscreen A switch to set the map fullscreen or not. Props: isMapFullScreen : required, usually setted in the map itself with a useState . setIsMapFullScreen : required, method to set into fullscreen or not. MapToggleCluster A switch to allow clustering or not of marker on the map. You should use MarkerClusterGroup from react-leaflet-markercluster Props: isClusterActive : required, usually setted in the map itself with a useState . setIsClusterActive : required, method to enable custering of markers or not. MarkerComponent / CircleMarkerComponent Components used to display a marker on the map. Props: - see js file for not required props, mainly the same props as Marker from react-leaflet. - PopupComponent : not required, Popup used while clicking on the marker - TooltipComponent : not required, Tooltip used while hovering the marker - item : required, an object with latitude an longitude arguments, those are numbers MarkersListComponent Used to display a list of markers Props: - markerProps : not required, props spreaded to the marker - items : required, array of items use by previous component - PopupComponent : not required, Popup used while clicking on the marker - TooltipComponent : not required, Tooltip used while hovering the marker - onMarkerClick : not required, method applied while clicking on the marker on the map - isCircle : not required, display marker as a circle or not - onContextmenu : not required, method applied while right clicking on the marker on the map Tables # Most tables we use need to support filters and deep linking. We have a TableWithDeepLinking component for that purpose, which is a wrapper on the Table from Bluesuare-components. The typical props to pass are: - data : the table data. Usually originate s from a react-query hook - page : the current page. Usually returned by the API - pageSize : the amount of rows to display on each page. Also comes from the API - count : the total amount of items in the page. From the API - pages: total number of pages. From the API - baseUrl : the baseUrl the table will redirect to - params : the params of the current location. TableWithDeepLink will combine them with baseUrl to redirect to the correct location - extraProps : an object. The loading key will be used to manage the table's loading state. Other values will force a table re-render when they change (similar to useEffect deps array), which can be useful in some situations - columns : an array of objects of type Column` (imported from bluesquare-components). It's usually defined in a custom hook in order to easily handle translations. Note: useDeleteTableRow When performing DELETE operations from the table that will reduce the amount of table rows, we can run into a pagination bug. To avoid it, use useDeleteTableRow in the useDelete<whatever> hook that will return the delete function: export const useDeleteWhatever = ( params: Record<string, any>, count: number, ): UseMutationResult => { const onSuccess = useDeleteTableRow({ params, pageKey: 'whateverPage', // optional, will default to \"page\" pageSizeKey: 'whateverPageSize', //optional, will default to \"pageSize\" count, invalidateQueries: ['whatever'], // optional baseUrl: baseUrls.whatever, }); return useSnackMutation({ mutationFn: deleteWhatever, options: { onSuccess }, }); }; Filters # Most tables we display come with one or several filters, most commonly a text search and date filters. It's a global feature in Iaso that all filter searches performed on pages are deep-linked, i.e.: the parameters of the filters are saved in the url, so users can share the results of their search/filtering. This has an impact on the architecture of Iaso: All search fields need to be declared in routes.js , under the params key. Important: params is an ordered list. Passing them in the wrong order in the URL will result in a 404. Applying a filter doesn't change the component state per se but results in a redirection. Depending on the use cases, we may or may not want to save consecutive filters/searches in the routers history We have a few ready-made components for filters: InputComponent : handles most types of inputs: text, select, checkbox, radio OrgUnitTreeviewModal : handles searches on org units DatePicker and DateRange : handle dates InputComponent takes a keyValue prop, which is a string that corresponds to the url parameter that stores the filter value, and an onChange prop which is a function with the signature (keyValue,value) => void. DateRange takes a keyDateFrom and a keyDateTo that play the same role for the start and end date respectively. We also have a useFilterState hook that handles the state and update methods for filters of a given page: const { filters, handleSearch, handleChange, filtersUpdated } = useFilterState({ baseUrl, params, withPagination: false, saveSearchInHistory: false, }); baseUrl : is the url of the page params : the parameters passed to the url. useFilterState will generate the state for the filters based on those. withPagination: if false the hook will remove parameters related to table pagination ( page , pageSize and so on) saveSearchInHistory : if true , the redirection will use redirect i.o redirectToReplace and the searchg will be saved in the router's history, meaning that using the back arrow will bring the user to the previous search and not the previous page. Code style # Prefer type?:string to type: string | undefined Prefer const to let : ```javascript // BAD let myVar = \"placeholder\" if(otherVAlue) { myVar = otherValue } // GOOD const myVar = otherValue ?? \"placeholder ``` Function names should include a verb: // BAD const username = user => user.firstname + user.lastname // GOOD const makeUsername = user => user.firstname + user.lastname Not all functions are hooks. Hooks should either have some sort of internal state or trigger a side-effect: // BAD, we're just returning a value const useMyValue = (value :string) => { return parseInt(value,10) } // GOOD, because of useSafeIntl, the return value will change with user locale const useMyValue = (value :IntlMessage) => { const { formatMessage } = useSafeIntl() return formatMessage(value) } //GOOD, the returned object is memoized const useMyValue = (value: string) => { return useMemo(() => { const result = { isNumber:false, value } if (parseFloat(value)){ result.isNumber = true } return result },[value]) } // GOOD, as side effect will be triggered after the first render export const useSkipEffectOnMount = (func:Function, deps:Array<unknown>) => { const didMount = useRef(false); useEffect(() => { if (didMount.current) { func(); } else { didMount.current = true; } }, deps); }; Remarks # order translations by alphanumeric spacing is by default theme.spacing(2) do not use Grid everywhere or too much all the calls to the api without query params should end by '/' in routes.js, the params listed are ordered, meaning you can get a 404 when they are not in the right order. Related to this, the paginationPathParams that we spread in most routes should come first, right after the accountId to avoid getting 404 because of automatic redirections","title":"Front end"},{"location":"pages/dev/reference/guidelines/front-end/front-end.html#front-end-guidelines","text":"","title":"Front-end guidelines"},{"location":"pages/dev/reference/guidelines/front-end/front-end.html#prerequisite","text":"First of all make sure your eslint, prettier, typescript environnement is set properly. On VSC code you can format code following IAOS rules while saving in the settings: \"[javascript]\": { \"editor.formatOnSave\": true, }, \"[typescript]\": { \"editor.formatOnSave\": true, }, Make sure you installed eslint extension too. On each file you can have only one component. Use constants, and config files to store static data. Don't be afraid to split your code into smaller parts, using understandable naming convention. It will help to understand what you are doing in your code.","title":"Prerequisite"},{"location":"pages/dev/reference/guidelines/front-end/front-end.html#legacy","text":"Class component, redux, provider are still old way to create features in IASO. Please use hooks , typescript and arrow component . Redux can still be used with state that needs to be available everywhere in the application (current user, UI constants and states, ...). We already have a lot of typing done in each domain of the application (forms, submissions, org units, ... )","title":"Legacy"},{"location":"pages/dev/reference/guidelines/front-end/front-end.html#bluesquare-components","text":"Lots of components used in IASO has been moved to a separate repo . We tried to be the most generic has possible in this repo, people from outside IASO should be able to use it in their own project. To use it locally, checkout the repo on the same level has ISO and run: LIVE_COMPONENTS=true pm run dev in IASO folder. This will use directly the code from your local repo. To make it available too everybody you have to build new files with npm run clean && npm run build in bluesquare-component folder.","title":"Bluesquare-components"},{"location":"pages/dev/reference/guidelines/front-end/front-end.html#architecture","text":"Main index file is located here: hat/assets/js/apps/Iaso/index This is the entrypoint of the app, setting up providers, theme, react-query query client, custom plugins, redux,... components Used to store generic components that can be used everywhere, like inputComponent , buttons , ... domains For every big feature entity in IASO (forms, org units, plannings, ...) we have a domain folder allowing to display related pages. - index is generally used to display a list of items - details the details of an item - config used to store constants for the domain (columns, default order, ...) - hooks : dedicated hooks to make requests or compute specitic data for the domain - components : mostly intermediate components using smaller ones to construct domain page - messages : translations messages used for this specific domain config: used to store constants like defaultOrder, columns, 'baseUrls' - types : All types related to the domain","title":"Architecture"},{"location":"pages/dev/reference/guidelines/front-end/front-end.html#styling-components","text":"In our effort to maintain readability and conciseness in our code, we are transitioning away from the makeStyles hook and adopting a new approach for styling our components. We will now use a separate object, styles , to define our styles outside of the component function. This object will then be referenced within the sx prop in our JSX. Here's how to apply this approach: Define your styles in a styles object using the SxStyles type from hat/assets/js/apps/Iaso/types/general.ts . This helps with readability and keeps the component code clean. Apply styles to your components using the sx prop by referencing the styles object properties. Example: const styles: SxStyles = { root: { cursor: 'pointer', }, tooltip: { color: 'text.primary', bgcolor: 'background.paper', boxShadow: (theme: Theme) => theme.shadows[1], '& .MuiTooltip-arrow': { color: 'background.paper', }, }, noResult: { textDecoration: 'underline dotted', }, }; ... <Box sx={styles.root}> ...","title":"Styling components"},{"location":"pages/dev/reference/guidelines/front-end/front-end.html#maps","text":"We are using leaflet latest version and react-leaflet (LTS version 3). To use latest version of react-leaflet we need to upgrade to react 18. Styles are located in bluesquare-components , you have to import it on each map: const styles = (theme) => ({ mapContainer: { ...commonStyles(theme).mapContainer, }, });","title":"Maps"},{"location":"pages/dev/reference/guidelines/front-end/front-end.html#from-react-leaflet","text":"MapContainer The main container of the Map. Props we use: - bounds : not required, bounds of markers and shapes displayed, used by fit to bound, doc here . - boundsOptions : not required, options related to bounds, doc here . - zoomControl : required and set to false , in order to use the CustomZoomControl . - whenCreated : not required,to use a ref of the map in the same component as the MapContainer, you get it by doing whenCreated={mapInstance => { map.current = mapInstance; }} default props: doubleClickZoom={false} scrollWheelZoom={false} maxZoom={currentTile.maxZoom} style={{ height: '100%' }} center={[0, 0]} zoomControl={false} keyboard={false} bounds={bounds} boundsOptions={boundsOptions} Scalecontrol Used to display a scale on the bottom left of the map. Props we use: - imperial : always set to false We use other component from react-leaflet not listed here as they are optionnal and used like describe in their docs .","title":"From react-leaflet"},{"location":"pages/dev/reference/guidelines/front-end/front-end.html#custom-components","text":"CustomZoomControl This will display an extended zoom control on the top left of the map. You can zoom in and out, select an area to zoom in and fit the map to the bounds of the map. Props: - bounds : not required, computed bounds displayed on the map, doc here . - boundsOptions : not required, options related to bounds, doc here . - bound : not required, a boolean to fit to bounds on load, not working if bounds stays undefined. CustomTileLayer + TilesSwitchDialog Control to display a dialog allowing to change the tile layer of the map, on the top right of the map Those twot components are going together, maybe we should refactor it to a single component. CustomTileLayer Props: - currentTile : required, active tile of the map, usually setted in the map itself with a useState . TilesSwitchDialog Props: - currentTile : required, active tile of the map, usually setted in the map itself with a useState . - setCurrentTile : required, method to update current tile on the map. MapToggleTooltips A switch to show or hide tooltips on the map. Props: showTooltip : required, usually setted in the map itself with a useState . setShowTooltip : required, method to showTooltip or not. MapToggleFullscreen A switch to set the map fullscreen or not. Props: isMapFullScreen : required, usually setted in the map itself with a useState . setIsMapFullScreen : required, method to set into fullscreen or not. MapToggleCluster A switch to allow clustering or not of marker on the map. You should use MarkerClusterGroup from react-leaflet-markercluster Props: isClusterActive : required, usually setted in the map itself with a useState . setIsClusterActive : required, method to enable custering of markers or not. MarkerComponent / CircleMarkerComponent Components used to display a marker on the map. Props: - see js file for not required props, mainly the same props as Marker from react-leaflet. - PopupComponent : not required, Popup used while clicking on the marker - TooltipComponent : not required, Tooltip used while hovering the marker - item : required, an object with latitude an longitude arguments, those are numbers MarkersListComponent Used to display a list of markers Props: - markerProps : not required, props spreaded to the marker - items : required, array of items use by previous component - PopupComponent : not required, Popup used while clicking on the marker - TooltipComponent : not required, Tooltip used while hovering the marker - onMarkerClick : not required, method applied while clicking on the marker on the map - isCircle : not required, display marker as a circle or not - onContextmenu : not required, method applied while right clicking on the marker on the map","title":"Custom components"},{"location":"pages/dev/reference/guidelines/front-end/front-end.html#tables","text":"Most tables we use need to support filters and deep linking. We have a TableWithDeepLinking component for that purpose, which is a wrapper on the Table from Bluesuare-components. The typical props to pass are: - data : the table data. Usually originate s from a react-query hook - page : the current page. Usually returned by the API - pageSize : the amount of rows to display on each page. Also comes from the API - count : the total amount of items in the page. From the API - pages: total number of pages. From the API - baseUrl : the baseUrl the table will redirect to - params : the params of the current location. TableWithDeepLink will combine them with baseUrl to redirect to the correct location - extraProps : an object. The loading key will be used to manage the table's loading state. Other values will force a table re-render when they change (similar to useEffect deps array), which can be useful in some situations - columns : an array of objects of type Column` (imported from bluesquare-components). It's usually defined in a custom hook in order to easily handle translations. Note: useDeleteTableRow When performing DELETE operations from the table that will reduce the amount of table rows, we can run into a pagination bug. To avoid it, use useDeleteTableRow in the useDelete<whatever> hook that will return the delete function: export const useDeleteWhatever = ( params: Record<string, any>, count: number, ): UseMutationResult => { const onSuccess = useDeleteTableRow({ params, pageKey: 'whateverPage', // optional, will default to \"page\" pageSizeKey: 'whateverPageSize', //optional, will default to \"pageSize\" count, invalidateQueries: ['whatever'], // optional baseUrl: baseUrls.whatever, }); return useSnackMutation({ mutationFn: deleteWhatever, options: { onSuccess }, }); };","title":"Tables"},{"location":"pages/dev/reference/guidelines/front-end/front-end.html#filters","text":"Most tables we display come with one or several filters, most commonly a text search and date filters. It's a global feature in Iaso that all filter searches performed on pages are deep-linked, i.e.: the parameters of the filters are saved in the url, so users can share the results of their search/filtering. This has an impact on the architecture of Iaso: All search fields need to be declared in routes.js , under the params key. Important: params is an ordered list. Passing them in the wrong order in the URL will result in a 404. Applying a filter doesn't change the component state per se but results in a redirection. Depending on the use cases, we may or may not want to save consecutive filters/searches in the routers history We have a few ready-made components for filters: InputComponent : handles most types of inputs: text, select, checkbox, radio OrgUnitTreeviewModal : handles searches on org units DatePicker and DateRange : handle dates InputComponent takes a keyValue prop, which is a string that corresponds to the url parameter that stores the filter value, and an onChange prop which is a function with the signature (keyValue,value) => void. DateRange takes a keyDateFrom and a keyDateTo that play the same role for the start and end date respectively. We also have a useFilterState hook that handles the state and update methods for filters of a given page: const { filters, handleSearch, handleChange, filtersUpdated } = useFilterState({ baseUrl, params, withPagination: false, saveSearchInHistory: false, }); baseUrl : is the url of the page params : the parameters passed to the url. useFilterState will generate the state for the filters based on those. withPagination: if false the hook will remove parameters related to table pagination ( page , pageSize and so on) saveSearchInHistory : if true , the redirection will use redirect i.o redirectToReplace and the searchg will be saved in the router's history, meaning that using the back arrow will bring the user to the previous search and not the previous page.","title":"Filters"},{"location":"pages/dev/reference/guidelines/front-end/front-end.html#code-style","text":"Prefer type?:string to type: string | undefined Prefer const to let : ```javascript // BAD let myVar = \"placeholder\" if(otherVAlue) { myVar = otherValue } // GOOD const myVar = otherValue ?? \"placeholder ``` Function names should include a verb: // BAD const username = user => user.firstname + user.lastname // GOOD const makeUsername = user => user.firstname + user.lastname Not all functions are hooks. Hooks should either have some sort of internal state or trigger a side-effect: // BAD, we're just returning a value const useMyValue = (value :string) => { return parseInt(value,10) } // GOOD, because of useSafeIntl, the return value will change with user locale const useMyValue = (value :IntlMessage) => { const { formatMessage } = useSafeIntl() return formatMessage(value) } //GOOD, the returned object is memoized const useMyValue = (value: string) => { return useMemo(() => { const result = { isNumber:false, value } if (parseFloat(value)){ result.isNumber = true } return result },[value]) } // GOOD, as side effect will be triggered after the first render export const useSkipEffectOnMount = (func:Function, deps:Array<unknown>) => { const didMount = useRef(false); useEffect(() => { if (didMount.current) { func(); } else { didMount.current = true; } }, deps); };","title":"Code style"},{"location":"pages/dev/reference/guidelines/front-end/front-end.html#remarks","text":"order translations by alphanumeric spacing is by default theme.spacing(2) do not use Grid everywhere or too much all the calls to the api without query params should end by '/' in routes.js, the params listed are ordered, meaning you can get a 404 when they are not in the right order. Related to this, the paginationPathParams that we spread in most routes should come first, right after the accountId to avoid getting 404 because of automatic redirections","title":"Remarks"},{"location":"pages/dev/reference/guidelines/git/git.html","text":"Github flow # Create and merge a pull request # Make a new branch using the name of the JIRA issue in title Make sure you fill up all sections of the template (changes, how to test, ...) For any new feature make sure you wrote enough python or cypress tests To be mergeable your PR needs to pass build, JS and Python tests. You can also launch Cypress test manually to make sure you didn't brake something else just by tagging @cypress in a comment on your PR Add reviewer(s) to make sure someone is gonna take care of it Merge main in your branch if you have conflicts (we are not doing rebase) If a reviewer request changes apply the changes and mark the discussion on github as resolved when fixed. It will help other reviewers to see if the changes has been done. Re-request a review when all changes are pushed (double check tests again) Wait at least that one reviewer approved the PR and merge the thing Add documentation when necessary (new feature, change in config, etc) Review a pull request: # Go to all modified files and parse the code You can write your remarks or change requests directly on the files For each file, click on viewed checkbox while you reviewed it. This can help you to show changes on files after the author fixed your change requests Pull the branch and test the feature locally Approve/comment/request changes while you are done Restart the proccess if the author re-request a review Tips # You can always write a draft PR to run the tests or share a discussion with other developers To make sure your PR will pass in the next release you can add the release label to it You can add comments on a file or on multiple lines Black formatting is not automatic on new migration files You can access to the pull requests where your review is requested here When reviewing a PR and adding comments, you can inline a suggestion with the suggestion block. More information can be found here on point 6.","title":"Git"},{"location":"pages/dev/reference/guidelines/git/git.html#github-flow","text":"","title":"Github flow"},{"location":"pages/dev/reference/guidelines/git/git.html#create-and-merge-a-pull-request","text":"Make a new branch using the name of the JIRA issue in title Make sure you fill up all sections of the template (changes, how to test, ...) For any new feature make sure you wrote enough python or cypress tests To be mergeable your PR needs to pass build, JS and Python tests. You can also launch Cypress test manually to make sure you didn't brake something else just by tagging @cypress in a comment on your PR Add reviewer(s) to make sure someone is gonna take care of it Merge main in your branch if you have conflicts (we are not doing rebase) If a reviewer request changes apply the changes and mark the discussion on github as resolved when fixed. It will help other reviewers to see if the changes has been done. Re-request a review when all changes are pushed (double check tests again) Wait at least that one reviewer approved the PR and merge the thing Add documentation when necessary (new feature, change in config, etc)","title":"Create and merge a pull request"},{"location":"pages/dev/reference/guidelines/git/git.html#review-a-pull-request","text":"Go to all modified files and parse the code You can write your remarks or change requests directly on the files For each file, click on viewed checkbox while you reviewed it. This can help you to show changes on files after the author fixed your change requests Pull the branch and test the feature locally Approve/comment/request changes while you are done Restart the proccess if the author re-request a review","title":"Review a pull request:"},{"location":"pages/dev/reference/guidelines/git/git.html#tips","text":"You can always write a draft PR to run the tests or share a discussion with other developers To make sure your PR will pass in the next release you can add the release label to it You can add comments on a file or on multiple lines Black formatting is not automatic on new migration files You can access to the pull requests where your review is requested here When reviewing a PR and adding comments, you can inline a suggestion with the suggestion block. More information can be found here on point 6.","title":"Tips"},{"location":"pages/dev/reference/public_registry/public_registry.html","text":"Configuring a Public Registry # To configure a public registry, follow these steps: Step 1: Activate the Plugin # First, you need to activate the plugin by adding \"registry\" to the PLUGINS variable in your settings. PLUGINS = registry,... Step 2: Make a Data Source Public # Open the Django admin interface. Navigate to the data source you want to make public. Select the data source and mark it as public. Step 3: Create a Public Registry Config # In the Django admin interface, navigate to the public registry config section. Click on \"Add\" to create a new public registry config. Configuration Fields # Host : Enter any URL you want to use as the host. Slug : Set this to default_registry (this value is hardcoded in the front-end at the moment). Whitelist : Leave this field to the default value. Account : Select the account where your data source is located. Root Orgunit : Leave this field empty. Data Source : Select the data source you made public. Source Version : Select the version of the data source. App ID : Fill in the App ID of the project that uses the account and the data source. Example Configuration # Here is an example configuration: Host : https://www.example.com Slug : default_registry Whitelist : {\"fields\": [\"Name\"]} Account : polioTest Root Orgunit : (leave empty) Data Source : polio Source Version : Polio 1 App ID : com.poliooutbreaks.app Final Steps # After filling in all the required fields, save the configuration. Your public registry should now be configured and ready to use.","title":"Configuring a Public Registry"},{"location":"pages/dev/reference/public_registry/public_registry.html#configuring-a-public-registry","text":"To configure a public registry, follow these steps:","title":"Configuring a Public Registry"},{"location":"pages/dev/reference/public_registry/public_registry.html#step-1-activate-the-plugin","text":"First, you need to activate the plugin by adding \"registry\" to the PLUGINS variable in your settings. PLUGINS = registry,...","title":"Step 1: Activate the Plugin"},{"location":"pages/dev/reference/public_registry/public_registry.html#step-2-make-a-data-source-public","text":"Open the Django admin interface. Navigate to the data source you want to make public. Select the data source and mark it as public.","title":"Step 2: Make a Data Source Public"},{"location":"pages/dev/reference/public_registry/public_registry.html#step-3-create-a-public-registry-config","text":"In the Django admin interface, navigate to the public registry config section. Click on \"Add\" to create a new public registry config.","title":"Step 3: Create a Public Registry Config"},{"location":"pages/dev/reference/public_registry/public_registry.html#configuration-fields","text":"Host : Enter any URL you want to use as the host. Slug : Set this to default_registry (this value is hardcoded in the front-end at the moment). Whitelist : Leave this field to the default value. Account : Select the account where your data source is located. Root Orgunit : Leave this field empty. Data Source : Select the data source you made public. Source Version : Select the version of the data source. App ID : Fill in the App ID of the project that uses the account and the data source.","title":"Configuration Fields"},{"location":"pages/dev/reference/public_registry/public_registry.html#example-configuration","text":"Here is an example configuration: Host : https://www.example.com Slug : default_registry Whitelist : {\"fields\": [\"Name\"]} Account : polioTest Root Orgunit : (leave empty) Data Source : polio Source Version : Polio 1 App ID : com.poliooutbreaks.app","title":"Example Configuration"},{"location":"pages/dev/reference/public_registry/public_registry.html#final-steps","text":"After filling in all the required fields, save the configuration. Your public registry should now be configured and ready to use.","title":"Final Steps"},{"location":"pages/dev/reference/sql_dashboard/SQL_Dashboard_feature.html","text":"For super user across account there is a way to run raw read only SQL queries at the /explore/ page : https://iaso.bluesquare.org/explore/ e.g SELECT name FROM iaso_orgunittype This is useful to check the database state and query data accross different client account. You can also save query and share them with others. This feature is implemented via the excellent Django SQL Dashboard, their documentation has more complete information: https://django-sql-dashboard.datasette.io/en/stable/index.html Tips # Bar charts # You can generate bar chart by having two column named bar_label and bar_quantity Examples Example: Number of Org Unit per type in a project # select iaso_orgunittype.name as bar_label, count(org_unit.id) as bar_quantity from iaso_orgunittype join iaso_orgunittype_projects on iaso_orgunittype.id = iaso_orgunittype_projects.orgunittype_id left join iaso_orgunit org_unit on iaso_orgunittype.id = org_unit.org_unit_type_id where iaso_orgunittype_projects.project_id = 1 group by iaso_orgunittype.id order by bar_quantity OrgUnit hierarchy linked to an org unit # SELECT * FROM iaso_orgunit WHERE path ~ '*.104133.*' Use of parameters # You can use parameter, this will automatically create an input. If you save them as a dashboard it will allow passing the paramter in the url Example number of submission per form and per org_unit in a particular SourceVersion (version_id) # SELECT \"iaso_orgunit\".\"path\", \"iaso_orgunit\".\"name\", \"iaso_instance\".\"form_id\", count(\"iaso_instance\".\"id\") filter (WHERE (not (\"iaso_instance\".\"file\" = '' and \"iaso_instance\".\"file\" is not null) and not (\"iaso_instance\".\"deleted\" and \"iaso_instance\".\"deleted\" is not null))) as \"instances_count\" FROM \"iaso_orgunit\" JOIN \"iaso_instance\" ON (\"iaso_orgunit\".\"id\" = \"iaso_instance\".\"org_unit_id\") and version_id = %(version_id)s GROUP BY \"iaso_orgunit\".path, \"iaso_orgunit\".\"id\", \"iaso_instance\".\"form_id\" order by \"iaso_orgunit\".path limit 100; Use multiple ids # This tips is useful to allow passing multiple ids, separated per , select * from iaso_form where iaso_form.id = ANY (string_to_array(%(form_ids)s::text, ',')::int[]) Multi Line chart # You can generate multi line chart by naming columns line_label , line_quantity and line_category (you need all three) Example cumulative submission per projects per month # select line_label, line_category, sum(line_quantity) over (PARTITION BY line_category order by line_label) as line_quantity from ( select TO_CHAR(date_trunc('month', COALESCE(iaso_instance.source_created_at, iaso_instance.created_at)), 'YYYY/MM') as line_label, count(*) as line_quantity, iaso_project.name as line_category from iaso_instance inner join iaso_project on iaso_instance.project_id = iaso_project.id group by line_label, iaso_project.name order by line_label, line_quantity desc limit 200 ) as data Cumulative sum # To generate a cumulative sum (particularly useful for progression over time). Wrap your query with select line_label, line_category, sum(line_quantity) over (PARTITION BY line_category order by line_label) as line_quantity from ( YOUR QUERY ) as data See previous example. random data generation example # select line_label, line_category, sum(line_quantity) over (PARTITION BY line_category order by line_label) as line_quantity from (select TO_CHAR(gen_date.generate_series, 'YYYY/MM') as line_label, (random() - 0.2) * 1000::int as line_quantity, name as line_category from (select * from generate_series('2008-03-01 08:00'::timestamp, '2009-03-04 12:00'::timestamp, '1 month')) gen_date cross join (VALUES ('foo'), ('bar'), ('baz')) as categories (name)) as data Searching in Org Units, Org Unit Types # Here are some examples of queries to find Org Units, their types, reference forms and everything linked to the hierarchy of a specific Org Unit. As we are using Postgre's ltree extension and django-ltree to model this hierarchy, specific SQL operators are available to search in a performant way and queries can be cumbersome. Let's say you have a OrgUnit with ID : XXXXXX Find the hierarchy linked to this Org Unit. # SELECT * FROM iaso_orgunit WHERE path ~ '*.XXXXXX.*' Find the related Org Unit Types : # SELECT * FROM iaso_orgunittype WHERE id IN (SELECT org_unit_type_id FROM iaso_orgunit WHERE path ~ '*.XXXXXX.*') Reference forms of these Org Unit Types # SELECT * FROM iaso_form WHERE id IN (SELECT reference_form_id FROM iaso_orgunittype WHERE id IN (SELECT org_unit_type_id FROM iaso_orgunit WHERE path ~ '*.XXXXXX.*')) Find the Form Versions of these Reference Forms. # SELECT * FROM iaso_formversion WHERE id IN (SELECT id FROM iaso_form WHERE id IN (SELECT reference_form_id FROM iaso_orgunittype WHERE id IN (SELECT org_unit_type_id FROM iaso_orgunit WHERE path ~ '*.XXXXXX.*'))) The Instances linked to that hierarchy # SELECT * FROM iaso_instance WHERE org_unit_id IN (SELECT id FROM iaso_orgunit WHERE path ~ '*.104133.*') Finding the projects linked to that hierarchy # SELECT * FROM iaso_project WHERE id in (SELECT project_id FROM iaso_instance WHERE org_unit_id IN (SELECT id FROM iaso_orgunit WHERE path ~ '*.104133.*')) Devices linked to that hierarchy # SELECT * FROM iaso_device WHERE id in (SELECT device_id FROM iaso_instance WHERE org_unit_id IN (SELECT id FROM iaso_orgunit WHERE path ~ '*.104133.*')) Accounts linked to these projects # SELECT * FROM iaso_account WHERE id IN (SELECT account_id FROM iaso_project WHERE id in (SELECT project_id FROM iaso_instance WHERE org_unit_id IN (SELECT id FROM iaso_orgunit WHERE path ~ '*.104133.*'))) Source versions linked to these projects # SELECT * FROM iaso_sourceversion WHERE id IN (SELECT default_version_id FROM iaso_account WHERE id IN (SELECT account_id FROM iaso_project WHERE id in (SELECT project_id FROM iaso_instance WHERE org_unit_id IN (SELECT id FROM iaso_orgunit WHERE path ~ '*.104133.*')))) Datasources linked to these versions # SELECT * FROM iaso_datasource WHERE id IN (SELECT data_source_id FROM iaso_sourceversion WHERE id IN (SELECT default_version_id FROM iaso_account WHERE id IN (SELECT account_id FROM iaso_project WHERE id in (SELECT project_id FROM iaso_instance WHERE org_unit_id IN (SELECT id FROM iaso_orgunit WHERE path ~ '*.104133.*'))))) Credentials linked these datasources # SELECT * FROM iaso_externalcredentials WHERE id IN (SELECT credentials_id FROM iaso_datasource WHERE id IN (SELECT data_source_id FROM iaso_sourceversion WHERE id IN (SELECT default_version_id FROM iaso_account WHERE id IN (SELECT account_id FROM iaso_project WHERE id in (SELECT project_id FROM iaso_instance WHERE org_unit_id IN (SELECT id FROM iaso_orgunit WHERE path ~ '*.104133.*')))))) Restrictions # This functionality is severly restricted to prevent the risk of data leak and security issues: Only a certain set of table are accessible. (notably not the user table password) Since this is ignore the multi tenant rule only super user can be given access to it Access is read only (see implementation detail) Configuration and Implementation detail # To garantee read only access this feature use a separate user that should only be given restricted right. The functionnality is automatically enabled if this user is set via the DB_READONLY_USERNAME environment variable. To configure it: Create a Postgresql user with a password and no acess and give him the role readonlyrole . You can do so using the sql command GRANT readonlyrole to YOUR_USER Set the environment variable DB_READONLY_USERNAME and DB_READONLY_PASSWORD . Some migration will give read acess to the certain tables to the readonlyrole , should you give access to more table use the command GRANT SELECT ON TABLE iaso_new_table_1, iaso_new_table_2, TO \"readonlyrole\"; to only give access to certain column on a table GRANT SELECT( id, username, is_active, date_joined ) ON auth_user TO \"readonlyrole\"; See also https://django-sql-dashboard.datasette.io/en/stable/security.html In local dev # this feature is automatically enabled.","title":"SQL Dashboard feature"},{"location":"pages/dev/reference/sql_dashboard/SQL_Dashboard_feature.html#tips","text":"","title":"Tips"},{"location":"pages/dev/reference/sql_dashboard/SQL_Dashboard_feature.html#bar-charts","text":"You can generate bar chart by having two column named bar_label and bar_quantity Examples","title":"Bar charts"},{"location":"pages/dev/reference/sql_dashboard/SQL_Dashboard_feature.html#example-number-of-org-unit-per-type-in-a-project","text":"select iaso_orgunittype.name as bar_label, count(org_unit.id) as bar_quantity from iaso_orgunittype join iaso_orgunittype_projects on iaso_orgunittype.id = iaso_orgunittype_projects.orgunittype_id left join iaso_orgunit org_unit on iaso_orgunittype.id = org_unit.org_unit_type_id where iaso_orgunittype_projects.project_id = 1 group by iaso_orgunittype.id order by bar_quantity","title":"Example: Number of Org Unit per type in a project"},{"location":"pages/dev/reference/sql_dashboard/SQL_Dashboard_feature.html#orgunit-hierarchy-linked-to-an-org-unit","text":"SELECT * FROM iaso_orgunit WHERE path ~ '*.104133.*'","title":"OrgUnit hierarchy linked to an org unit"},{"location":"pages/dev/reference/sql_dashboard/SQL_Dashboard_feature.html#use-of-parameters","text":"You can use parameter, this will automatically create an input. If you save them as a dashboard it will allow passing the paramter in the url","title":"Use of parameters"},{"location":"pages/dev/reference/sql_dashboard/SQL_Dashboard_feature.html#example-number-of-submission-per-form-and-per-org_unit-in-a-particular-sourceversion-version_id","text":"SELECT \"iaso_orgunit\".\"path\", \"iaso_orgunit\".\"name\", \"iaso_instance\".\"form_id\", count(\"iaso_instance\".\"id\") filter (WHERE (not (\"iaso_instance\".\"file\" = '' and \"iaso_instance\".\"file\" is not null) and not (\"iaso_instance\".\"deleted\" and \"iaso_instance\".\"deleted\" is not null))) as \"instances_count\" FROM \"iaso_orgunit\" JOIN \"iaso_instance\" ON (\"iaso_orgunit\".\"id\" = \"iaso_instance\".\"org_unit_id\") and version_id = %(version_id)s GROUP BY \"iaso_orgunit\".path, \"iaso_orgunit\".\"id\", \"iaso_instance\".\"form_id\" order by \"iaso_orgunit\".path limit 100;","title":"Example number of submission per form and per org_unit in a particular SourceVersion (version_id)"},{"location":"pages/dev/reference/sql_dashboard/SQL_Dashboard_feature.html#use-multiple-ids","text":"This tips is useful to allow passing multiple ids, separated per , select * from iaso_form where iaso_form.id = ANY (string_to_array(%(form_ids)s::text, ',')::int[])","title":"Use multiple ids"},{"location":"pages/dev/reference/sql_dashboard/SQL_Dashboard_feature.html#multi-line-chart","text":"You can generate multi line chart by naming columns line_label , line_quantity and line_category (you need all three)","title":"Multi Line chart"},{"location":"pages/dev/reference/sql_dashboard/SQL_Dashboard_feature.html#example-cumulative-submission-per-projects-per-month","text":"select line_label, line_category, sum(line_quantity) over (PARTITION BY line_category order by line_label) as line_quantity from ( select TO_CHAR(date_trunc('month', COALESCE(iaso_instance.source_created_at, iaso_instance.created_at)), 'YYYY/MM') as line_label, count(*) as line_quantity, iaso_project.name as line_category from iaso_instance inner join iaso_project on iaso_instance.project_id = iaso_project.id group by line_label, iaso_project.name order by line_label, line_quantity desc limit 200 ) as data","title":"Example cumulative submission per projects per month"},{"location":"pages/dev/reference/sql_dashboard/SQL_Dashboard_feature.html#cumulative-sum","text":"To generate a cumulative sum (particularly useful for progression over time). Wrap your query with select line_label, line_category, sum(line_quantity) over (PARTITION BY line_category order by line_label) as line_quantity from ( YOUR QUERY ) as data See previous example.","title":"Cumulative sum"},{"location":"pages/dev/reference/sql_dashboard/SQL_Dashboard_feature.html#random-data-generation-example","text":"select line_label, line_category, sum(line_quantity) over (PARTITION BY line_category order by line_label) as line_quantity from (select TO_CHAR(gen_date.generate_series, 'YYYY/MM') as line_label, (random() - 0.2) * 1000::int as line_quantity, name as line_category from (select * from generate_series('2008-03-01 08:00'::timestamp, '2009-03-04 12:00'::timestamp, '1 month')) gen_date cross join (VALUES ('foo'), ('bar'), ('baz')) as categories (name)) as data","title":"random data generation example"},{"location":"pages/dev/reference/sql_dashboard/SQL_Dashboard_feature.html#searching-in-org-units-org-unit-types","text":"Here are some examples of queries to find Org Units, their types, reference forms and everything linked to the hierarchy of a specific Org Unit. As we are using Postgre's ltree extension and django-ltree to model this hierarchy, specific SQL operators are available to search in a performant way and queries can be cumbersome. Let's say you have a OrgUnit with ID : XXXXXX","title":"Searching in Org Units, Org Unit Types"},{"location":"pages/dev/reference/sql_dashboard/SQL_Dashboard_feature.html#find-the-hierarchy-linked-to-this-org-unit","text":"SELECT * FROM iaso_orgunit WHERE path ~ '*.XXXXXX.*'","title":"Find the hierarchy linked to this Org Unit."},{"location":"pages/dev/reference/sql_dashboard/SQL_Dashboard_feature.html#find-the-related-org-unit-types","text":"SELECT * FROM iaso_orgunittype WHERE id IN (SELECT org_unit_type_id FROM iaso_orgunit WHERE path ~ '*.XXXXXX.*')","title":"Find the related Org Unit Types :"},{"location":"pages/dev/reference/sql_dashboard/SQL_Dashboard_feature.html#reference-forms-of-these-org-unit-types","text":"SELECT * FROM iaso_form WHERE id IN (SELECT reference_form_id FROM iaso_orgunittype WHERE id IN (SELECT org_unit_type_id FROM iaso_orgunit WHERE path ~ '*.XXXXXX.*'))","title":"Reference forms of these Org Unit Types"},{"location":"pages/dev/reference/sql_dashboard/SQL_Dashboard_feature.html#find-the-form-versions-of-these-reference-forms","text":"SELECT * FROM iaso_formversion WHERE id IN (SELECT id FROM iaso_form WHERE id IN (SELECT reference_form_id FROM iaso_orgunittype WHERE id IN (SELECT org_unit_type_id FROM iaso_orgunit WHERE path ~ '*.XXXXXX.*')))","title":"Find the Form Versions of these Reference Forms."},{"location":"pages/dev/reference/sql_dashboard/SQL_Dashboard_feature.html#the-instances-linked-to-that-hierarchy","text":"SELECT * FROM iaso_instance WHERE org_unit_id IN (SELECT id FROM iaso_orgunit WHERE path ~ '*.104133.*')","title":"The Instances linked to that hierarchy"},{"location":"pages/dev/reference/sql_dashboard/SQL_Dashboard_feature.html#finding-the-projects-linked-to-that-hierarchy","text":"SELECT * FROM iaso_project WHERE id in (SELECT project_id FROM iaso_instance WHERE org_unit_id IN (SELECT id FROM iaso_orgunit WHERE path ~ '*.104133.*'))","title":"Finding the projects linked to that hierarchy"},{"location":"pages/dev/reference/sql_dashboard/SQL_Dashboard_feature.html#devices-linked-to-that-hierarchy","text":"SELECT * FROM iaso_device WHERE id in (SELECT device_id FROM iaso_instance WHERE org_unit_id IN (SELECT id FROM iaso_orgunit WHERE path ~ '*.104133.*'))","title":"Devices linked to that hierarchy"},{"location":"pages/dev/reference/sql_dashboard/SQL_Dashboard_feature.html#accounts-linked-to-these-projects","text":"SELECT * FROM iaso_account WHERE id IN (SELECT account_id FROM iaso_project WHERE id in (SELECT project_id FROM iaso_instance WHERE org_unit_id IN (SELECT id FROM iaso_orgunit WHERE path ~ '*.104133.*')))","title":"Accounts linked to these projects"},{"location":"pages/dev/reference/sql_dashboard/SQL_Dashboard_feature.html#source-versions-linked-to-these-projects","text":"SELECT * FROM iaso_sourceversion WHERE id IN (SELECT default_version_id FROM iaso_account WHERE id IN (SELECT account_id FROM iaso_project WHERE id in (SELECT project_id FROM iaso_instance WHERE org_unit_id IN (SELECT id FROM iaso_orgunit WHERE path ~ '*.104133.*'))))","title":"Source versions linked to these projects"},{"location":"pages/dev/reference/sql_dashboard/SQL_Dashboard_feature.html#datasources-linked-to-these-versions","text":"SELECT * FROM iaso_datasource WHERE id IN (SELECT data_source_id FROM iaso_sourceversion WHERE id IN (SELECT default_version_id FROM iaso_account WHERE id IN (SELECT account_id FROM iaso_project WHERE id in (SELECT project_id FROM iaso_instance WHERE org_unit_id IN (SELECT id FROM iaso_orgunit WHERE path ~ '*.104133.*')))))","title":"Datasources linked to these versions"},{"location":"pages/dev/reference/sql_dashboard/SQL_Dashboard_feature.html#credentials-linked-these-datasources","text":"SELECT * FROM iaso_externalcredentials WHERE id IN (SELECT credentials_id FROM iaso_datasource WHERE id IN (SELECT data_source_id FROM iaso_sourceversion WHERE id IN (SELECT default_version_id FROM iaso_account WHERE id IN (SELECT account_id FROM iaso_project WHERE id in (SELECT project_id FROM iaso_instance WHERE org_unit_id IN (SELECT id FROM iaso_orgunit WHERE path ~ '*.104133.*'))))))","title":"Credentials linked these datasources"},{"location":"pages/dev/reference/sql_dashboard/SQL_Dashboard_feature.html#restrictions","text":"This functionality is severly restricted to prevent the risk of data leak and security issues: Only a certain set of table are accessible. (notably not the user table password) Since this is ignore the multi tenant rule only super user can be given access to it Access is read only (see implementation detail)","title":"Restrictions"},{"location":"pages/dev/reference/sql_dashboard/SQL_Dashboard_feature.html#configuration-and-implementation-detail","text":"To garantee read only access this feature use a separate user that should only be given restricted right. The functionnality is automatically enabled if this user is set via the DB_READONLY_USERNAME environment variable. To configure it: Create a Postgresql user with a password and no acess and give him the role readonlyrole . You can do so using the sql command GRANT readonlyrole to YOUR_USER Set the environment variable DB_READONLY_USERNAME and DB_READONLY_PASSWORD . Some migration will give read acess to the certain tables to the readonlyrole , should you give access to more table use the command GRANT SELECT ON TABLE iaso_new_table_1, iaso_new_table_2, TO \"readonlyrole\"; to only give access to certain column on a table GRANT SELECT( id, username, is_active, date_joined ) ON auth_user TO \"readonlyrole\"; See also https://django-sql-dashboard.datasette.io/en/stable/security.html","title":"Configuration and Implementation detail"},{"location":"pages/dev/reference/sql_dashboard/SQL_Dashboard_feature.html#in-local-dev","text":"this feature is automatically enabled.","title":"In local dev"},{"location":"pages/dev/reference/vector_control/vector_control.html","text":"This App is used to log API calls in the DB. The idea is that the mobile app user may not have great internet connection where they are so in case of import problem we can fix it server side and not ask them to upload again. API endpoint to be logged as such are decorated with the @safe_api_import decorator. The request themselves are stored in the vector_control.APIImport model. To replay the failings requests use the django command reimport_failed_imports.py This app used to be a lot of others things too before, hence the not matching name.","title":"Vector control"},{"location":"pages/users/FAQ/faq.html","text":"How do I configure Iaso in a way that mobile users cannot create new OUs ? And/or is it possible to limit OU creation to certain OU types. Ex: mobile users can create the types at the bottom of the hierarchy (FOSA, village), but not at the top (Region -> Aire sanitaire) ? It\u2019s in the org unit type configuration: you specify what is allowed under a given org unit type in the \"sub org unit types\" selector.","title":"Faq"},{"location":"pages/users/how_to/convert_docx_to_md/convert_docx_to_md.html","text":"How to convert a .docx file to .md # Install pandoc Add a copy of your docx file to iaso/docs/originals Create a folder for your file at the right place. E.g: If you want to create a how-to file for users, you would create the folder iaso/docs/pages/users/how_to/my_new_page . Make sure to use snake_case when naming your folder. In your iaso/docs/pages/users/how_to/my_new_page folder, create a media folder. The full path to the media folder should be: iaso/docs/pages/users/how_to/my_new_page/media/ In iaso/docs/pages/users/how_to/my_new_page/ , run the following pandoc command: pandoc -s -f docx -t markdown_mmd --extract-media=. -o ./my_new_page.md ../../../../originals/MyPage.docx This will copy all the attached media of you docx file (like screenshots) in iaso/docs/pages/users/how_to/my_new_page/media/ , and create my_new_page.md in iaso/docs/pages/users/how_to/my_new_page/ - Rename the media folder to attachments - Open my_new_pages.md . search (ctrl+F/cmd+F) for the word \"media\" and replace it with \"attachment\" whenever it is a path to a file, eg: <!-->Initial value<--> <img src=\"./media/image1.png\"style=\"width:3.02211in;height:0.79688in\" /> <!-->Correct value<--> <img src=\"./attachments/image1.png\"style=\"width:3.02211in;height:0.79688in\" /> This is because media folders are not pushed on github, so if we don't rename it, the screenshots in your docs will be lost Go through my_new_pages.md and fix any layout issues that may have been caused by the conversion. Now you can add you page to the docs: go to iaso/mkDocs.yml and locate the nav entry. Add you new page: nav: - Home: index.md - Users: - References: - User guide: - ./pages/users/reference/user_guide/user_guide.md - How to: - ./pages/users/how_to/my_new_page/my_new_page.md #<-- Your page would go here - FAQ: ./pages/users/FAQ/faq.md","title":"How to convert a .docx file to .md"},{"location":"pages/users/how_to/convert_docx_to_md/convert_docx_to_md.html#how-to-convert-a-docx-file-to-md","text":"Install pandoc Add a copy of your docx file to iaso/docs/originals Create a folder for your file at the right place. E.g: If you want to create a how-to file for users, you would create the folder iaso/docs/pages/users/how_to/my_new_page . Make sure to use snake_case when naming your folder. In your iaso/docs/pages/users/how_to/my_new_page folder, create a media folder. The full path to the media folder should be: iaso/docs/pages/users/how_to/my_new_page/media/ In iaso/docs/pages/users/how_to/my_new_page/ , run the following pandoc command: pandoc -s -f docx -t markdown_mmd --extract-media=. -o ./my_new_page.md ../../../../originals/MyPage.docx This will copy all the attached media of you docx file (like screenshots) in iaso/docs/pages/users/how_to/my_new_page/media/ , and create my_new_page.md in iaso/docs/pages/users/how_to/my_new_page/ - Rename the media folder to attachments - Open my_new_pages.md . search (ctrl+F/cmd+F) for the word \"media\" and replace it with \"attachment\" whenever it is a path to a file, eg: <!-->Initial value<--> <img src=\"./media/image1.png\"style=\"width:3.02211in;height:0.79688in\" /> <!-->Correct value<--> <img src=\"./attachments/image1.png\"style=\"width:3.02211in;height:0.79688in\" /> This is because media folders are not pushed on github, so if we don't rename it, the screenshots in your docs will be lost Go through my_new_pages.md and fix any layout issues that may have been caused by the conversion. Now you can add you page to the docs: go to iaso/mkDocs.yml and locate the nav entry. Add you new page: nav: - Home: index.md - Users: - References: - User guide: - ./pages/users/reference/user_guide/user_guide.md - How to: - ./pages/users/how_to/my_new_page/my_new_page.md #<-- Your page would go here - FAQ: ./pages/users/FAQ/faq.md","title":"How to convert a .docx file to .md"},{"location":"pages/users/how_to/create_new_documentation_page/create_new_documentation_page.html","text":"How to add a new page to Iaso's documentation # 1. Determine where the page belongs # To determine where a new documentation page fits, there are 2 questions to answer: - Who is it intended for? - What kind of document is it? We currently have 2 categories of documentation users: developers and users. This will determine the style of the writing and the assumptions you can make in terms of, eg prior knowledge of the product. We determine the kind of document using the diataxis framework . Basically, the idea is to ask what the goal of the document is. A simple rule of thumb is: - Give instructions about how to perform a task, eg: how do I login? -> how to - Explanation of concepts, eg: what is an org unit type? -> reference - Explanation on choices made for some implementation, eg: why do we use react-query for API calls? -> explanation Once we know who the document is intended for and what kind of document it is, we just need to follow the folder structure. For example, this document is intended for users and aims to explain how to create a new page in the documentation, so it will go in: > pages > users > how_to There is an exception for the FAQ whixh we keep separate and visible for convenience 2. Create a branch on git for the new document # Ideally, there will be a Jira ticket for the changes about to be made. It should be used to name the branch, as it will enable Jira to directly link the ticket to the branch. For example, the development branch for this document is called IA-2630_how_to_write_iaso_doc To create the branch: - Open a terminal - Make sure you are on main. If not run git checkout main - Run git checkout -b <Branch name> . This will create the branch and switch to it 3. Create folder and markdown file # By convention, we create a folder with the same name as the markdown file. For example, this document is in: > pages > users > how_to > create_new_documentation_page - create_new_documentation_page.md 4. Write the doc # Format the text using markdown syntax 4.1. Add images # Add a folder called /attachments/ in the document's folder and move the images there > pages > users > how_to > create_new_documentation_page > attachments - create_new_documentation_page.md To add the image in the markdown file, either: - use markdown syntax to add the link ![my_image](./attachments/my_image.png) - use an html img tag: <img src=\"./attachments/image49.png\" /> The markdown syntax is less cumbersome if the image is already at the right size. The img tag allows for manually setting the image width and heigh via the style attribute: <img src=\"./attachments/image49.png\" style=\"width:50px;height:50px\" /> Note: Add the /attachments/ folder even if the document doesn't contain any images yet. It will make it easier for others to add them later. 5. Push the changes on Github # Once the document is ready, the changes need to be saved on the git branch, then pushed on Github, so they can be reviewed and merged. There are tools to make this part faster and easier to manage ( Github desktop , or even just the git ineterface of VS Code ), but if it needs to be done in the terminal (from the document's branch): - git add . - git commit -m <commit message> - git push 6. Open the Pull Request # Pull requests are the process through which we review code. Since the documentation is hosted as part of the code, it's going through the same review process, though not necessarily by the same persons. To open a pull request: - Go to iaso's pull requests - Click New pull request - Select a branch - Describe the changes. The description template can be ignored for documentation changes, but please leave a description, as it helps tracking and understanding changes. 7. Review a pull request # Pull requests are peer-reviews that insure that all changes are cross-checked, so one should not merge their own pull requests. To review a pull request: - Go to iaso's pull requests - Click in the pull request - Click \"Add your review\" - Review the changes, comment where necessary - To finish the review, click \"Review changes\" - If the changes can be deployed as they are, choose \"Approve\" - If not, explain what needs to be corrected and chooses \"Request changes\" - If the PR has been approved, go the \"Conversation\" tab of the PR, scroll down and click \"Merge pull request\" The changes will be visible in production after the next release of iaso.","title":"How to add a new page to Iaso's documentation"},{"location":"pages/users/how_to/create_new_documentation_page/create_new_documentation_page.html#how-to-add-a-new-page-to-iasos-documentation","text":"","title":"How to add a new page to Iaso's documentation"},{"location":"pages/users/how_to/create_new_documentation_page/create_new_documentation_page.html#1-determine-where-the-page-belongs","text":"To determine where a new documentation page fits, there are 2 questions to answer: - Who is it intended for? - What kind of document is it? We currently have 2 categories of documentation users: developers and users. This will determine the style of the writing and the assumptions you can make in terms of, eg prior knowledge of the product. We determine the kind of document using the diataxis framework . Basically, the idea is to ask what the goal of the document is. A simple rule of thumb is: - Give instructions about how to perform a task, eg: how do I login? -> how to - Explanation of concepts, eg: what is an org unit type? -> reference - Explanation on choices made for some implementation, eg: why do we use react-query for API calls? -> explanation Once we know who the document is intended for and what kind of document it is, we just need to follow the folder structure. For example, this document is intended for users and aims to explain how to create a new page in the documentation, so it will go in: > pages > users > how_to There is an exception for the FAQ whixh we keep separate and visible for convenience","title":"1. Determine where the page belongs"},{"location":"pages/users/how_to/create_new_documentation_page/create_new_documentation_page.html#2-create-a-branch-on-git-for-the-new-document","text":"Ideally, there will be a Jira ticket for the changes about to be made. It should be used to name the branch, as it will enable Jira to directly link the ticket to the branch. For example, the development branch for this document is called IA-2630_how_to_write_iaso_doc To create the branch: - Open a terminal - Make sure you are on main. If not run git checkout main - Run git checkout -b <Branch name> . This will create the branch and switch to it","title":"2. Create a branch on git for the new document"},{"location":"pages/users/how_to/create_new_documentation_page/create_new_documentation_page.html#3-create-folder-and-markdown-file","text":"By convention, we create a folder with the same name as the markdown file. For example, this document is in: > pages > users > how_to > create_new_documentation_page - create_new_documentation_page.md","title":"3. Create folder and markdown file"},{"location":"pages/users/how_to/create_new_documentation_page/create_new_documentation_page.html#4-write-the-doc","text":"Format the text using markdown syntax","title":"4. Write the doc"},{"location":"pages/users/how_to/create_new_documentation_page/create_new_documentation_page.html#41-add-images","text":"Add a folder called /attachments/ in the document's folder and move the images there > pages > users > how_to > create_new_documentation_page > attachments - create_new_documentation_page.md To add the image in the markdown file, either: - use markdown syntax to add the link ![my_image](./attachments/my_image.png) - use an html img tag: <img src=\"./attachments/image49.png\" /> The markdown syntax is less cumbersome if the image is already at the right size. The img tag allows for manually setting the image width and heigh via the style attribute: <img src=\"./attachments/image49.png\" style=\"width:50px;height:50px\" /> Note: Add the /attachments/ folder even if the document doesn't contain any images yet. It will make it easier for others to add them later.","title":"4.1. Add images"},{"location":"pages/users/how_to/create_new_documentation_page/create_new_documentation_page.html#5-push-the-changes-on-github","text":"Once the document is ready, the changes need to be saved on the git branch, then pushed on Github, so they can be reviewed and merged. There are tools to make this part faster and easier to manage ( Github desktop , or even just the git ineterface of VS Code ), but if it needs to be done in the terminal (from the document's branch): - git add . - git commit -m <commit message> - git push","title":"5. Push the changes on Github"},{"location":"pages/users/how_to/create_new_documentation_page/create_new_documentation_page.html#6-open-the-pull-request","text":"Pull requests are the process through which we review code. Since the documentation is hosted as part of the code, it's going through the same review process, though not necessarily by the same persons. To open a pull request: - Go to iaso's pull requests - Click New pull request - Select a branch - Describe the changes. The description template can be ignored for documentation changes, but please leave a description, as it helps tracking and understanding changes.","title":"6. Open the Pull Request"},{"location":"pages/users/how_to/create_new_documentation_page/create_new_documentation_page.html#7-review-a-pull-request","text":"Pull requests are peer-reviews that insure that all changes are cross-checked, so one should not merge their own pull requests. To review a pull request: - Go to iaso's pull requests - Click in the pull request - Click \"Add your review\" - Review the changes, comment where necessary - To finish the review, click \"Review changes\" - If the changes can be deployed as they are, choose \"Approve\" - If not, explain what needs to be corrected and chooses \"Request changes\" - If the PR has been approved, go the \"Conversation\" tab of the PR, scroll down and click \"Merge pull request\" The changes will be visible in production after the next release of iaso.","title":"7. Review a pull request"},{"location":"pages/users/how_to/edit_documentation/edit_documentation.html","text":"How to edit an existing page in iaso's documentation # 1. To add only text # On the readthedocs page, click \"Edit on Github\" Make the changes Click \"Commit changes\" Add a description of the changes (eg: \"fix typo\") Choose \"Create new branch for this commit and start pull request\" Change the name of the branch (eg to include he Jira ticket number) Click \"Propose changes\" 2. To add Text and images # For the text, see point 1 above. For the images, add the images to the /attachments/ folder of that document, eg, for user_guide: > user_guide > attachments // <-- there - user_guide.md To add the image in the markdown file, either: - use markdown syntax to add the link ![my_image](./attachments/my_image.png) - use an html img tag: <img src=\"./attachments/image49.png\" /> The markdown syntax is less cumbersome if the image is already at the right size. The img tag allows for manually setting the image width and heigh via the style attribute: ```html If the /attachments/ folder doesn't exist, the change can't be made using Github's interface and should be made using git and an IDE/text editor","title":"How to edit an existing page in iaso's documentation"},{"location":"pages/users/how_to/edit_documentation/edit_documentation.html#how-to-edit-an-existing-page-in-iasos-documentation","text":"","title":"How to edit an existing page in iaso's documentation"},{"location":"pages/users/how_to/edit_documentation/edit_documentation.html#1-to-add-only-text","text":"On the readthedocs page, click \"Edit on Github\" Make the changes Click \"Commit changes\" Add a description of the changes (eg: \"fix typo\") Choose \"Create new branch for this commit and start pull request\" Change the name of the branch (eg to include he Jira ticket number) Click \"Propose changes\"","title":"1. To add only text"},{"location":"pages/users/how_to/edit_documentation/edit_documentation.html#2-to-add-text-and-images","text":"For the text, see point 1 above. For the images, add the images to the /attachments/ folder of that document, eg, for user_guide: > user_guide > attachments // <-- there - user_guide.md To add the image in the markdown file, either: - use markdown syntax to add the link ![my_image](./attachments/my_image.png) - use an html img tag: <img src=\"./attachments/image49.png\" /> The markdown syntax is less cumbersome if the image is already at the right size. The img tag allows for manually setting the image width and heigh via the style attribute: ```html If the /attachments/ folder doesn't exist, the change can't be made using Github's interface and should be made using git and an IDE/text editor","title":"2. To add Text and images"},{"location":"pages/users/how_to/setup_an_empty_iaso_account/setup_an_empty_iaso_account.html","text":"1. Setup an empty iaso account # Find someone with appropriate access right (django admin required) https://iaso.bluesquare.org/api/setupaccount/ Use and store the user/password in a password manager 2. Create a dedicated DHIS2 for iaso # We want to keep track of which app is changing which data/metadata of dhis2 so please don\u2019t use the main/default \u201cadmin\u201d user but a dedicated one. Go in the dhis2 \u201cUsers / Utilisateurs\u201d module \u201cDuplicate the admin\u201d Generate a password with password manager (need at least one special char) 3. Login in iaso with the user created at step 1 # Verify the account is empty or in the left menu Avoid doing the next steps with the django admin, as it can lead to industrial accident: the user may be linked to a totally different account/project you might end up with the pyramid of a project filled with orgunits of another country. 4. Add a new project # Use the naming used by clients if applicable. Promote \u201cgood behavior\u201d by enabling authentication by default 5. Create a new datasource # Use the user created at step 2 Make the source the default one 6. Create a new (first) Version of the data source # You can import this first version 7. Updating the pyramid # IMPORTANT note that if you \u201cadd new orgunits or add/change groups\u201d that\u2019s not previous step screen that you should use but the \u201cupdate\u201d button on the default version ! If you create a new version \u201cswap it to the default version\u201d this detection will be broken since incoming submission will be attached to different orgUnit iaso id. 8. What's next ? # Use the Mobile app in the store and provide the appId/user/password Start configuring the iaso forms try to be consistent and future proof in the naming ! this is good : ``` PMA - Qualit\u00e9 01 - Indicateurs g\u00e9n\u00e9raux PMA - Qualit\u00e9 02 - Plan financier PMA - Qualit\u00e9 03 - Consultation Postnatale ... PMA - Qualit\u00e9 10 - Vaccination PMA - Qualit\u00e9 11 - Accouchements PMA - Quantit\u00e9 PCA - Qualit\u00e9 ... this is **BAD** : PMA - Qualit\u00e9 1 - Indicateurs g\u00e9n\u00e9raux PMA - qualit\u00e9 10 - Vaccination PMA - Qualit\u00e9 11 - accouchements PMA - qualit\u00e9 2 - plan financier PMA - Qualit\u00e9 3 - consultation Postnatale... ... PMA - Quantit\u00e9 Qualit\u00e9 - PCA - ... ``` - computers are really bad at sorting in natural order so prefer 01 02 03 - be consistent in your upper/lower case usage - be consistent by prefixing the entity type (no need to put the country in it, we have limited space in the mobile app)","title":"1. Setup an empty iaso account"},{"location":"pages/users/how_to/setup_an_empty_iaso_account/setup_an_empty_iaso_account.html#1-setup-an-empty-iaso-account","text":"Find someone with appropriate access right (django admin required) https://iaso.bluesquare.org/api/setupaccount/ Use and store the user/password in a password manager","title":"1. Setup an empty iaso account"},{"location":"pages/users/how_to/setup_an_empty_iaso_account/setup_an_empty_iaso_account.html#2-create-a-dedicated-dhis2-for-iaso","text":"We want to keep track of which app is changing which data/metadata of dhis2 so please don\u2019t use the main/default \u201cadmin\u201d user but a dedicated one. Go in the dhis2 \u201cUsers / Utilisateurs\u201d module \u201cDuplicate the admin\u201d Generate a password with password manager (need at least one special char)","title":"2. Create a dedicated DHIS2 for iaso"},{"location":"pages/users/how_to/setup_an_empty_iaso_account/setup_an_empty_iaso_account.html#3-login-in-iaso-with-the-user-created-at-step-1","text":"Verify the account is empty or in the left menu Avoid doing the next steps with the django admin, as it can lead to industrial accident: the user may be linked to a totally different account/project you might end up with the pyramid of a project filled with orgunits of another country.","title":"3. Login in iaso with the user created at step 1"},{"location":"pages/users/how_to/setup_an_empty_iaso_account/setup_an_empty_iaso_account.html#4-add-a-new-project","text":"Use the naming used by clients if applicable. Promote \u201cgood behavior\u201d by enabling authentication by default","title":"4. Add a new project"},{"location":"pages/users/how_to/setup_an_empty_iaso_account/setup_an_empty_iaso_account.html#5-create-a-new-datasource","text":"Use the user created at step 2 Make the source the default one","title":"5. Create a new datasource"},{"location":"pages/users/how_to/setup_an_empty_iaso_account/setup_an_empty_iaso_account.html#6-create-a-new-first-version-of-the-data-source","text":"You can import this first version","title":"6. Create a new (first) Version of the data source"},{"location":"pages/users/how_to/setup_an_empty_iaso_account/setup_an_empty_iaso_account.html#7-updating-the-pyramid","text":"IMPORTANT note that if you \u201cadd new orgunits or add/change groups\u201d that\u2019s not previous step screen that you should use but the \u201cupdate\u201d button on the default version ! If you create a new version \u201cswap it to the default version\u201d this detection will be broken since incoming submission will be attached to different orgUnit iaso id.","title":"7. Updating the pyramid"},{"location":"pages/users/how_to/setup_an_empty_iaso_account/setup_an_empty_iaso_account.html#8-whats-next","text":"Use the Mobile app in the store and provide the appId/user/password Start configuring the iaso forms try to be consistent and future proof in the naming ! this is good : ``` PMA - Qualit\u00e9 01 - Indicateurs g\u00e9n\u00e9raux PMA - Qualit\u00e9 02 - Plan financier PMA - Qualit\u00e9 03 - Consultation Postnatale ... PMA - Qualit\u00e9 10 - Vaccination PMA - Qualit\u00e9 11 - Accouchements PMA - Quantit\u00e9 PCA - Qualit\u00e9 ... this is **BAD** : PMA - Qualit\u00e9 1 - Indicateurs g\u00e9n\u00e9raux PMA - qualit\u00e9 10 - Vaccination PMA - Qualit\u00e9 11 - accouchements PMA - qualit\u00e9 2 - plan financier PMA - Qualit\u00e9 3 - consultation Postnatale... ... PMA - Quantit\u00e9 Qualit\u00e9 - PCA - ... ``` - computers are really bad at sorting in natural order so prefer 01 02 03 - be consistent in your upper/lower case usage - be consistent by prefixing the entity type (no need to put the country in it, we have limited space in the mobile app)","title":"8. What's next ?"},{"location":"pages/users/how_to/setup_dhis2_login_in_iaso/setup_dhis2_login_in_iaso.html","text":"Setup login with dhis2 for iaso # In DHIS2 # Go in the oauth settings # in the menu : System settings > Oauth 2 clients Parametres Systeme > Oauth 2 clients Create oauth client # Name : iaso Select : authorization code Url : you need to pick a unique code : https://iaso.bluesquare.org/api/dhis2/<<unique-code>>/login/ In iaso django admin # Create an external credentials record # In django admin : https://iaso.bluesquare.org/admin/iaso/externalcredentials/ Name : oauth client id Login: the url of the dhis2 Password: the oauth client secret Url : iaso Enable the dhis2 link in the iaso menu # to be able to easily go back to dhis2 add the feature flag \"SHOW_DHIS2_LINK\" on the Project then the entry should appear In iaso # Link the iaso user with a dhis2 user # in iaso general ui Test # login in dhis2 with the linked in previous step <<dhis2>>/uaa/oauth/authorize?client_id=<<unique-code>>&response_type=code then \"Authorize\": you should end up in iaso It's not working ? Did you put the same code in iaso/dhis2/url to login ? The login in iaso external contains the url of the dhis2 ? Are you logged in dhis2 with the user you linked the iaso user ?","title":"Setup login with dhis2 for iaso"},{"location":"pages/users/how_to/setup_dhis2_login_in_iaso/setup_dhis2_login_in_iaso.html#setup-login-with-dhis2-for-iaso","text":"","title":"Setup login with dhis2 for iaso"},{"location":"pages/users/how_to/setup_dhis2_login_in_iaso/setup_dhis2_login_in_iaso.html#in-dhis2","text":"","title":"In DHIS2"},{"location":"pages/users/how_to/setup_dhis2_login_in_iaso/setup_dhis2_login_in_iaso.html#go-in-the-oauth-settings","text":"in the menu : System settings > Oauth 2 clients Parametres Systeme > Oauth 2 clients","title":"Go in the oauth settings"},{"location":"pages/users/how_to/setup_dhis2_login_in_iaso/setup_dhis2_login_in_iaso.html#create-oauth-client","text":"Name : iaso Select : authorization code Url : you need to pick a unique code : https://iaso.bluesquare.org/api/dhis2/<<unique-code>>/login/","title":"Create oauth client"},{"location":"pages/users/how_to/setup_dhis2_login_in_iaso/setup_dhis2_login_in_iaso.html#in-iaso-django-admin","text":"","title":"In iaso django admin"},{"location":"pages/users/how_to/setup_dhis2_login_in_iaso/setup_dhis2_login_in_iaso.html#create-an-external-credentials-record","text":"In django admin : https://iaso.bluesquare.org/admin/iaso/externalcredentials/ Name : oauth client id Login: the url of the dhis2 Password: the oauth client secret Url : iaso","title":"Create an external credentials record"},{"location":"pages/users/how_to/setup_dhis2_login_in_iaso/setup_dhis2_login_in_iaso.html#enable-the-dhis2-link-in-the-iaso-menu","text":"to be able to easily go back to dhis2 add the feature flag \"SHOW_DHIS2_LINK\" on the Project then the entry should appear","title":"Enable the dhis2 link in the iaso menu"},{"location":"pages/users/how_to/setup_dhis2_login_in_iaso/setup_dhis2_login_in_iaso.html#in-iaso","text":"","title":"In iaso"},{"location":"pages/users/how_to/setup_dhis2_login_in_iaso/setup_dhis2_login_in_iaso.html#link-the-iaso-user-with-a-dhis2-user","text":"in iaso general ui","title":"Link the iaso user with a dhis2 user"},{"location":"pages/users/how_to/setup_dhis2_login_in_iaso/setup_dhis2_login_in_iaso.html#test","text":"login in dhis2 with the linked in previous step <<dhis2>>/uaa/oauth/authorize?client_id=<<unique-code>>&response_type=code then \"Authorize\": you should end up in iaso It's not working ? Did you put the same code in iaso/dhis2/url to login ? The login in iaso external contains the url of the dhis2 ? Are you logged in dhis2 with the user you linked the iaso user ?","title":"Test"},{"location":"pages/users/reference/iaso_concepts/iaso_concepts.html","text":"Concepts # Questionnaires or XLS data collection forms # What comes with data collection are questions, and to organize these questions, data collection forms . These are basically lists of the questions one would like to collect answers for, while specifying options (mandatory or not, skip a question depending on previous answer, etc.). IASO builds on XLS forms for its questionnaires, which are therefore pre-defined using an Excel file. In IASO, data collection forms are versioned meaning that every time a new version is created, the former version is kept and available in the system. Organization Units # IASO uses the notion of Organization Units (Org unit or OU) to manage geographic data. The organisation unit types (OUT) represent levels in the hierarchy Example: Country Region District Area Facility/Village/Point of Interest The organization units are classified in the pyramid according to a parent and one or several children (except the top parent(s) and the lowest child/children). Example below: Democratic Republic of Congo (Org unit type \"Country\") is the parent org unit of Kinshasa (Org unit type \"City\"), which is the parent org unit of Bluesquare office (Org unit type \"Office\") Data collection in IASO is structured according to the defined hierarchy, and any user needs to explicitly select an organization unit before proceeding to opening the questionnaire and answer questions. This way, one makes sure that the data collected is correctly associated with the relevant geography. Projects # In IASO, a Project is a mobile application instance, with its own App ID. Within one account, you can have one or several Project(s) with different feature option(s). Users can be linked to one or several Project(s). Good to know: One Project is linked one data source One Project can be linked to one or several users Some users can be limited to one or several Project(s)/App ID(s) - you can define this in the User management part Every Org Unit Type has to be linked to one or several Project(s) Every Form has to be linked to one or several Project(s)","title":"Concepts"},{"location":"pages/users/reference/iaso_concepts/iaso_concepts.html#concepts","text":"","title":"Concepts"},{"location":"pages/users/reference/iaso_concepts/iaso_concepts.html#questionnaires-or-xls-data-collection-forms","text":"What comes with data collection are questions, and to organize these questions, data collection forms . These are basically lists of the questions one would like to collect answers for, while specifying options (mandatory or not, skip a question depending on previous answer, etc.). IASO builds on XLS forms for its questionnaires, which are therefore pre-defined using an Excel file. In IASO, data collection forms are versioned meaning that every time a new version is created, the former version is kept and available in the system.","title":"Questionnaires or XLS data collection forms"},{"location":"pages/users/reference/iaso_concepts/iaso_concepts.html#organization-units","text":"IASO uses the notion of Organization Units (Org unit or OU) to manage geographic data. The organisation unit types (OUT) represent levels in the hierarchy Example: Country Region District Area Facility/Village/Point of Interest The organization units are classified in the pyramid according to a parent and one or several children (except the top parent(s) and the lowest child/children). Example below: Democratic Republic of Congo (Org unit type \"Country\") is the parent org unit of Kinshasa (Org unit type \"City\"), which is the parent org unit of Bluesquare office (Org unit type \"Office\") Data collection in IASO is structured according to the defined hierarchy, and any user needs to explicitly select an organization unit before proceeding to opening the questionnaire and answer questions. This way, one makes sure that the data collected is correctly associated with the relevant geography.","title":"Organization Units"},{"location":"pages/users/reference/iaso_concepts/iaso_concepts.html#projects","text":"In IASO, a Project is a mobile application instance, with its own App ID. Within one account, you can have one or several Project(s) with different feature option(s). Users can be linked to one or several Project(s). Good to know: One Project is linked one data source One Project can be linked to one or several users Some users can be limited to one or several Project(s)/App ID(s) - you can define this in the User management part Every Org Unit Type has to be linked to one or several Project(s) Every Form has to be linked to one or several Project(s)","title":"Projects"},{"location":"pages/users/reference/iaso_mobile/iaso_mobile.html","text":"Mobile Application # IASO mobile application is available on Google Play Store (Android phones only). It can work completely offline - once the end user has encoded the data needed, he/she can upload the data collected offline all at once when network is available. Updates made from the web (forms versions, health pyramid) will be reflected in the App only after the App data has been refreshed and this requires network connectivity. Key tip before testing / using the App - Make sure you have refreshed data beforehand Run the mobile application for the first time # IASO Mobile application has to be configured on the web part before using (see the part \u201cProject\u201d). Then you can: Download IASO App on Google Play Insert the server url : https://iaso.bluesquare.org Then, enter the App ID Overview of buttons # See below an overview of the main buttons that you can find on the main screen in data collection mode. In the More Options part, you can take the below actions: - Refresh data: you need to have internet connectivity to do so. It will synchronize the mobile application with IASO web data. In order to avoid that it takes too long in low-connectivity settings, you can choose to refresh only sub-parts such as Forms, Organization Units, or other. - Change the App ID: you can switch Project by entering another App ID. In order to make sure that there is no data from the former App ID left on the IASO mobile application, please access your parameters and erase storage and cache data from IASO beforehand. - Change the URL of the server: this can be handy if you need to switch from Production to Staging server - Logout: your user can logout. This does not prevent data consultation of local data (data available on IASO on the user's device) - About: gives the version of the IASO mobile application. It can be good to have to debug. Collect data # Once you are connected to the IASO mobile application, you can then proceed with your data collection. Here below are the different screens that you would see for a simple data collection. You will then have data collection form chosen opening. You can proceed with answering the different questions and press \"Next\" until the end of the Form. If you wish to interrupt data collection during input, you can press the back button on the tablet or smartphone. Once you click on the button, you have 2 options: - Save Changes: to save all data already filled and the form with unfinalized status. With this option you can, come back and continue enter data - Ignore Changes: to delete data filled and the form Upload collected data If you collect data with your mobile device, they are stored in your device. You need to upload data to the server to make them visible at central level. Keep in mind that you need internet connection in order to be able to upload data . Click on the \"Send Finalized Forms\" icon on the mobile application home page on the top right corner. Then, a specific page will open to let you know if the data has been correctly uploaded. Finalize the operation by clicking on \"Send to server\".","title":"Mobile Application"},{"location":"pages/users/reference/iaso_mobile/iaso_mobile.html#mobile-application","text":"IASO mobile application is available on Google Play Store (Android phones only). It can work completely offline - once the end user has encoded the data needed, he/she can upload the data collected offline all at once when network is available. Updates made from the web (forms versions, health pyramid) will be reflected in the App only after the App data has been refreshed and this requires network connectivity. Key tip before testing / using the App - Make sure you have refreshed data beforehand","title":"Mobile Application"},{"location":"pages/users/reference/iaso_mobile/iaso_mobile.html#run-the-mobile-application-for-the-first-time","text":"IASO Mobile application has to be configured on the web part before using (see the part \u201cProject\u201d). Then you can: Download IASO App on Google Play Insert the server url : https://iaso.bluesquare.org Then, enter the App ID","title":"Run the mobile application for the first time"},{"location":"pages/users/reference/iaso_mobile/iaso_mobile.html#overview-of-buttons","text":"See below an overview of the main buttons that you can find on the main screen in data collection mode. In the More Options part, you can take the below actions: - Refresh data: you need to have internet connectivity to do so. It will synchronize the mobile application with IASO web data. In order to avoid that it takes too long in low-connectivity settings, you can choose to refresh only sub-parts such as Forms, Organization Units, or other. - Change the App ID: you can switch Project by entering another App ID. In order to make sure that there is no data from the former App ID left on the IASO mobile application, please access your parameters and erase storage and cache data from IASO beforehand. - Change the URL of the server: this can be handy if you need to switch from Production to Staging server - Logout: your user can logout. This does not prevent data consultation of local data (data available on IASO on the user's device) - About: gives the version of the IASO mobile application. It can be good to have to debug.","title":"Overview of buttons"},{"location":"pages/users/reference/iaso_mobile/iaso_mobile.html#collect-data","text":"Once you are connected to the IASO mobile application, you can then proceed with your data collection. Here below are the different screens that you would see for a simple data collection. You will then have data collection form chosen opening. You can proceed with answering the different questions and press \"Next\" until the end of the Form. If you wish to interrupt data collection during input, you can press the back button on the tablet or smartphone. Once you click on the button, you have 2 options: - Save Changes: to save all data already filled and the form with unfinalized status. With this option you can, come back and continue enter data - Ignore Changes: to delete data filled and the form Upload collected data If you collect data with your mobile device, they are stored in your device. You need to upload data to the server to make them visible at central level. Keep in mind that you need internet connection in order to be able to upload data . Click on the \"Send Finalized Forms\" icon on the mobile application home page on the top right corner. Then, a specific page will open to let you know if the data has been correctly uploaded. Finalize the operation by clicking on \"Send to server\".","title":"Collect data"},{"location":"pages/users/reference/iaso_modules/iaso_modules.html","text":"Modules # IASO is organized according to Modules, which are groups of functionalities which can be added up depending on the use case to cover. Here are the Modules available in IASO: Data collection functionalities # Manage data collection forms (XLS forms) and their related data submissions Manage geographic data (import/export of geo data from Excel, DHIS2 or Geopackages, manage the Organizations Units and their hierarchy) Monitor the data collection process with the completeness statistics table and map Manage users and their permissions and geographies, user roles and teams Create mobile application(s) IDs and manage related features options Georegistry # Import several data sources from Excel, DHIS2 or Geopackages, compare and merge them as needed Visualize on a dynamic map data collected at the different levels of the hierarchy (e.g. Country, Region, District, facility) Validate changes on Organization Units (Name, Type, GPS coordinates, opening/closing dates) submitted from the field via the mobile application Validate data submitted via data collection forms that are linked to specific Organization Units types, called \"Reference forms\" Based on the validated proposed changes per user, generate payment lots to send to Mobile Money provider DHIS2 bi-directional integration # Manage the mappings with DHIS2 data elements for import/export of data Planning # Plan ahead your data collection activities by creating a planning with a set timeframe, geography, data collection forms and teams Assign data collection tasks to teams and users from the map-based interface available on the web Once tasks have been assigned, the mobile application users on the field will only see the forms that have been assigned to them Entities # Entities are items that can move from a geography to another, for instance a person, a pallet of goods, or other Entities can be created from the mobile application and then managed from the web application Find the entities duplicates by using the web application interface and make the decision to merge two similar entities or not Assign workflows to entity types, enabling specific data collection forms to open according to previsouly given answers","title":"Modules"},{"location":"pages/users/reference/iaso_modules/iaso_modules.html#modules","text":"IASO is organized according to Modules, which are groups of functionalities which can be added up depending on the use case to cover. Here are the Modules available in IASO:","title":"Modules"},{"location":"pages/users/reference/iaso_modules/iaso_modules.html#data-collection-functionalities","text":"Manage data collection forms (XLS forms) and their related data submissions Manage geographic data (import/export of geo data from Excel, DHIS2 or Geopackages, manage the Organizations Units and their hierarchy) Monitor the data collection process with the completeness statistics table and map Manage users and their permissions and geographies, user roles and teams Create mobile application(s) IDs and manage related features options","title":"Data collection functionalities"},{"location":"pages/users/reference/iaso_modules/iaso_modules.html#georegistry","text":"Import several data sources from Excel, DHIS2 or Geopackages, compare and merge them as needed Visualize on a dynamic map data collected at the different levels of the hierarchy (e.g. Country, Region, District, facility) Validate changes on Organization Units (Name, Type, GPS coordinates, opening/closing dates) submitted from the field via the mobile application Validate data submitted via data collection forms that are linked to specific Organization Units types, called \"Reference forms\" Based on the validated proposed changes per user, generate payment lots to send to Mobile Money provider","title":"Georegistry"},{"location":"pages/users/reference/iaso_modules/iaso_modules.html#dhis2-bi-directional-integration","text":"Manage the mappings with DHIS2 data elements for import/export of data","title":"DHIS2 bi-directional integration"},{"location":"pages/users/reference/iaso_modules/iaso_modules.html#planning","text":"Plan ahead your data collection activities by creating a planning with a set timeframe, geography, data collection forms and teams Assign data collection tasks to teams and users from the map-based interface available on the web Once tasks have been assigned, the mobile application users on the field will only see the forms that have been assigned to them","title":"Planning"},{"location":"pages/users/reference/iaso_modules/iaso_modules.html#entities","text":"Entities are items that can move from a geography to another, for instance a person, a pallet of goods, or other Entities can be created from the mobile application and then managed from the web application Find the entities duplicates by using the web application interface and make the decision to merge two similar entities or not Assign workflows to entity types, enabling specific data collection forms to open according to previsouly given answers","title":"Entities"},{"location":"pages/users/reference/iaso_web/user_guide.html","text":"Web Platform # IASO web platform is intended to administrators for them to define the details of the data collection they would like to proceed with. Some key assets of IASO are: the versioning of all data - every change is tracked and former versions can be retrieved as needed geo-structured data collection - forms are linked to clear Geographical levels or \"Organization Units\" the traceability of changes - allowing decentralization of the activities and responsibilities Administrators can therefore use the web platform to plan, monitor and then evaluate the data collection efforts. Login # To log into the web interface, go to https://iaso.bluesquare.org/login/ and sign in with your username and password. You can also reset your password by clicking on the link \"Forgot password\". This will send an automatic email and allow you to create a new password. Navigating in IASO # Manage data collection forms # Forms list # From the forms list, you can search through the available forms of the IASO account you are connected to using the filters: The below buttons allow you to manage the data collections forms. Create/Upload a data collection form # Access the Forms entry in the menu, then click on Form list. Click on the button \"Create\". Once on the Form creation page, follow the below steps: Enter a name for your form in the field \"Name\". Assign one or several Project(s) to your form. Assign an Org unit type to your form. Assign a Period to your form. This is intended for regular data collection (e.g. daily/weekly/yearly). If you don't need this option, just select \"No Period\". Tips: Check your XLS form before uploading it to IASO using this link: https://getodk.org/xlsform/ Form ID should stay the same across versions (it cannot be different from a version to another). You will have an error if this is the case. Form version (which is not a mandatory field in the settings of the XLS forms) should stay consistent across versions. For instance, if it is a date such as 20240410, then you will not be able to upload a version names 20231025. IASO makes automatic checks to ensure that you are not uploading a former version. Form submissions # Once a form has been completed and sent to the server, it creates a \"form submission\". Every form submission is recorded into the platform and data submitted can be consulted from there. You can use the filters to consult the form submissions as needed: Open search (type some key words) Per form Per Org unit (select the relevant one in the dropdown pyramid) Per Org unit type (e.g. Country, District, Village) Per submission date (creation from/creation until) Per user (type a user name and it will show as dropdown) This view allows you to search forms through free text entry and several filters that can be combined. Once you have applied at least one form filter, you can download submissions using the \"CSV\" or \"XLSX\" buttons. You can also create a new submission by clicking on \"Create\". This will open Enketo and ask you which Organization Unit it relates to. You can also check the submissions on the map view, on which the filters apply. To make sure to have this map view enabled, make sure you have added the feature flag \"GPS for each form\" to the related Project . The tab \"File\" allows you to visualize the files that have been submitted together with the forms, such as pictures. When clicking on a given file, you can then be redirected to the relevant form submission. Manage submissions # On the Submissions page, you can see the list of submissions that have been done for the account. You can manage them using the below options. Visualise a submission You can view a specific submission/submitted form by clicking on the \"View\" button (see above). This allows you to see the data submitted and edit it on Enketo ( open-source web application. The \u201cInformation\u201d section provides a technical overview of the form. The \u201cLocation\u201d section shows the health pyramid's indication of where the data was collected. The \u201cExport Requests\u201d section shows when the data was exported to DHIS2, by whom, and any errors that occurred during export. The \u201cFiles\u201d section can contain images, videos, documents. The \u201cForm\u201d section shows all form questions and answers entered during data collection. Download a submission The \"XML\" icon allows you to download a submission in XML format. The gear icon on the bottom corner at the right hand side shows you a series of icons upon hover. These allow you to: Delete a submission Edit attached Org Unit or Period Export (e.g. to DHIS2) Push GPS coordinates from the submission to the Org Unit Edit this submission via Enketo Lock submission See below the dedicated sections for more information on each of these actions. Delete a submission Allows you to delete the form. If it has already been exported to DHIS2, this will not delete the data in DHIS2. A warning message will appear: Edit attached Org Unit or Period When you click on \u201cEdit Period and/or Organisational Unit\u201d, a window opens allowing you to reassign the instance. You can change the time period or organization unit that has been assigned to the submitted form. Export a submission The export function allows you to export the form to DHIS2. Beforehand, it needs to have been mapped using the DHIS2 mapping functionality. Edit the submission via Enketo To edit a form, click on the Enketo icon (see above). Edit the form by changing the answers to the questions that need to be changed. Then click on submit at the bottom of the form. Push GPS coordinates from the submission to the Org Unit This will use the GPS coordinate collected via the form to push to the Organization Unit GPS coordinates. Lock submission This functionalty allows you to protect the form submissions from further editing by users who have less permissions than you. Form statistics # This view allows you to see statistics about the forms. When clicking on \u201dForm Statistics\" you will open a page with two graphs. The first one shows the total number of submissions over time and the second one shows the new submissions per month per form. DHIS2 mappings # A great advantage of IASO is that you can export data to DHIS2. When doing so, prior mapping is necessary. After the form is uploaded, map the form to match the data item in DHIS2. Click on DHIS mappings to see the forms : In the Form view you can see details of: Actions Name of forms available for mapping Versions Type of the form : Aggregate : fix Event : series of singular events Event Tracker : continuous Number of questionnaire to be mapped Total number of questionnaires Mapping coverage Date of last modification Click \"Create\" and a window will open allowing you to map each questionnaire of the xls forms to the correspondent DHIS2 data element The mapping process consists of selecting a question on the left and deciding whether it should be mapped to DHIS2 or not. Some questions may not need to be mapped like notes, metadata etc. in such a case click on never map. If the question is to be mapped, search for the correspondence DE in the box by using the name, code or ID and then confirm. Once confirmed, the question will turn to green and be counted. Completeness # This functionality is intended to use cases where Periods have been set to the data collection forms. In the view \u201ccompleteness\u201d you will see details of : Buttons to select forms \u201cready\u201d to be exported, form with \u201cerrors\u201d > and forms that have been \u201cexported\u201d Periodicity filter : the periodicity filter allows you to organise > the data into months, quarters, semesters or years. The list will > display the forms available for the selected period, and will > indicate how many forms have been submitted for each Synchronise button to synchronise two forms Click on each of these buttons to have forms ready to be exported, errors and exported. A periodicity filter is there to organise data in months, quarters, semester or yearly. If you click on the number of submissions, you will be taken to the submissions view, where you can click on the view icon and see the submissions for that form. Click on the button to synchronise two forms Eg: to get aggregate data from community verification survey, all the client forms should be synchronised to a single form. Completeness statistics # This table view shows you the completeness of the forms submissions in number (number of completed forms) and in percentages (Data completeness). A distinction is made between \u201cdirect forms\u201d (which relate to the select Organization unit level) and \u201clower level forms\u201d (which relates to forms down the hierarchy). Use the filters (Form name, Parent Organization Unit, Organization Unit type, User, Planning, Teams, Period) to only see statistics in a more specific way. The \"See children\" action button allows you to drilldown the geographical hierarchy to identify the level of completeness and spot where issues may have happened. The first two columns \"itself\" indicate the number of forms completed at the level of the Organization Unit highlighted. The next column \"descendants\" give information on the number of forms completed at the level in question, but also at all lower levels. You can also view data completeness with a map view by clicking on the \"Map\" tab. Be aware that you need to select a Form in the filters beforehand to enable this view. You can adjust the thresholds to apply to the legend on completeness in the relevant form's advanced settings. Georegistry - Organization Units Management # See the Organization Unit definition for more insight on what Organization Units are. In a nutshell, you can manage your geographical data associated to your account using the Organization Unit part of IASO. Organization Units List # Click Organization Units in the menu and then on Organization Unit List to navigate the organization unit pyramid. You can view in list or map. You can select an Organization Unit Navigation and: Change the name, type, validation status, place in the pyramid, etc. of the OU Visualize the OU on a map See the history of its modifications The search results can be exported in CSV, XLSX or GPKG. Results can be seen in a list or on a map The status for when a village has just been added and needs to be reviewed for example. The external reference is used to export data to DHIS2. The map helps you to know where the structure is located. You can see the history of modifications by clicking on the little clock icon or the details of the filled forms by clicking on the eye icon. Several searches can be made by adding tabs to the page with the + button. You can choose the colour of the results on the map for each search. Creation of an Organization Unit On the Organization Unit list page, click on \"Create\". You can then create an Organization Unit as needed. You will need to enter the below information before saving: Name of the Organization Unit Type of the Organization Unit (that you would have previously defined in the Organization Unit Type part) Status: New, Validated, or Rejected. New: the Organization unit has been created but has not been validated yet. If you activate the possibility to create Organization Units from the IASO mobile application, they will first appear as \"New\" on the web Validated: the Organization unit is validated Rejected: the Organization unit no longer exists or has been merged/split or replaced by another one. IASO does not allow to erase Organization Units in order to keep track of past changes. Optional fields: Aliases: you can add as many aliases as necessary to track the different ways of writing the name of the Organization Unit (e.g. \"Ste Marie\", \"Sainte-Marie\", \"Sainte Marie\", etc.) Group: you can organize Organization Units in Groups in IASO. You can multi-select the group(s) that the organization unit you are creating is associated to Parent Org Unit: place your Organization Unit at its relevant place in the hierarchy Opening and/or Closing date(s): use these fields to indicate the opening or closing date(s) of the Organization Unit Edit an Organization Unit or consult details To access the detailed view of an Organization Unit, proceed as described below: In this view, you have a set of tabs that allow you to edit the Organization Unit as needed: Infos: edit the main information relating to this Organization Unit Map: consult the geographical information available for this Organization Unit (boundaries or GPS coordinates). You can view geographical data across data sources (if there are several sources). You can also leave a comment Children: lists this Organization Unit's children. You can use filter to go through the list in a more detailed way Links: in the case of matching an Organization Unit across multiple data sources, the links among the data sources can be found here History: allows you to trace back all modifications that were done to the Organization Unit by user Forms: lists all data collection forms that are linked to the Organization Unit type of this Organization Unit Comments: you can leave a comment about this Organization Unit using this section Bulk edition of Organization Units You can also edit Organization Units in bulk. In order to do this, from the Organization Unit list, tick the boxes of the Organization Units you would like to bulk edit, then hover on the action button. Click on the gear action button, and select the action you would like to perform. Organization Unit Groups # Organisation units can be grouped in organisation unit groups, and these groups can be further organised into group sets. Together they can mimic an alternative organisational hierarchy which can be used when creating reports and other data output. In addition to representing alternative geographical locations not part of the main hierarchy, these groups are useful for assigning classification schemes to Organization Units. Manage Organization Unit Groups In order to manage the Organization Unit Groups, access the menu entry Organization Units > Groups. This view allows you to search the Organisation Unit Groups through free text entry. You can create a new group by clicking on the create button. Groups can be edited by clicking on the gear icon or deleted by clicking on the delete button. In the table, the column \"Org Units\" shows the number of Organization Units that are assigned to this group. When you click on the number, you will see the list of that Org Unit group. Assign Organization Units to Groups To assign Organization Units to Groups, go to the Organization Units List view from the menu and make a bulk edit of the selected organization Units. See above in section \"Bulk edition of Organization Units\" for more details on bulk edition of Organization Units. Organization Unit types management # Organization Unit types are specific to IASO (i.e. this is not handled in DHIS2). See the part about Organization Units for more details on what Organization Unit types are. From the Organization Unit menu entry, click on \"Organization Unit types\". This view lists the Organization Unit types existing in your IASO account. Create an Organization Unit type Click on \"Create\" and enter the below mandatory fields: Name of the Organization Unit type. Beware that this should be the \"category\" / \"level in the hierarchy\", NOT the specific name of an Organization Unit. E.g. \"Country, \"Province\", \"District\", and NOT \"DRC\", \"Kinshasa\", \"Gombe\" Short name: this will appear on other IASO views. It should be a short version of the full name Project(s): select one or multiple project(s) the Organization Unit type is linked to These other fields are not mandatory: Level: start with 0 for the highest point in the hierarchy, for instance \"Country\". E.g. Country - 0, Province - 1, District - 2, Village - 3 Sub org unit types to display: select the below Org Unit type(s) that you would like to display on the Registry view if this main Org Unit type that you are editing is selected. Sub Org unit types to create: select the Org Unit type(s) that you would like to enable the creation for in the IASO mobile application. For instance, if you are editing the Org unit type \"District\", you can enable the creation of \"Village\" and/or \"Point of Interest\" Reference forms: select one or several data collection Form(s) that will be assigned as reference for this Org Unit type. Reference forms are Forms that are closely linked to the Org Unit type. A typical use case is for an Area to assign a reference Form for Population data. Data Source(s) management # IASO allows to import and handle one or several geographic data source(s). Data Source(s) List # Find here the data sources with their names, versions and descriptions. It is possible to edit the data source, check up on the files\u2019 version history or compare data sources and export them to DHIS2. Matching # This is rather a \"geospatial\" functionality : to have several geographical pyramid sources and try to make links (Example: where in a csv \u201cprovince x\u201d is called \"PROVINCE X\" and in another source it is called \"DPS X\"). The algorithms run part is intended for data science work. Registry # The Registry entry in Organization Unit is a visualization tool allowing users to drilldown in the geographical hierarchy and consult the geographical data as well as data collection associated to the different level(s). Review change proposals # With IASO, supervisors can compare and validate data submissions as they are sent to the server. Note that this feature will only work provided that you have activated the \"Change requests\" feature flag on the IASO Project you would like to validate data collected for. See the Projects part for more information on mobile feature flags in IASO. On the Review change proposals page, users can use the filters to select the proposals they would like to focus on. See on the picture below the detailed filters. Supervisors can then click on the gear icon at the end of the relevant line to be able to see the details of the change proposal submitted and compare with the former version on the left. Supervisors can then select the changes they would like to approve by ticking the boxes of the changes selected on the right column, and then hit \"Approve selected changes\". If the changes proposed are not satisfactory, supervisors can reject all changes and provide a comment. For each change proposal sent, IASO mobile application users will be able to see if they have been approved or rejected, and if rejected, consult the comment. Planning # The Planning feature in IASO allows you to plan field work per team and user in defined zones/organization units and according to a specific timeline. Once data collection activities would have been assigned via the interface, field agents using the mobile application would only be able to see the activities assigned to them, and navigate towards the relevant GPS point(s). In order to be able to create a Planning, you will need to have created beforehand Organization units, Users, a Project, Teams of Users/Teams of Teams and data collection Forms for which you would like to use the Planning feature. Planning List # Click on Planning in the menu panel. Under Planning List you will see the list of schedules/plannings that have been created in IASO. You can search through the different Plannings using the different filters and take the below actions: Create Planning View Planning: this is where you will access the interface to assign data collection activities to Teams and Users according to geographies Edit Planning: edit the Name, Project, Parent Organization Unit and Team it applies to, Form(s), Description Duplicate Planning: allows users to copy an existing Planning and readapt it as needed Erase Planning Create a Planning Click on \"Create\" and you will see the below window opening: The below fields are mandatory: Name Project: defines in which mobile app environment the Planning info will be visible Team: it is the team responsible for the planning - this is usually a Team of Teams Form(s): select one or several Form(s) to apply to this Planning Org unit: select the base Organization Unit your Planning applies to. Keep in mind that you will drilldown from this base Organization Unit to assign your data collection activities to Teams/Users. start and end dates for your Planning You can add a description as an option. The \u201cPublishing status\u201d (in the lower left corner) feature makes it possible to ensure, once completed (and all assignments made), the newly created planning will be available in the IASO mobile app for the relevant project. Once you have completed the fields, click \"Save\" to finish. Click on the eye icon button from the Planning list to start editing your new Planning via the Map interface. You can do the assignment either through the \u201cMap\u201d or the \u201cList\u201d tab. If processing through the map, first select the Team you would like to assign a geography to in the dropdown, as well as the relevant \u201cBase Org Unit type\u201d in the dropdown. You can then start assigning geographic areas or points directly to the selected Team members directly on the map. Selected areas will be highlighted with the team\u2019s colour, that you can change as needed. In order to assign all children Org Unit of a given parent Org unit to the same Team/User, you can select the \"Parent picking mode\" before proceeding to your selection. If you prefer using the List tab, the process is pretty similar. The main difference being that you work here with a list of names, according to the selected level. Org units are assigned by clicking in front of the item name, in the \u201cAssignment\u201d column. You can sort Org units and Parents by clicking on the column name. Admin # The Admin part of IASO comprises several parts, which will appear or not depending on the user's permissions: Tasks Monitoring Projects Modules Users User roles Teams Tasks # This is the IASO batch updates log. An operation log contains information about when and where an operation ran, the operation status, the number of source and target records processed, and any log messages. Examples of tasks include: Organization unit bulk update DHIS2 data import Geopackage import The statuses are: Errored: the Task did not make it through. Users are advised to try again. Running: the Task is in process Queued: the Task has stopped and will restart if the conditions are met (for instance, if there is better connectivity) Killed: the Task was interrupted by the user after it had been started Success: the Task has been successfully run The Task list can be refreshed by pressing the button \"Refresh\" on the right top hand side. Monitoring # This part allows supervisors to monitor devices that are linked with the IASO account. From this page, you can consult: The IMEI or device identifier If this is a test device or not the name of the last owner the last time it has been synchronized the creation date (first time it has been synchronized) the modification date On the right hand side, you can see the number of devices that are connected under the IASO account you are connected to. Projects # A Project in IASO relates to an instance of mobile application. Each Project is identified by a Name and an App ID. See here for a more detailed definition of Projects in IASO. Create a Project From the menu, Admin > Projects > Click on \"Create\" Then, add a Project name, and an App ID. Be aware that the App ID will have to be entered by IASO mobile application users the first time they connect to the IASO app, so it should not be overly complicated to avoid typing errors. You can then select the Feature flags you would like to apply to your Project in the next tab and press \"Save\". Feature flags definition See the table below for more details on the Project Feature flags: Feature flag Description Authentication Users have to enter their login and password on the mobile application before proceeding to the data collection. Please note that this is possible in IASO to proceed to data collection without authentication for simplified processes (also called \u201canonymous mode\u201d) Mobile: show data collection screen Enable the feature to collect data from the IASO mobile application (data collection that is not linked to a planning or a change request workflow) GPS for each form Every time a data collection form is submitted, a GPS point is automatically taken and associated to the form submission Enforce users are within reach of the org unit before starting the form IASO mobile application users have to be close (50m) to the organization unit GPS point they are collecting data for in order for the form to open Mobile. Show planning screen When a planning has been done in IASO via the web interface, the assigned data collection points and tasks are reflected via this tab Mobile: limit download of org unit to what the user has access to When loading data into the mobile application, only the geographical zone that is assigned to the user is downloaded, so as to enable offline use. This allows a lighter (and then quicker and less data-consuming) download of data at the start of the IASO mobile application Mobile. Show Map of org unit Adds a tab in the mobile application to show the geographic information available for the selected Org Unit in the mobile application. For instance, if a GPS coordinate is available for a health facility, it would show on the map via this tab Request changes to org units Enable the feature to propose changes to org units and their related reference form(s) Mobile: Change requests Adds the tab allowing to propose changes to org units and their reference form(s) GPS for trajectory Enable the user to activate a function that track their position every 15 minutes over a period of time Mobile. Warn the user when forms have been updated When new form versions have been uploaded on the web, the IASO mobile application user is notified. Then the user can choose to apply them or not Mobile. Warn the user when forms have been updated and force them to update When new form versions have been uploaded on the web, the IASO mobile application user is notified and the update happens automatically Mobile. Warn the user when the org units have been updated When changes to the Org units (health pyramid) have been done on the web, the IASO mobile application user is notified. Then the user can choose to apply them or not Mobile. Warn the user when the org units have been updated and force them to update When changes to the Org units (health pyramid) have been done on the web, the IASO mobile application user is notified and the update happens automatically Auto upload of finalized forms The synchronization of forms that have been filled takes place automatically as soon as the user has connectivity Mobile. Finalized forms are read only IASO mobile application users cannot edit the forms once finalized in the mobile application Users # Users can access IASO web and mobile application with login credentials. Each user is assigned permissions and can be limited by location. Permissions are relatively granular: - By screen/tab - Different read/write permissions for important domains - Restriction of access using the health pyramid - Batch creation/modification of users - Customizable user roles (Administrator, Data manager, etc.) Please note that the permissions assigned from the User management apply to IASO web only . IASO does not have a system of permissions for its mobile application, but rather a set of Feature Flags. Create a new IASO user From the menu Admin > Users, click on \"Create\". Fill in user information Note that you can also indicate the following information: DHIS2 id of the user: you can import a list of DHIS2 users to IASO and keep track of their DHIS2 id in IASO to link then across both systems Home page: you can set up a default landing page for that user when connecting to this IASO account Projects: select one or several Project(s) to which the newly created user will be linked. If there is no Project indicated here, the user will have access to all Projects of the IASO account by default. Language: you can specify in which default language this user will use IASO web. IASO mobile application is based on the default language of the users's device. Assign user permissions On the next tab \u201cPermissions\u201d, you can enable/disable permissions for that user as needed. Note that in the \u201c?\u201d are tooltips to explain what the permissions do. Restrict user to a specific Location On the last tab \"Location\", you can restrict the access of the user you are editing to a sub-part of the Organization Unit hierarchy (hence the user will only be able to see data relating to his/her Geography). If no Location is specified here, by default the user will see all data available across the entire hierarchy. Create users in bulk You can create several users at once using a CSV file that you import to IASO. Use the button \u201cCreate from file\u201d and you can then import your list of users (or download the relevant template to do so beforehand). Manage IASO users This view allows you to manage users and their permissions. You can search for a user using the different filters. You can edit IASO users in bulk using the bulk update feature. First, tick each user you would like to update using the check boxes on the right side of each user line. Then select the action(s) you would like to perform for these users. They can be: Add or remove from user role(s) Add or remove from Project(s) Add or remove from Team(s) Update default language Add or Remove Location (hence limiting these users to the selected Geography) Click on \"Validate\" when done. User roles # User roles allow to group users that are granted a set of permissions under the same role. In the User role, you are able to create User roles with their matching permissions, to which Users can be assigned to. Create a User role From the Admin > User roles page, click on \"Create\". You can then assign this user role to any user through the Permission tab in the User edit popup. Be aware that the User role permissions will apply to the user, but if the User has more permissions that had been previsouly assigned to him/her, he/she will not lose them but they will add up. To assign multiple Users to this newly created user role in bulk, go back to the Users list and proceed to a bulk update (see Manage Users above). Teams # The notion of Teams in IASO is used mainly for the Planning feature. It allows to organize Users in Team hierarchies and assign data collection activities to the relevant geographies as needed for the Planning purposes. There are two types of Teams: Teams of Users: gathers IASO Users under the same team Teams of Teams: gathers several Teams under a same Team. You can then create hierarchies of Teams Create a Team From the menu, access Admin > Teams. Click on \u201cCreate\u201d Fill out the below fields: Team name Manager: select from the Users in IASO Project: select the Project to be linked to this Team Type: select in the dropdown the type of Team If you select \"Team of Users\" - then select the Users to be added to that Team If you select \"Team of Teams\" - then select the Teams to be added to that Team Parent: select the Parent Team for this newly created team You can then use the gear or bin icon on the main page to edit or delete Team(s) as needed.","title":"Web Platform"},{"location":"pages/users/reference/iaso_web/user_guide.html#web-platform","text":"IASO web platform is intended to administrators for them to define the details of the data collection they would like to proceed with. Some key assets of IASO are: the versioning of all data - every change is tracked and former versions can be retrieved as needed geo-structured data collection - forms are linked to clear Geographical levels or \"Organization Units\" the traceability of changes - allowing decentralization of the activities and responsibilities Administrators can therefore use the web platform to plan, monitor and then evaluate the data collection efforts.","title":"Web Platform"},{"location":"pages/users/reference/iaso_web/user_guide.html#login","text":"To log into the web interface, go to https://iaso.bluesquare.org/login/ and sign in with your username and password. You can also reset your password by clicking on the link \"Forgot password\". This will send an automatic email and allow you to create a new password.","title":"Login"},{"location":"pages/users/reference/iaso_web/user_guide.html#navigating-in-iaso","text":"","title":"Navigating in IASO"},{"location":"pages/users/reference/iaso_web/user_guide.html#manage-data-collection-forms","text":"","title":"Manage data collection forms"},{"location":"pages/users/reference/iaso_web/user_guide.html#forms-list","text":"From the forms list, you can search through the available forms of the IASO account you are connected to using the filters: The below buttons allow you to manage the data collections forms.","title":"Forms list"},{"location":"pages/users/reference/iaso_web/user_guide.html#createupload-a-data-collection-form","text":"Access the Forms entry in the menu, then click on Form list. Click on the button \"Create\". Once on the Form creation page, follow the below steps: Enter a name for your form in the field \"Name\". Assign one or several Project(s) to your form. Assign an Org unit type to your form. Assign a Period to your form. This is intended for regular data collection (e.g. daily/weekly/yearly). If you don't need this option, just select \"No Period\". Tips: Check your XLS form before uploading it to IASO using this link: https://getodk.org/xlsform/ Form ID should stay the same across versions (it cannot be different from a version to another). You will have an error if this is the case. Form version (which is not a mandatory field in the settings of the XLS forms) should stay consistent across versions. For instance, if it is a date such as 20240410, then you will not be able to upload a version names 20231025. IASO makes automatic checks to ensure that you are not uploading a former version.","title":"Create/Upload a data collection form"},{"location":"pages/users/reference/iaso_web/user_guide.html#form-submissions","text":"Once a form has been completed and sent to the server, it creates a \"form submission\". Every form submission is recorded into the platform and data submitted can be consulted from there. You can use the filters to consult the form submissions as needed: Open search (type some key words) Per form Per Org unit (select the relevant one in the dropdown pyramid) Per Org unit type (e.g. Country, District, Village) Per submission date (creation from/creation until) Per user (type a user name and it will show as dropdown) This view allows you to search forms through free text entry and several filters that can be combined. Once you have applied at least one form filter, you can download submissions using the \"CSV\" or \"XLSX\" buttons. You can also create a new submission by clicking on \"Create\". This will open Enketo and ask you which Organization Unit it relates to. You can also check the submissions on the map view, on which the filters apply. To make sure to have this map view enabled, make sure you have added the feature flag \"GPS for each form\" to the related Project . The tab \"File\" allows you to visualize the files that have been submitted together with the forms, such as pictures. When clicking on a given file, you can then be redirected to the relevant form submission.","title":"Form submissions"},{"location":"pages/users/reference/iaso_web/user_guide.html#manage-submissions","text":"On the Submissions page, you can see the list of submissions that have been done for the account. You can manage them using the below options. Visualise a submission You can view a specific submission/submitted form by clicking on the \"View\" button (see above). This allows you to see the data submitted and edit it on Enketo ( open-source web application. The \u201cInformation\u201d section provides a technical overview of the form. The \u201cLocation\u201d section shows the health pyramid's indication of where the data was collected. The \u201cExport Requests\u201d section shows when the data was exported to DHIS2, by whom, and any errors that occurred during export. The \u201cFiles\u201d section can contain images, videos, documents. The \u201cForm\u201d section shows all form questions and answers entered during data collection. Download a submission The \"XML\" icon allows you to download a submission in XML format. The gear icon on the bottom corner at the right hand side shows you a series of icons upon hover. These allow you to: Delete a submission Edit attached Org Unit or Period Export (e.g. to DHIS2) Push GPS coordinates from the submission to the Org Unit Edit this submission via Enketo Lock submission See below the dedicated sections for more information on each of these actions. Delete a submission Allows you to delete the form. If it has already been exported to DHIS2, this will not delete the data in DHIS2. A warning message will appear: Edit attached Org Unit or Period When you click on \u201cEdit Period and/or Organisational Unit\u201d, a window opens allowing you to reassign the instance. You can change the time period or organization unit that has been assigned to the submitted form. Export a submission The export function allows you to export the form to DHIS2. Beforehand, it needs to have been mapped using the DHIS2 mapping functionality. Edit the submission via Enketo To edit a form, click on the Enketo icon (see above). Edit the form by changing the answers to the questions that need to be changed. Then click on submit at the bottom of the form. Push GPS coordinates from the submission to the Org Unit This will use the GPS coordinate collected via the form to push to the Organization Unit GPS coordinates. Lock submission This functionalty allows you to protect the form submissions from further editing by users who have less permissions than you.","title":"Manage submissions"},{"location":"pages/users/reference/iaso_web/user_guide.html#form-statistics","text":"This view allows you to see statistics about the forms. When clicking on \u201dForm Statistics\" you will open a page with two graphs. The first one shows the total number of submissions over time and the second one shows the new submissions per month per form.","title":"Form statistics"},{"location":"pages/users/reference/iaso_web/user_guide.html#dhis2-mappings","text":"A great advantage of IASO is that you can export data to DHIS2. When doing so, prior mapping is necessary. After the form is uploaded, map the form to match the data item in DHIS2. Click on DHIS mappings to see the forms : In the Form view you can see details of: Actions Name of forms available for mapping Versions Type of the form : Aggregate : fix Event : series of singular events Event Tracker : continuous Number of questionnaire to be mapped Total number of questionnaires Mapping coverage Date of last modification Click \"Create\" and a window will open allowing you to map each questionnaire of the xls forms to the correspondent DHIS2 data element The mapping process consists of selecting a question on the left and deciding whether it should be mapped to DHIS2 or not. Some questions may not need to be mapped like notes, metadata etc. in such a case click on never map. If the question is to be mapped, search for the correspondence DE in the box by using the name, code or ID and then confirm. Once confirmed, the question will turn to green and be counted.","title":"DHIS2 mappings"},{"location":"pages/users/reference/iaso_web/user_guide.html#completeness","text":"This functionality is intended to use cases where Periods have been set to the data collection forms. In the view \u201ccompleteness\u201d you will see details of : Buttons to select forms \u201cready\u201d to be exported, form with \u201cerrors\u201d > and forms that have been \u201cexported\u201d Periodicity filter : the periodicity filter allows you to organise > the data into months, quarters, semesters or years. The list will > display the forms available for the selected period, and will > indicate how many forms have been submitted for each Synchronise button to synchronise two forms Click on each of these buttons to have forms ready to be exported, errors and exported. A periodicity filter is there to organise data in months, quarters, semester or yearly. If you click on the number of submissions, you will be taken to the submissions view, where you can click on the view icon and see the submissions for that form. Click on the button to synchronise two forms Eg: to get aggregate data from community verification survey, all the client forms should be synchronised to a single form.","title":"Completeness"},{"location":"pages/users/reference/iaso_web/user_guide.html#completeness-statistics","text":"This table view shows you the completeness of the forms submissions in number (number of completed forms) and in percentages (Data completeness). A distinction is made between \u201cdirect forms\u201d (which relate to the select Organization unit level) and \u201clower level forms\u201d (which relates to forms down the hierarchy). Use the filters (Form name, Parent Organization Unit, Organization Unit type, User, Planning, Teams, Period) to only see statistics in a more specific way. The \"See children\" action button allows you to drilldown the geographical hierarchy to identify the level of completeness and spot where issues may have happened. The first two columns \"itself\" indicate the number of forms completed at the level of the Organization Unit highlighted. The next column \"descendants\" give information on the number of forms completed at the level in question, but also at all lower levels. You can also view data completeness with a map view by clicking on the \"Map\" tab. Be aware that you need to select a Form in the filters beforehand to enable this view. You can adjust the thresholds to apply to the legend on completeness in the relevant form's advanced settings.","title":"Completeness statistics"},{"location":"pages/users/reference/iaso_web/user_guide.html#georegistry-organization-units-management","text":"See the Organization Unit definition for more insight on what Organization Units are. In a nutshell, you can manage your geographical data associated to your account using the Organization Unit part of IASO.","title":"Georegistry - Organization Units Management"},{"location":"pages/users/reference/iaso_web/user_guide.html#organization-units-list","text":"Click Organization Units in the menu and then on Organization Unit List to navigate the organization unit pyramid. You can view in list or map. You can select an Organization Unit Navigation and: Change the name, type, validation status, place in the pyramid, etc. of the OU Visualize the OU on a map See the history of its modifications The search results can be exported in CSV, XLSX or GPKG. Results can be seen in a list or on a map The status for when a village has just been added and needs to be reviewed for example. The external reference is used to export data to DHIS2. The map helps you to know where the structure is located. You can see the history of modifications by clicking on the little clock icon or the details of the filled forms by clicking on the eye icon. Several searches can be made by adding tabs to the page with the + button. You can choose the colour of the results on the map for each search. Creation of an Organization Unit On the Organization Unit list page, click on \"Create\". You can then create an Organization Unit as needed. You will need to enter the below information before saving: Name of the Organization Unit Type of the Organization Unit (that you would have previously defined in the Organization Unit Type part) Status: New, Validated, or Rejected. New: the Organization unit has been created but has not been validated yet. If you activate the possibility to create Organization Units from the IASO mobile application, they will first appear as \"New\" on the web Validated: the Organization unit is validated Rejected: the Organization unit no longer exists or has been merged/split or replaced by another one. IASO does not allow to erase Organization Units in order to keep track of past changes. Optional fields: Aliases: you can add as many aliases as necessary to track the different ways of writing the name of the Organization Unit (e.g. \"Ste Marie\", \"Sainte-Marie\", \"Sainte Marie\", etc.) Group: you can organize Organization Units in Groups in IASO. You can multi-select the group(s) that the organization unit you are creating is associated to Parent Org Unit: place your Organization Unit at its relevant place in the hierarchy Opening and/or Closing date(s): use these fields to indicate the opening or closing date(s) of the Organization Unit Edit an Organization Unit or consult details To access the detailed view of an Organization Unit, proceed as described below: In this view, you have a set of tabs that allow you to edit the Organization Unit as needed: Infos: edit the main information relating to this Organization Unit Map: consult the geographical information available for this Organization Unit (boundaries or GPS coordinates). You can view geographical data across data sources (if there are several sources). You can also leave a comment Children: lists this Organization Unit's children. You can use filter to go through the list in a more detailed way Links: in the case of matching an Organization Unit across multiple data sources, the links among the data sources can be found here History: allows you to trace back all modifications that were done to the Organization Unit by user Forms: lists all data collection forms that are linked to the Organization Unit type of this Organization Unit Comments: you can leave a comment about this Organization Unit using this section Bulk edition of Organization Units You can also edit Organization Units in bulk. In order to do this, from the Organization Unit list, tick the boxes of the Organization Units you would like to bulk edit, then hover on the action button. Click on the gear action button, and select the action you would like to perform.","title":"Organization Units List"},{"location":"pages/users/reference/iaso_web/user_guide.html#organization-unit-groups","text":"Organisation units can be grouped in organisation unit groups, and these groups can be further organised into group sets. Together they can mimic an alternative organisational hierarchy which can be used when creating reports and other data output. In addition to representing alternative geographical locations not part of the main hierarchy, these groups are useful for assigning classification schemes to Organization Units. Manage Organization Unit Groups In order to manage the Organization Unit Groups, access the menu entry Organization Units > Groups. This view allows you to search the Organisation Unit Groups through free text entry. You can create a new group by clicking on the create button. Groups can be edited by clicking on the gear icon or deleted by clicking on the delete button. In the table, the column \"Org Units\" shows the number of Organization Units that are assigned to this group. When you click on the number, you will see the list of that Org Unit group. Assign Organization Units to Groups To assign Organization Units to Groups, go to the Organization Units List view from the menu and make a bulk edit of the selected organization Units. See above in section \"Bulk edition of Organization Units\" for more details on bulk edition of Organization Units.","title":"Organization Unit Groups"},{"location":"pages/users/reference/iaso_web/user_guide.html#organization-unit-types-management","text":"Organization Unit types are specific to IASO (i.e. this is not handled in DHIS2). See the part about Organization Units for more details on what Organization Unit types are. From the Organization Unit menu entry, click on \"Organization Unit types\". This view lists the Organization Unit types existing in your IASO account. Create an Organization Unit type Click on \"Create\" and enter the below mandatory fields: Name of the Organization Unit type. Beware that this should be the \"category\" / \"level in the hierarchy\", NOT the specific name of an Organization Unit. E.g. \"Country, \"Province\", \"District\", and NOT \"DRC\", \"Kinshasa\", \"Gombe\" Short name: this will appear on other IASO views. It should be a short version of the full name Project(s): select one or multiple project(s) the Organization Unit type is linked to These other fields are not mandatory: Level: start with 0 for the highest point in the hierarchy, for instance \"Country\". E.g. Country - 0, Province - 1, District - 2, Village - 3 Sub org unit types to display: select the below Org Unit type(s) that you would like to display on the Registry view if this main Org Unit type that you are editing is selected. Sub Org unit types to create: select the Org Unit type(s) that you would like to enable the creation for in the IASO mobile application. For instance, if you are editing the Org unit type \"District\", you can enable the creation of \"Village\" and/or \"Point of Interest\" Reference forms: select one or several data collection Form(s) that will be assigned as reference for this Org Unit type. Reference forms are Forms that are closely linked to the Org Unit type. A typical use case is for an Area to assign a reference Form for Population data.","title":"Organization Unit types management"},{"location":"pages/users/reference/iaso_web/user_guide.html#data-sources-management","text":"IASO allows to import and handle one or several geographic data source(s).","title":"Data Source(s) management"},{"location":"pages/users/reference/iaso_web/user_guide.html#data-sources-list","text":"Find here the data sources with their names, versions and descriptions. It is possible to edit the data source, check up on the files\u2019 version history or compare data sources and export them to DHIS2.","title":"Data Source(s) List"},{"location":"pages/users/reference/iaso_web/user_guide.html#matching","text":"This is rather a \"geospatial\" functionality : to have several geographical pyramid sources and try to make links (Example: where in a csv \u201cprovince x\u201d is called \"PROVINCE X\" and in another source it is called \"DPS X\"). The algorithms run part is intended for data science work.","title":"Matching"},{"location":"pages/users/reference/iaso_web/user_guide.html#registry","text":"The Registry entry in Organization Unit is a visualization tool allowing users to drilldown in the geographical hierarchy and consult the geographical data as well as data collection associated to the different level(s).","title":"Registry"},{"location":"pages/users/reference/iaso_web/user_guide.html#review-change-proposals","text":"With IASO, supervisors can compare and validate data submissions as they are sent to the server. Note that this feature will only work provided that you have activated the \"Change requests\" feature flag on the IASO Project you would like to validate data collected for. See the Projects part for more information on mobile feature flags in IASO. On the Review change proposals page, users can use the filters to select the proposals they would like to focus on. See on the picture below the detailed filters. Supervisors can then click on the gear icon at the end of the relevant line to be able to see the details of the change proposal submitted and compare with the former version on the left. Supervisors can then select the changes they would like to approve by ticking the boxes of the changes selected on the right column, and then hit \"Approve selected changes\". If the changes proposed are not satisfactory, supervisors can reject all changes and provide a comment. For each change proposal sent, IASO mobile application users will be able to see if they have been approved or rejected, and if rejected, consult the comment.","title":"Review change proposals"},{"location":"pages/users/reference/iaso_web/user_guide.html#planning","text":"The Planning feature in IASO allows you to plan field work per team and user in defined zones/organization units and according to a specific timeline. Once data collection activities would have been assigned via the interface, field agents using the mobile application would only be able to see the activities assigned to them, and navigate towards the relevant GPS point(s). In order to be able to create a Planning, you will need to have created beforehand Organization units, Users, a Project, Teams of Users/Teams of Teams and data collection Forms for which you would like to use the Planning feature.","title":"Planning"},{"location":"pages/users/reference/iaso_web/user_guide.html#planning-list","text":"Click on Planning in the menu panel. Under Planning List you will see the list of schedules/plannings that have been created in IASO. You can search through the different Plannings using the different filters and take the below actions: Create Planning View Planning: this is where you will access the interface to assign data collection activities to Teams and Users according to geographies Edit Planning: edit the Name, Project, Parent Organization Unit and Team it applies to, Form(s), Description Duplicate Planning: allows users to copy an existing Planning and readapt it as needed Erase Planning Create a Planning Click on \"Create\" and you will see the below window opening: The below fields are mandatory: Name Project: defines in which mobile app environment the Planning info will be visible Team: it is the team responsible for the planning - this is usually a Team of Teams Form(s): select one or several Form(s) to apply to this Planning Org unit: select the base Organization Unit your Planning applies to. Keep in mind that you will drilldown from this base Organization Unit to assign your data collection activities to Teams/Users. start and end dates for your Planning You can add a description as an option. The \u201cPublishing status\u201d (in the lower left corner) feature makes it possible to ensure, once completed (and all assignments made), the newly created planning will be available in the IASO mobile app for the relevant project. Once you have completed the fields, click \"Save\" to finish. Click on the eye icon button from the Planning list to start editing your new Planning via the Map interface. You can do the assignment either through the \u201cMap\u201d or the \u201cList\u201d tab. If processing through the map, first select the Team you would like to assign a geography to in the dropdown, as well as the relevant \u201cBase Org Unit type\u201d in the dropdown. You can then start assigning geographic areas or points directly to the selected Team members directly on the map. Selected areas will be highlighted with the team\u2019s colour, that you can change as needed. In order to assign all children Org Unit of a given parent Org unit to the same Team/User, you can select the \"Parent picking mode\" before proceeding to your selection. If you prefer using the List tab, the process is pretty similar. The main difference being that you work here with a list of names, according to the selected level. Org units are assigned by clicking in front of the item name, in the \u201cAssignment\u201d column. You can sort Org units and Parents by clicking on the column name.","title":"Planning List"},{"location":"pages/users/reference/iaso_web/user_guide.html#admin","text":"The Admin part of IASO comprises several parts, which will appear or not depending on the user's permissions: Tasks Monitoring Projects Modules Users User roles Teams","title":"Admin"},{"location":"pages/users/reference/iaso_web/user_guide.html#tasks","text":"This is the IASO batch updates log. An operation log contains information about when and where an operation ran, the operation status, the number of source and target records processed, and any log messages. Examples of tasks include: Organization unit bulk update DHIS2 data import Geopackage import The statuses are: Errored: the Task did not make it through. Users are advised to try again. Running: the Task is in process Queued: the Task has stopped and will restart if the conditions are met (for instance, if there is better connectivity) Killed: the Task was interrupted by the user after it had been started Success: the Task has been successfully run The Task list can be refreshed by pressing the button \"Refresh\" on the right top hand side.","title":"Tasks"},{"location":"pages/users/reference/iaso_web/user_guide.html#monitoring","text":"This part allows supervisors to monitor devices that are linked with the IASO account. From this page, you can consult: The IMEI or device identifier If this is a test device or not the name of the last owner the last time it has been synchronized the creation date (first time it has been synchronized) the modification date On the right hand side, you can see the number of devices that are connected under the IASO account you are connected to.","title":"Monitoring"},{"location":"pages/users/reference/iaso_web/user_guide.html#projects","text":"A Project in IASO relates to an instance of mobile application. Each Project is identified by a Name and an App ID. See here for a more detailed definition of Projects in IASO. Create a Project From the menu, Admin > Projects > Click on \"Create\" Then, add a Project name, and an App ID. Be aware that the App ID will have to be entered by IASO mobile application users the first time they connect to the IASO app, so it should not be overly complicated to avoid typing errors. You can then select the Feature flags you would like to apply to your Project in the next tab and press \"Save\". Feature flags definition See the table below for more details on the Project Feature flags: Feature flag Description Authentication Users have to enter their login and password on the mobile application before proceeding to the data collection. Please note that this is possible in IASO to proceed to data collection without authentication for simplified processes (also called \u201canonymous mode\u201d) Mobile: show data collection screen Enable the feature to collect data from the IASO mobile application (data collection that is not linked to a planning or a change request workflow) GPS for each form Every time a data collection form is submitted, a GPS point is automatically taken and associated to the form submission Enforce users are within reach of the org unit before starting the form IASO mobile application users have to be close (50m) to the organization unit GPS point they are collecting data for in order for the form to open Mobile. Show planning screen When a planning has been done in IASO via the web interface, the assigned data collection points and tasks are reflected via this tab Mobile: limit download of org unit to what the user has access to When loading data into the mobile application, only the geographical zone that is assigned to the user is downloaded, so as to enable offline use. This allows a lighter (and then quicker and less data-consuming) download of data at the start of the IASO mobile application Mobile. Show Map of org unit Adds a tab in the mobile application to show the geographic information available for the selected Org Unit in the mobile application. For instance, if a GPS coordinate is available for a health facility, it would show on the map via this tab Request changes to org units Enable the feature to propose changes to org units and their related reference form(s) Mobile: Change requests Adds the tab allowing to propose changes to org units and their reference form(s) GPS for trajectory Enable the user to activate a function that track their position every 15 minutes over a period of time Mobile. Warn the user when forms have been updated When new form versions have been uploaded on the web, the IASO mobile application user is notified. Then the user can choose to apply them or not Mobile. Warn the user when forms have been updated and force them to update When new form versions have been uploaded on the web, the IASO mobile application user is notified and the update happens automatically Mobile. Warn the user when the org units have been updated When changes to the Org units (health pyramid) have been done on the web, the IASO mobile application user is notified. Then the user can choose to apply them or not Mobile. Warn the user when the org units have been updated and force them to update When changes to the Org units (health pyramid) have been done on the web, the IASO mobile application user is notified and the update happens automatically Auto upload of finalized forms The synchronization of forms that have been filled takes place automatically as soon as the user has connectivity Mobile. Finalized forms are read only IASO mobile application users cannot edit the forms once finalized in the mobile application","title":"Projects"},{"location":"pages/users/reference/iaso_web/user_guide.html#users","text":"Users can access IASO web and mobile application with login credentials. Each user is assigned permissions and can be limited by location. Permissions are relatively granular: - By screen/tab - Different read/write permissions for important domains - Restriction of access using the health pyramid - Batch creation/modification of users - Customizable user roles (Administrator, Data manager, etc.) Please note that the permissions assigned from the User management apply to IASO web only . IASO does not have a system of permissions for its mobile application, but rather a set of Feature Flags. Create a new IASO user From the menu Admin > Users, click on \"Create\". Fill in user information Note that you can also indicate the following information: DHIS2 id of the user: you can import a list of DHIS2 users to IASO and keep track of their DHIS2 id in IASO to link then across both systems Home page: you can set up a default landing page for that user when connecting to this IASO account Projects: select one or several Project(s) to which the newly created user will be linked. If there is no Project indicated here, the user will have access to all Projects of the IASO account by default. Language: you can specify in which default language this user will use IASO web. IASO mobile application is based on the default language of the users's device. Assign user permissions On the next tab \u201cPermissions\u201d, you can enable/disable permissions for that user as needed. Note that in the \u201c?\u201d are tooltips to explain what the permissions do. Restrict user to a specific Location On the last tab \"Location\", you can restrict the access of the user you are editing to a sub-part of the Organization Unit hierarchy (hence the user will only be able to see data relating to his/her Geography). If no Location is specified here, by default the user will see all data available across the entire hierarchy. Create users in bulk You can create several users at once using a CSV file that you import to IASO. Use the button \u201cCreate from file\u201d and you can then import your list of users (or download the relevant template to do so beforehand). Manage IASO users This view allows you to manage users and their permissions. You can search for a user using the different filters. You can edit IASO users in bulk using the bulk update feature. First, tick each user you would like to update using the check boxes on the right side of each user line. Then select the action(s) you would like to perform for these users. They can be: Add or remove from user role(s) Add or remove from Project(s) Add or remove from Team(s) Update default language Add or Remove Location (hence limiting these users to the selected Geography) Click on \"Validate\" when done.","title":"Users"},{"location":"pages/users/reference/iaso_web/user_guide.html#user-roles","text":"User roles allow to group users that are granted a set of permissions under the same role. In the User role, you are able to create User roles with their matching permissions, to which Users can be assigned to. Create a User role From the Admin > User roles page, click on \"Create\". You can then assign this user role to any user through the Permission tab in the User edit popup. Be aware that the User role permissions will apply to the user, but if the User has more permissions that had been previsouly assigned to him/her, he/she will not lose them but they will add up. To assign multiple Users to this newly created user role in bulk, go back to the Users list and proceed to a bulk update (see Manage Users above).","title":"User roles"},{"location":"pages/users/reference/iaso_web/user_guide.html#teams","text":"The notion of Teams in IASO is used mainly for the Planning feature. It allows to organize Users in Team hierarchies and assign data collection activities to the relevant geographies as needed for the Planning purposes. There are two types of Teams: Teams of Users: gathers IASO Users under the same team Teams of Teams: gathers several Teams under a same Team. You can then create hierarchies of Teams Create a Team From the menu, access Admin > Teams. Click on \u201cCreate\u201d Fill out the below fields: Team name Manager: select from the Users in IASO Project: select the Project to be linked to this Team Type: select in the dropdown the type of Team If you select \"Team of Users\" - then select the Users to be added to that Team If you select \"Team of Teams\" - then select the Teams to be added to that Team Parent: select the Parent Team for this newly created team You can then use the gear or bin icon on the main page to edit or delete Team(s) as needed.","title":"Teams"},{"location":"pages/users/reference/interop/interop.html","text":"Interoperability roadmap 2023-2024 # Introduction # Iaso, whose name was taken from the name of a Greek goddess for health, has initially been developed to support national health programmes in their data collection and organization of geographical information in remote and low connectivity areas. Since then, it has also been used in other fields, such as education and environmental projects. Iaso builds on three essential concepts users, forms (in XLSForm format) and org units (e.g. districts and facilities) with a focus on structuring data collection along geographic lines to allow for splitting responsibility geographically, as is commonly done in health programs. This allows to decentralize monitoring, validation and team management. It also allows to have out of the box completeness reporting for data collection. Iaso has been recognized as a Global Good for Health by Digital Square. As such, Bluesquare acknowledges the importance of making Iaso as interoperable as possible in order to facilitate data exchange within the global digital health ecosystem such as the Open Health Information Exchange (OpenHIE) community . Open standards already implemented # The below below standard technologies are already being used by Iaso today: Data collection: XLSForm , CSV Geographical data: geopackage Iaso data collection can be done through forms in the common XLSForm format used for example by ODK, and allows to import and export data to DHIS2 (thanks to a user-friendly mapping interface), which is not per se using open formats in general, but is a de facto standard in some health topics, DHIS2 being probably the most installed open source health information management system. Iaso allows imports and exports of geographical data through the geopackage format ( http://www.geopackage.org/ ) which is the relatively new golden standard for Geographical Information Systems. Interoperability roadmap # 1. Short-term (by end of 2023) DHIS2 Tracker data import/export Recently, we implemented case management features in Iaso, which is mainly the possibility to collect and store data about individuals. One goal will be to further develop the integration between Iaso and DHIS2 Tracker, to allow the import and export of data linked to individuals. FHIR In the same context as above, Bluesquare would ensure that Iaso is compatible with the FHIR standard for health care data exchange. That said, Iaso is a generic data collection tool, and consequently we can\u2019t enforce that collected data always uses a predefined set of fields. Consequently, support of FHIR for case management would be made on a project basis, and where Bluesquare could help is by providing documentation of how to implement some parts of the FHIR standard. On the other hand, Iaso is a very complete facility list management system and here, there is a very good opportunity to adopt OHIE facility registry standards. This will be studied by the end of the year and implemented if we can identify a project needing the feature. 2. Long-term (end of 2023 and beyond) Better sharing of documentation about Iaso Iaso\u2019s code and general information is published on the dedicated Github repository that you can find here: https://github.com/BLSQ/iaso/wiki Bluesquare has started to organize processes to ensure more easily accessible documentation about Iaso, that will benefit the open source health softwares community. An evolving user guide will be made available on https://readthedocs.org/ , together with more technical documentation on new features. A high-level roadmap on next features will also be published and maintained. To facilitate interoperability, we are in the process of publishing the api specification in the OpenAPI standard (the format used by the Swagger tool). Microplanning Iaso is growing more and more to be a planning system, e.g. for vaccination campaigns. We need to investigate if there are existing standards (outside of calendar standards like caldav) , especially in the OHIE specification that could be reused to expose our plannings to external systems. Logistics There is a growing demand for Iaso to be able to handle logistics, in order to monitor stocks of certain health-related or other supplies, such as vaccines, mosquito nets in certain locations. If Iaso would further develop features in this field, Bluesquare will make sure to follow the openHIE \u201cLogistics Management Information System (LMIS)\u201d and \u201cProduct Catalogue\u201d components principles.","title":"Interoperability roadmap 2023-2024"},{"location":"pages/users/reference/interop/interop.html#interoperability-roadmap-2023-2024","text":"","title":"Interoperability roadmap 2023-2024"},{"location":"pages/users/reference/interop/interop.html#introduction","text":"Iaso, whose name was taken from the name of a Greek goddess for health, has initially been developed to support national health programmes in their data collection and organization of geographical information in remote and low connectivity areas. Since then, it has also been used in other fields, such as education and environmental projects. Iaso builds on three essential concepts users, forms (in XLSForm format) and org units (e.g. districts and facilities) with a focus on structuring data collection along geographic lines to allow for splitting responsibility geographically, as is commonly done in health programs. This allows to decentralize monitoring, validation and team management. It also allows to have out of the box completeness reporting for data collection. Iaso has been recognized as a Global Good for Health by Digital Square. As such, Bluesquare acknowledges the importance of making Iaso as interoperable as possible in order to facilitate data exchange within the global digital health ecosystem such as the Open Health Information Exchange (OpenHIE) community .","title":"Introduction"},{"location":"pages/users/reference/interop/interop.html#open-standards-already-implemented","text":"The below below standard technologies are already being used by Iaso today: Data collection: XLSForm , CSV Geographical data: geopackage Iaso data collection can be done through forms in the common XLSForm format used for example by ODK, and allows to import and export data to DHIS2 (thanks to a user-friendly mapping interface), which is not per se using open formats in general, but is a de facto standard in some health topics, DHIS2 being probably the most installed open source health information management system. Iaso allows imports and exports of geographical data through the geopackage format ( http://www.geopackage.org/ ) which is the relatively new golden standard for Geographical Information Systems.","title":"Open standards already implemented"},{"location":"pages/users/reference/interop/interop.html#interoperability-roadmap","text":"1. Short-term (by end of 2023) DHIS2 Tracker data import/export Recently, we implemented case management features in Iaso, which is mainly the possibility to collect and store data about individuals. One goal will be to further develop the integration between Iaso and DHIS2 Tracker, to allow the import and export of data linked to individuals. FHIR In the same context as above, Bluesquare would ensure that Iaso is compatible with the FHIR standard for health care data exchange. That said, Iaso is a generic data collection tool, and consequently we can\u2019t enforce that collected data always uses a predefined set of fields. Consequently, support of FHIR for case management would be made on a project basis, and where Bluesquare could help is by providing documentation of how to implement some parts of the FHIR standard. On the other hand, Iaso is a very complete facility list management system and here, there is a very good opportunity to adopt OHIE facility registry standards. This will be studied by the end of the year and implemented if we can identify a project needing the feature. 2. Long-term (end of 2023 and beyond) Better sharing of documentation about Iaso Iaso\u2019s code and general information is published on the dedicated Github repository that you can find here: https://github.com/BLSQ/iaso/wiki Bluesquare has started to organize processes to ensure more easily accessible documentation about Iaso, that will benefit the open source health softwares community. An evolving user guide will be made available on https://readthedocs.org/ , together with more technical documentation on new features. A high-level roadmap on next features will also be published and maintained. To facilitate interoperability, we are in the process of publishing the api specification in the OpenAPI standard (the format used by the Swagger tool). Microplanning Iaso is growing more and more to be a planning system, e.g. for vaccination campaigns. We need to investigate if there are existing standards (outside of calendar standards like caldav) , especially in the OHIE specification that could be reused to expose our plannings to external systems. Logistics There is a growing demand for Iaso to be able to handle logistics, in order to monitor stocks of certain health-related or other supplies, such as vaccines, mosquito nets in certain locations. If Iaso would further develop features in this field, Bluesquare will make sure to follow the openHIE \u201cLogistics Management Information System (LMIS)\u201d and \u201cProduct Catalogue\u201d components principles.","title":"Interoperability roadmap"}]}